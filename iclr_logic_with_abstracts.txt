{'title': 'LogicInference: A new Datasaet for Teaching Logical Inference to seq2seq Models', 'authors': ['Santiago Ontanon', 'Joshua Ainslie', 'Vaclav Cvicek', 'Zachary Fisher'], 'Conference': 'ICLR2022 OSC Poster', 'date': 'Published: 25 Mar 2022, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HAGeIS_Lcg9&name=pdf', 'abstract': '</span><span class="note_content_value">Machine learning models such as Transformers or LSTMs struggle with tasks that are compositional in nature such as those involving reasoning/inference. Although many datasets exist to evaluate compositional generalization, when it comes to evaluating inference abilities, options are more limited. This paper presents LogicInference, a new dataset to evaluate the ability of models to perform logical inference. The dataset focuses on inference using propositional logic and a small subset of first-order logic, represented both in semi-formal logical notation, as well as in natural language. We also report initial results using a collection of machine learning models to establish an initial baseline in this dataset.</span>'}
{'title': 'Logic Pre-Training of Language Models', 'authors': ['Siru Ouyang', 'Zhuosheng Zhang', 'hai zhao'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=1gEb_H1DEqZ&name=pdf', 'abstract': '</span><span class="note_content_value">Pre-trained language models (PrLMs) have been shown useful for enhancing a broad range of natural language understanding (NLU) tasks. However, the capacity for capturing logic relations in challenging NLU still remains a bottleneck even for state-of-the-art PrLM enhancement, which greatly stalled their reasoning abilities. Thus we propose logic pre-training of language models, leading to the logic reasoning ability equipped PrLM, \\textsc{Prophet}. To let logic pre-training perform on a clear, accurate, and generalized knowledge basis, we introduce \\textit{fact} instead of the plain language unit in previous PrLMs. The \\textit{fact} is extracted through syntactic parsing in avoidance of unnecessary complex knowledge injection. Meanwhile, it enables training logic-aware models to be conducted on a more general language text. To explicitly guide the PrLM to capture logic relations, three pre-training objectives are introduced: 1) logical connectives masking to capture sentence-level logics, 2) logical structure completion to accurately capture facts from the original context, 3) logical path prediction on a logical graph to uncover global logic relationships among facts. We evaluate our model on a broad range of NLP and NLU tasks, including natural language inference, relation extraction, and machine reading comprehension with logical reasoning. Results show that the extracted fact and the newly introduced pre-training tasks can help \\textsc{Prophet} achieve significant performance in all the downstream tasks, especially in logic reasoning related tasks. </span>'}
{'title': 'Can Neural Networks Learn Implicit Logic from Physical Reasoning?', 'authors': ['Aaron Traylor', 'Roman Feiman', 'Ellie Pavlick'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 09 Mar 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HVoJCRLByVk&name=pdf', 'abstract': '</span><span class="note_content_value">Despite the success of neural network models in a range of domains, it remains an open question whether they can learn to represent abstract logical operators such as negation and disjunction. We test the hypothesis that neural networks without inherent inductive biases for logical reasoning can acquire an implicit representation of negation and disjunction. Here, implicit refers to limited, domain-specific forms of these operators, and work in psychology suggests these operators may be a precursor (developmentally and evolutionarily) to the type of abstract, domain-general logic that is characteristic of adult humans. To test neural networks, we adapt a test designed to diagnose the presence of negation and disjunction in animals and pre-verbal children, which requires inferring the location of a hidden object using constraints of the physical environment as well as implicit logic: if a ball is hidden in A or B, and shown not to be in A, can the subject infer that it is in B? Our results show that, despite the neural networks learning to track objects behind occlusion, they are unable to generalize to a task that requires implicit logic. We further show that models are unable to generalize to the test task even when they are trained directly on a logically identical (though visually dissimilar) task. However, experiments using transfer learning reveal that the models do recognize structural similarity between tasks which invoke the same logical reasoning pattern, suggesting that some desirable abstractions are learned, even if they are not yet sufficient to pass established tests of logical reasoning.</span>'}
{'title': 'LogicDP: Creating Labels for Graph Data via Inductive Logic Programming', 'authors': ['Yuan Yang', 'Faramarz Fekri', 'James Clayton Kerce', 'Ali Payani'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 01 Mar 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=2b2s9vd7wYv&name=pdf', 'abstract': '</span><span class="note_content_value">Graph data, such as scene graphs and knowledge graphs, see wide use in AI systems. In real-world and large applications graph data are usually incomplete, motivating graph reasoning models for missing-fact or missing-relationship inference. While these models can achieve state-of-the-art performance, they require a large amount of training data.\n\nRecent years have witnessed the rising interest in label creation with data programming (DP) methods, which aim to generate training labels from heuristic labeling functions. However, existing methods typically focus on unstructured data and are not optimized for graphs. In this work, we propose LogicDP, a data programming framework for graph data. Unlike existing DP methods, (1) LogicDP utilizes the inductive logic programming (ILP) technique and automatically discovers the labeling functions from the graph data; (2) LogicDP employs a budget-aware framework to iteratively refine the functions by querying an oracle, which significantly reduces the human efforts in function creations. Experiments show that LogicDP achieves better data efficiency in both scene graph and knowledge graph reasoning tasks.</span>'}
{'title': 'Logic and the 2-Simplicial Transformer', 'authors': ['James Clift', 'Dmitry Doryn', 'Daniel Murfet', 'James Wallbridge'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rkecJ6VFvr&name=pdf', 'abstract': '</span><span class="note_content_value">We introduce the 2-simplicial Transformer, an extension of the Transformer which includes a form of higher-dimensional attention generalising the dot-product attention, and uses this attention to update entity representations with tensor products of value vectors. We show that this architecture is a useful inductive bias for logical reasoning in the context of deep reinforcement learning.\n</span>'}
{'title': 'An Efficient Mean-field Approach to High-Order Markov Logic', 'authors': ['Weidi Xu', 'Jianshan He', 'Jingwei Wang', 'Hongting Zhou', 'Xiaopei Wan', 'Taifeng Wang', 'Ruopeng Li', 'Wei Chu'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=7UrHaeZ5Ie7&name=pdf', 'abstract': '</span><span class="note_content_value">Markov logic networks (MLNs) are powerful models for symbolic reasoning, which combine probabilistic modeling with relational logic. Inference algorithms for MLNs often perform at the level of propositional logic or require building a first-order probabilistic graph, and the computational efficiency remains a challenge. The mean-field algorithm generalizes message passing for approximate inference in many intractable probabilistic graphical models, but in MLNs it still suffers from the high-order dependencies among the massive groundings, resulting in time complexity exponential in both the length and the arity of logic rules. We propose a novel method, LogicMP, to simplify the logic message passing especially. In most practical cases, it can reduce the complexity significantly to polynomial for the formulae in conjunctive normal form (CNF). We exploit the property of CNF logic rules to sidestep the expectation computation of high-order dependency, and then formulate the logic message passing by Einstein summation to facilitate parallel computation, which can be optimized by sequentially contracting the rule arguments. With LogicMP, we achieve evident improvements on several reasoning benchmark datasets in both performance and efficiency over competitor methods. Specifically, the AUC-PR of the UW-CSE and Cora datasets is improved by more than 11\\% absolutely and the speed is about ten times faster.\n</span>'}
{'title': 'Neural Logic Machines', 'authors': ['Honghua Dong', 'Jiayuan Mao', 'Tian Lin', 'Chong Wang', 'Lihong Li', 'Denny Zhou'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': 'Published: 20 Dec 2018, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=B1xY-hRctX&name=pdf', 'abstract': '</span><span class="note_content_value">We propose the Neural Logic Machine (NLM), a neural-symbolic architecture for both inductive learning and logic reasoning. NLMs exploit the power of both neural networks---as function approximators, and logic programming---as a symbolic processor for objects with properties, relations, logic connectives, and quantifiers.  After being trained on small-scale tasks (such as sorting short arrays), NLMs can recover lifted rules, and generalize to large-scale tasks (such as sorting longer arrays). In our experiments, NLMs achieve perfect generalization in a number of tasks, from relational reasoning tasks on the family tree and general graphs, to decision making tasks including sorting arrays, finding shortest paths, and playing the blocks world. Most of these tasks are hard to accomplish for neural networks or inductive logic programming alone.</span>'}
{'title': 'Differentiable Logic Programming for Probabilistic Reasoning', 'authors': ['Tuo Xu', 'Lei Zou'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=FbC2VeNlth5&name=pdf', 'abstract': '</span><span class="note_content_value">This paper studies inductive logic programming for probabilistic reasoning. The key problems, i.e. learning rule structures and learning rule weights, have been extensively studied with traditional discrete searching methods as well as recent neural-based approaches. In this paper, we present a new approach called Differentiable Logic Programming (DLP), which provides a flexible framework for learning first-order logical rules for reasoning. We propose a continuous version of optimization problem for learning high-quality rules as a proxy and generalize rule learning and forward chaining algorithms in a differentiable manner, which enables us to efficiently learn rule structures and weights via gradient-based methods. Theoretical analysis and empirical results show effectiveness of our approach.</span>'}
{'title': 'Differentiable Learning of Graph-like Logical Rules from Knowledge Graphs', 'authors': ['Hongzhi Shi', 'quanming yao', 'Yong Li'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=AwPGPgExiYA&name=pdf', 'abstract': '</span><span class="note_content_value">Logical rules inside a knowledge graph (KG) are essential for reasoning, logical inference, and rule mining. However, existing works can only handle simple, i.e., chain-like and tree-like, rules and cannot capture KG\'s complex semantics, which can be better captured by graph-like rules. Besides, learning graph-like rules is very difficult because the graph structure exhibits a huge discrete search space. To address these issues, observing that the plausibility of logical rules can be explained by how frequently it appears in a KG, we propose a score function that represents graph-like rules with learnable parameters. The score also helps relax the discrete space into a continuous one and can be uniformly transformed into matrix form by the Einstein summation convention. Thus, it allows us to learn graph-like rules in an efficient, differentiable, and end-to-end training manner by optimizing the normalized score. We conduct extensive experiments on real-world datasets to show that our method outperforms previous works due to logical rules\' better expressive ability. Furthermore, we demonstrate that our method can learn high-quality and interpretable graph-like logical rules.</span>'}
{'title': 'Logical Entity Representation in Knowledge-Graphs for Differentiable Rule Learning', 'authors': ['Chi Han', 'Qizheng He', 'Charles Yu', 'Xinya Du', 'Hanghang Tong', 'Heng Ji'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 26 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=JdgO-ht1uTN&name=pdf', 'abstract': '</span><span class="note_content_value">Probabilistic logical rule learning has shown great strength in logical rule mining and knowledge graph completion. It learns logical rules to predict missing edges by reasoning on existing edges in the knowledge graph. However, previous efforts have largely been limited to only modeling chain-like Horn clauses such as R1(x; z) ^ R2(z; y) ) H(x; y). This formulation overlooks additional contextual information from neighboring sub-graphs of entity variables x, y and z. Intuitively, there is a large gap here, as local sub-graphs have been found to provide important information for knowledge graph completion. Inspired by these observations, we propose Logical Entity RePresentation (LERP) to encode contextual information of entities in the knowledge graph. A LERP is designed as a vector of probabilistic logical functions on the entity’s neighboring sub-graph. It is an interpretable representation while allowing for differentiable optimization. We can then incorporate LERP into probabilistic logical rule learning to learn more expressive rules. Empirical results demonstrate that with LERP, our model outperforms other rule learning methods in knowledge graph completion and is comparable or even superior to state-of-the-art black-box methods. Moreover, we find that our model can discover a more expressive family of logical rules. LERP can also be further combined with embedding learning methods like TransE to make it more interpretable.</span>'}
{'title': 'Can Neural Networks Understand Logical Entailment?', 'authors': ['Richard Evans', 'David Saxton', 'David Amos', 'Pushmeet Kohli', 'Edward Grefenstette'], 'Conference': 'ICLR 2018 Conference Blind Submission', 'date': '15 Feb 2018 (modified: 23 Feb 2018)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SkZxCk-0Z&name=pdf', 'abstract': '</span><span class="note_content_value">We introduce a new dataset of logical entailments for the purpose of measuring models\' ability to capture and exploit the structure of logical expressions against an entailment prediction task. We use this task to compare a series of architectures which are ubiquitous in the sequence-processing literature, in addition to a new model class---PossibleWorldNets---which computes entailment as a ``convolution over possible worlds\'\'. Results show that convolutional networks present the wrong inductive bias for this class of problems relative to LSTM RNNs, tree-structured neural networks outperform LSTM RNNs due to their enhanced ability to exploit the syntax of logic, and PossibleWorldNets outperform all benchmarks.</span>'}
{'title': 'GraphLog: A Benchmark for Measuring Logical Generalization in Graph Neural Networks', 'authors': ['Koustuv Sinha', 'Shagun Sodhani', 'Joelle Pineau', 'William L. Hamilton'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Ux5zdAir9-U&name=pdf', 'abstract': '</span><span class="note_content_value">Relational inductive biases have a key role in building learning agents that can generalize and reason in a compositional manner. While relational learning algorithms such as graph neural networks (GNNs) show promise, we do not understand their effectiveness to adapt to new tasks. In this work, we study the logical generalization capabilities of GNNs by designing a benchmark suite grounded in first-order logic. Our benchmark suite, GraphLog, requires that learning algorithms perform rule induction in different synthetic logics, represented as knowledge graphs. \nGraphLog consists of relation prediction tasks on 57 distinct procedurally generated logical worlds. We use GraphLog to evaluate GNNs in three different setups: single-task supervised learning, multi-task (with pretraining), and continual learning. Unlike previous benchmarks, GraphLog enables us to precisely control the logical relationship between the different worlds by controlling the underlying first-order logic rules. We find that models\' ability to generalize and adapt strongly correlates to the availability of diverse sets of logical rules during multi-task training. We also find the severe catastrophic forgetting effect in continual learning scenarios, and GraphLog provides a precise mechanism to control the distribution shift. Overall, our results highlight new challenges for the design of GNN models, opening up an exciting area of research in generalization using graph-structured data.</span>'}
{'title': 'Differentiable Meta-Logical Programming', 'authors': ['Zihan Ye', 'Hikaru Shindo', 'Devendra Singh Dhami', 'Kristian Kersting'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=iUCI3mQ8KkR&name=pdf', 'abstract': '</span><span class="note_content_value">Deep learning uses an increasing amount of computation and data to solve very specific problems. By stark contrast, \nhuman minds solve a wide range of problems using a fixed amount of computation and limited experience. One\nability that seems crucial to this kind of general intelligence is meta-reasoning, i.e., our ability to reason about reasoning. To make deep learning do more from less, we propose the differentiable logical meta interpreter (DLMI). The key idea is to realize a meta-interpreter using differentiable forward-chaining reasoning in first-order logic. This directly allows DLMI to reason and even learn about its own operations. This is different from performing object-level deep reasoning and learning, which refers in some way to entities external to the system. In contrast, DLMI is able to reflect or introspect, i.e., to shift from meta-reasoning to object-level reasoning and vice versa. Among many other experimental evaluations, we illustrate this behavior using the novel task of "repairing Kandinsky patterns", i.e., how to edit the objects in an image so that it agrees with a given logical concept.</span>'}
{'title': 'Teaching Temporal Logics to Neural Networks', 'authors': ['Christopher Hahn', 'Frederik Schmitt', 'Jens U. Kreber', 'Markus Norman Rabe', 'Bernd Finkbeiner'], 'Conference': 'ICLR 2021 Poster', 'date': 'Published: 12 Jan 2021, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=dOcQK-f4byz&name=pdf', 'abstract': '</span><span class="note_content_value">We study two fundamental questions in neuro-symbolic computing: can deep learning tackle challenging problems in logics end-to-end, and can neural networks learn the semantics of logics. In this work we focus on linear-time temporal logic (LTL), as it is widely used in verification. We train a Transformer on the problem to directly predict a solution, i.e. a trace, to a given LTL formula. The training data is generated with classical solvers, which, however, only provide one of many possible solutions to each formula. We demonstrate that it is sufficient to train on those particular solutions to formulas, and that Transformers can predict solutions even to formulas from benchmarks from the literature on which the classical solver timed out. Transformers also generalize to the semantics of the logics: while they often deviate from the solutions found by the classical solvers, they still predict correct solutions to most formulas.</span>'}
{'title': 'Skill Machines: Temporal Logic Composition in Reinforcement Learning', 'authors': ['Geraud Nangue Tasse', 'Devon Jarvis', 'Steven James', 'Benjamin Rosman'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=4Sp2v2DQcxX&name=pdf', 'abstract': '</span><span class="note_content_value">A major challenge in reinforcement learning is specifying tasks in a manner that is both interpretable and verifiable. One common approach is to specify tasks through reward machines---finite state machines that encode the task to be solved. We introduce skill machines, a representation that can be learned directly from these reward machines that encode the solution to such tasks. We propose a framework where an agent first learns a set of base skills in a reward-free setting, and then combines these skills with the learned skill machine to produce composite behaviours specified by any regular language, such as linear temporal logics. This provides the agent with the ability to map from complex logical task specifications to near-optimal behaviours zero-shot. We demonstrate our approach in both a tabular and high-dimensional video game environment, where an agent is faced with several of these complex, long-horizon tasks. Our results indicate that the agent is capable of satisfying extremely complex task specifications, producing near optimal performance with no further learning. Finally, we demonstrate that the performance of skill machines can be improved with regular off-policy reinforcement learning algorithms when optimal behaviours are desired.</span>'}
{'title': 'ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning', 'authors': ['Weihao Yu', 'Zihang Jiang', 'Yanfei Dong', 'Jiashi Feng'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HJgJtT4tvB&name=pdf', 'abstract': '</span><span class="note_content_value">Recent powerful pre-trained language models have achieved remarkable performance on most of the popular datasets for reading comprehension. It is time to introduce more challenging datasets to push the development of this field towards more comprehensive reasoning of text. In this paper, we introduce a new Reading Comprehension dataset requiring logical reasoning (ReClor) extracted from standardized graduate admission examinations. As earlier studies suggest, human-annotated datasets usually contain biases, which are often exploited by models to achieve high accuracy without truly understanding the text. In order to comprehensively evaluate the logical reasoning ability of models on ReClor, we propose to identify biased data points and separate them into EASY set while the rest as HARD set. Empirical results show that state-of-the-art models have an outstanding ability to capture biases contained in the dataset with high accuracy on EASY set. However, they struggle on HARD set with poor performance near that of random guess, indicating more research is needed to essentially enhance the logical reasoning ability of current models. </span>'}
{'title': 'Neural Logic Analogy Learning', 'authors': ['Yujia Fan', 'Yongfeng Zhang'], 'Conference': 'ICLR 2022 PAIR^2Struct Poster', 'date': 'Published: 25 Mar 2022, Last Modified: 23 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rGe-qsNrx5&name=pdf', 'abstract': '</span><span class="note_content_value">Letter-string analogy is an important analogy learning task which seems to be easy for humans but very challenging for machines.\nThe main idea behind current approaches to solving letter-string analogies is to design heuristic rules for extracting analogy structures and constructing analogy mappings. However, one key problem is that it is difficult to build a comprehensive and exhaustive set of analogy structures which can fully describe the subtlety of analogies. This problem makes current approaches unable to handle complicated letter-string analogy problems.\nIn this paper, we propose Neural lOgic ANalogy learning (Noan), which is a dynamic neural architecture driven by differentiable logic reasoning to solve analogy problems. Each analogy problem is converted into logical expressions consisting of logical variables and basic logical operations (AND, OR, and NOT). More specifically, Noan learns the logical variables as vector embeddings and learns each logical operation as a neural module. In this way, the model builds computational graph integrating neural network with logical reasoning to capture the internal logical structure of the input letter strings. The analogy learning problem then becomes a True/False evaluation problem of the logical expressions. Experiments show that our machine learning-based Noan approach outperforms state-of-the-art approaches on standard letter-string analogy benchmark datasets. </span>'}
{'title': 'NAIL: A Challenging Benchmark for Na\\"ive Logical Reasoning', 'authors': ['Xinbo Zhang', 'Changzhi Sun', 'Yue Zhang', 'Lei Li', 'Hao Zhou'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=djhu4DIZZHR&name=pdf', 'abstract': '</span><span class="note_content_value">Logical reasoning over natural text is an important capability towards human level intelligence.\nExisting datasets are either limited and inadequate to train and evaluate logical reasoning capability (e.g., LogiQA and ReClor),\nor not oriented for logical reasoning (e.g., SQuAD and HotpotQA).\nIn this paper, we focus on a specific category of logical reasoning, named \\emph{\\mytask}, and propose a new large scale benchmark, named \\mydata, targeted for learning and evaluating models\' capabilities towards \\mytask.\n \\mydata is source from  standardized exams such as Chinese National Civil Servants Examination and Law School Admission Test.\nFurthermore, to collect more data, we propose to imitate the example of standardized exams rather than designing them from scratch.\n\\mydata is available in both Chinese and English containing a total of <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>10</mn><mo>,</mo><mn>296</mn><mo>∗</mo><mn>2</mn></math></mjx-assistive-mml></mjx-container> instances.\nEmpirical results show that current state-of-the-art neural models struggle on \\mydata with very poor accuracy (the best result is 30.10\\% for \\mydata and 36.15\\% for Chinese \\mydata), while human experts can perform nearly 100\\% accuracy.\nFurther results indicate that human imitations can significantly help models learn logic from natural text.</span>'}
{'title': 'Fact-driven Logical Reasoning', 'authors': ['Siru Ouyang', 'Zhuosheng Zhang', 'hai zhao'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=gKWxifgJVP&name=pdf', 'abstract': '</span><span class="note_content_value">Recent years have witnessed an increasing interest in training machines with reasoning ability, which deeply relies on accurate, clearly presented clue forms that are usually modeled as entity-like knowledge in existing studies. However, in real hierarchical reasoning motivated machine reading comprehension, such one-sided modeling is insufficient for those indispensable local complete facts or events when only "global" knowledge is really paid attention to. Thus, in view of language being a complete knowledge/clue carrier, we propose a general formalism to support representing logic units by extracting backbone constituents of the sentence such as the subject-verb-object formed "facts", covering both global and local knowledge pieces that are necessary as the basis for logical reasoning. Beyond building the ad-hoc graphs, we propose a more general and convenient fact-driven approach to construct a supergraph on top of our newly defined fact units, benefiting from both sides of the connections between facts and internal knowledge such as concepts or actions inside a fact. Experiments on two challenging logical reasoning benchmarks show that our proposed model, \\textsc{Focal Reasoner}, outperforms the baseline models dramatically and achieves state-of-the-art results.</span>'}
{'title': 'Logical view on fairness of a binary classification task', 'authors': ['Serge Berger'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=MMiaF8KppTZ&name=pdf', 'abstract': '</span><span class="note_content_value">Ethical, Interpretable/Explainable, and Responsible AI are an active area of research and important social initiative. \n\nWe prove that, with no regards to data, fairness and trustworthiness are algorithmically undecidable for a basic machine learning task, the binary classification. Therefore, even the approach based on not only improving but fully solving the three usually assumed issues -- the insufficient quality of measurements, the complex consequences of (mis)measurements, and the limits of existing social theories -- is only heuristics. We show that, effectively, the fairness of a classifier is not even a (version of bias-variance) trade-off since it is a logical phenomenon. \nNamely, we reveal a language <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math></mjx-assistive-mml></mjx-container> and an <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi><mo>−</mo></math></mjx-assistive-mml></mjx-container>theory <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></mjx-assistive-mml></mjx-container> for binary classification task such that the very notion of loss is not expressible in the first-order logic formula in <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="3" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math></mjx-assistive-mml></mjx-container>. </span>'}
{'title': 'CLN2INV: Learning Loop Invariants with Continuous Logic Networks', 'authors': ['Gabriel Ryan', 'Justin Wong', 'Jianan Yao', 'Ronghui Gu', 'Suman Jana'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HJlfuTEtvB&name=pdf', 'abstract': '</span><span class="note_content_value">Program verification offers a framework for ensuring program correctness and therefore systematically eliminating different classes of bugs. Inferring loop invariants is one of the main challenges behind automated verification of real-world programs which often contain many loops. In this paper, we present the Continuous Logic Network (CLN), a novel neural architecture for automatically learning loop invariants directly from program execution traces. Unlike existing neural networks, CLNs can learn precise and explicit representations of formulas in Satisfiability Modulo Theories (SMT)  for loop invariants from program execution traces. We develop a new sound and complete semantic mapping for assigning SMT formulas to continuous truth values that allows CLNs to be trained efficiently. We use CLNs to implement a new inference system for loop invariants, CLN2INV, that significantly outperforms existing approaches on the popular Code2Inv dataset. CLN2INV is the first tool to solve all 124 theoretically solvable problems in the Code2Inv dataset. Moreover, CLN2INV takes only 1.1 second on average for each problem, which is 40 times faster than existing approaches. We further demonstrate that CLN2INV can even learn 12 significantly more complex loop invariants than the ones required for the Code2Inv dataset.</span>'}
{'title': 'Learning with Logical Constraints but without Shortcut Satisfaction', 'authors': ['Zenan Li', 'Zehua Liu', 'Yuan Yao', 'Jingwei Xu', 'Taolue Chen', 'Xiaoxing Ma', 'Jian L\\"{u}'], 'Conference': 'ICLR 2023 notable top 25%', 'date': 'Published: 01 Feb 2023, Last Modified: 24 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=M2unceRvqhh&name=pdf', 'abstract': '</span><span class="note_content_value">Recent studies have started to explore the integration of logical knowledge into deep learning via encoding logical constraints as an additional loss function. However, existing approaches tend to vacuously satisfy logical constraints through shortcuts, failing to fully exploit the knowledge. In this paper, we present a new framework for learning with logical constraints. Specifically, we address the shortcut satisfaction issue by introducing dual variables for logical connectives, encoding how the constraint is satisfied. We further propose a variational framework where the encoded logical constraint is expressed as a distributional loss that is compatible with the model\'s original training loss. The theoretical analysis shows that the proposed approach bears some nice properties, and the experimental evaluations demonstrate its superior performance in both model generalizability and constraint satisfaction.</span>'}
{'title': 'Transformers Implement First-Order Logic with Majority Quantifiers', 'authors': ['William Merrill', 'Ashish Sabharwal'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=W668diqwp4l&name=pdf', 'abstract': '</span><span class="note_content_value">Characterizing the implicit structure of the computation within neural networks is a foundational problem in the area of deep learning interpretability. Can their inner decision process be captured symbolically in some familiar logic? We show that any transformer neural network can be translated into an equivalent fixed-size first-order logic formula which may also use majority quantifiers. The idea is to simulate transformers with highly uniform threshold circuits and leverage known theoretical connections between circuits and logic. Our findings also reveal the surprising fact that the entire transformer computation can be reduced merely to the division of two (large) integers. While our results are most pertinent for transformers, they apply equally to a broader class of neural network architectures, namely those with a fixed-depth uniform computation graph made up of standard neural net components, which includes feedforward and convolutional networks.</span>'}
{'title': 'Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning', 'authors': ['Antonia Creswell', 'Murray Shanahan', 'Irina Higgins'], 'Conference': 'ICLR 2023 notable top 5%', 'date': 'Published: 01 Feb 2023, Last Modified: 01 Mar 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=3Pf3Wg6o-A4&name=pdf', 'abstract': '</span><span class="note_content_value">Large language models (LLMs) have been shown to be capable of impressive few-shot generalisation to new tasks. However, they still tend to perform poorly on multi-step logical reasoning problems. Here we carry out a comprehensive evaluation of LLMs on 46 tasks that probe different aspects of logical reasoning. We show that language models tend to perform fairly well at single step inference or entailment tasks, but struggle to chain together multiple reasoning steps to solve more complex problems. In light of this, we propose a Selection-Inference (SI) framework that exploits pre-trained LLMs as general processing modules, and alternates between selection and inference to generate a series of interpretable, casual reasoning steps leading to the final answer. We show that a 7B parameter LLM used within the SI framework in a 5-shot generalisation setting, with no fine-tuning, yields a performance improvement of over 100% compared to an equivalent vanilla baseline on a suite of 10 logical reasoning tasks. The same model in the same setting even outperforms a significantly larger 280B parameter baseline on the same suite of tasks. Moreover, answers produced by the SI framework are accompanied by a causal natural-language-based reasoning trace, which has important implications for the safety and trustworthiness of the system.</span>'}
{'title': 'Neural Probabilistic Logic Programming in Discrete-Continuous Domains', 'authors': ['Lennert De Smet', 'Pedro Zuidberg Dos Martires', 'Robin Manhaeve', 'Giuseppe Marra', 'Angelika Kimmig', 'Luc De Raedt'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=dyifcA9UuRo&name=pdf', 'abstract': '</span><span class="note_content_value">Neural-symbolic AI (NeSy) methods allow neural networks to exploit symbolic background knowledge. NeSy has been shown to aid learning in the limited data regime and to facilitate inference on out-of-distribution data. Neural probabilistic logic programming (NPLP) is a popular NeSy approach that integrates probabilistic models with neural networks and logic programming. A major limitation of current NPLP systems, such as DeepProbLog, is their restriction to discrete and finite probability distributions, e.g., binary random variables. To overcome this limitation, we introduce DeepSeaProbLog, an NPLP language that supports discrete and continuous random variables on (possibly) infinite and even uncountable domains. Our main contributions are 1) the introduction of DeepSeaProbLog and its semantics, 2) an implementation of DeepSeaProbLog that supports inference and gradient-based learning, and 3) an experimental evaluation of our approach.</span>'}
{'title': 'Neural Probabilistic Logic Programming in Discrete-Continuous Domains', 'authors': ['Lennert De Smet', 'Pedro Zuidberg Dos Martires', 'Robin Manhaeve', 'Giuseppe Marra', 'Angelika Kimmig', 'Luc De Raedt'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=dyifcA9UuRo&name=pdf', 'abstract': '</span><span class="note_content_value">Neural-symbolic AI (NeSy) methods allow neural networks to exploit symbolic background knowledge. NeSy has been shown to aid learning in the limited data regime and to facilitate inference on out-of-distribution data. Neural probabilistic logic programming (NPLP) is a popular NeSy approach that integrates probabilistic models with neural networks and logic programming. A major limitation of current NPLP systems, such as DeepProbLog, is their restriction to discrete and finite probability distributions, e.g., binary random variables. To overcome this limitation, we introduce DeepSeaProbLog, an NPLP language that supports discrete and continuous random variables on (possibly) infinite and even uncountable domains. Our main contributions are 1) the introduction of DeepSeaProbLog and its semantics, 2) an implementation of DeepSeaProbLog that supports inference and gradient-based learning, and 3) an experimental evaluation of our approach.</span>'}
{'title': 'An interpretable contrastive logical knowledge learning method for sentiment analysis', 'authors': ['Yulin Chen', 'Bo Yuan', 'Dongheng Chen', 'Dov Gabbay', 'Beishui Liao'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=9RDD2hefT94&name=pdf', 'abstract': '</span><span class="note_content_value">Current interpretable sentiment analysis (ISA) methods frequently underperform state-of-the-art models, and few of them cast light on the inner working of pre-trained models.  In this work, we fill the gap by addressing four key research challenges in ISA—knowledge acquisition, knowledge representation, knowledge learning and knowledge reasoning—in one unified framework. Theoretically, we propose a novel contrasitive logical knowledge learning (CLK) framework that can visualize the decisions made through deterministic Talmudic public announcement logic semantics. We apply CLK to current popular sentiment analysis models to obtain CLK based interpretable ones. Empirically, experimental results of both binary sentiment analysis tasks and fine-grained sentiment analysis tasks indicate that CLK can achieve an effective trade-off between accuracy and interpretability. Furthermore, we find that CLK can reduce the uncertainty of logical knowledge for discriminative labels by visualizing the learned feature representations and model output. Besides, we carry out a case study to investigate the fidelity of model interpretability through knowledge reasoning, which demonstrates that the explanations provided by our method are reasonable and consistent for sentiment analysis tasks. </span>'}
{'title': 'Logic-aware Pre-training of Language Models', 'authors': ['Siru Ouyang', 'Zhuosheng Zhang', 'hai zhao'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=p7Bfc_wsDtH&name=pdf', 'abstract': '</span><span class="note_content_value">Pre-trained language models (PrLMs) have been shown useful for enhancing a broad range of natural language understanding (NLU) tasks. However, the capacity for capturing logic relations in challenging NLU still remains a bottleneck even for state-of-the-art PrLM enhancement, which greatly stalls their reasoning abilities. To bridge the gap, we propose logic pre-training of language models to equip PrLMs with logical reasoning ability. To let logic pre-training perform on a clear, accurate, and generalized knowledge basis, we introduce \\textit{fact} instead of the plain language unit in previous PrLMs. The \\textit{fact} is extracted through syntactic parsing in avoidance of unnecessary complex knowledge injection. Meanwhile, it enables training logic-aware models to be conducted on a more general language text. To explicitly guide the PrLM to capture logic relations, three complementary self-supervised pre-training objectives are introduced: 1) logical structure completion to accurately capture fact-level logic from the original context, 2) logical path prediction on a logical graph to uncover global logic relationships among facts, 3) logical connectives masking to capture discourse-level for fact groups. We evaluate our model on a broad range of NLP tasks, including natural language inference, relation extraction, and machine reading comprehension with logical reasoning. Experimental results show that our model achieves significant performance in all the downstream tasks, especially in logical reasoning-related tasks. </span>'}
{'title': 'Neural Compositional Rule Learning for Knowledge Graph Reasoning', 'authors': ['Kewei Cheng', 'Nesreen Ahmed', 'Yizhou Sun'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=F8VKQyDgRVj&name=pdf', 'abstract': '</span><span class="note_content_value">Learning logical rules is critical to improving reasoning in KGs. This is due to their ability to provide logical and interpretable explanations when used for predictions, as well as their ability to generalize to other tasks, domains, and data. While recent methods have been proposed to learn logical rules, the majority of these methods are either restricted by their computational complexity and can not handle the large search space of large-scale KGs, or show poor generalization when exposed to data outside the training set. In this paper, we propose an end-to-end neural model for learning compositional logical rules called NCRL. NCRL detects the best compositional structure of a rule body, and breaks it into small compositions in order to infer the rule head. By recurrently merging compositions in the rule body with a recurrent attention unit, NCRL finally predicts a single rule head. Experimental results show that NCRL learns high-quality rules, as well as being generalizable. Specifically, we show that NCRL is scalable, efficient, and yields state-of-the-art results for knowledge graph completion on large-scale KGs. Moreover, we test NCRL for systematic generalization by learning to reason on small-scale observed graphs and evaluating on larger unseen ones.</span>'}
{'title': 'NeuralLog: a Neural Logic Language', 'authors': ['Victor Guimarães', 'Vitor Santos Costa'], 'Conference': 'ICLR 2021 Conference Withdrawn Submission', 'date': '28 Sept 2020 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rF2kJgYAr3&name=pdf', 'abstract': '</span><span class="note_content_value">Application domains that require considering relationships among objects which have real-valued attributes are becoming even more important. In this paper we propose NeuralLog, a first-order logic language that is compiled to a neural network. The main goal of NeuralLog is to bridge logic programming and deep learning, allowing advances in both fields to be combined in order to obtain better machine learning models. The main advantages of NeuralLog are: to allow neural networks to be defined as logic programs; and to be able to handle numeric attributes and functions. We compared NeuralLog with two distinct systems that use first-order logic to build neural networks. We have also shown that NeuralLog can learn link prediction and classification tasks, using the same theory as the compared systems, achieving better results for the area under the ROC curve in four datasets: Cora and UWCSE for link prediction; and Yelp and PAKDD15 for classification; and comparable results for link prediction in the WordNet dataset.</span>'}
{'title': 'RNNLogic: Learning Logic Rules for Reasoning on Knowledge Graphs', 'authors': ['Meng Qu', 'Junkun Chen', 'Louis-Pascal Xhonneux', 'Yoshua Bengio', 'Jian Tang'], 'Conference': 'ICLR 2021 Poster', 'date': 'Published: 12 Jan 2021, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=tGZu6DlbreV&name=pdf', 'abstract': '</span><span class="note_content_value">This paper studies learning logic rules for reasoning on knowledge graphs. Logic rules provide interpretable explanations when used for prediction as well as being able to generalize to other tasks, and hence are critical to learn. Existing methods either suffer from the problem of searching in a large search space (e.g., neural logic programming) or ineffective optimization due to sparse rewards (e.g., techniques based on reinforcement learning). To address these limitations, this paper proposes a probabilistic model called RNNLogic. RNNLogic treats logic rules as a latent variable, and simultaneously trains a rule generator as well as a reasoning predictor with logic rules. We develop an EM-based algorithm for optimization. In each iteration, the reasoning predictor is updated to explore some generated logic rules for reasoning. Then in the E-step, we select a set of high-quality rules from all generated rules with both the rule generator and reasoning predictor via posterior inference; and in the M-step, the rule generator is updated with the rules selected in the E-step. Experiments on four datasets prove the effectiveness of RNNLogic.</span>'}
{'title': 'Neural Temporal Logic Programming', 'authors': ['Karan Samel', 'Zelin Zhao', 'Binghong Chen', 'Shuang Li', 'Dharmashankar Subramanian', 'Irfan Essa', 'Le Song'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=i7h4M45tU8&name=pdf', 'abstract': '</span><span class="note_content_value">Events across a timeline are a common data representation, seen in different temporal modalities. Individual atomic events can occur in a certain temporal ordering to compose higher level composite events. Examples of a composite event are a patient\'s medical symptom or a baseball player hitting a home run, caused distinct temporal orderings of patient vitals and player movements respectively. Such salient composite events are provided as labels in temporal datasets and most works optimize models to predict these composite event labels directly. We focus uncovering the underlying atomic events and their relations that lead to the composite events within a noisy temporal data setting. We propose Neural Temporal Logic Programming (Neural TLP) which first learns implicit temporal relations between atomic events and then lifts logic rules for composite events, given only the composite events labels for supervision. This is done through efficiently searching through the combinatorial space of all temporal logic rules in an end-to-end differentiable manner. We evaluate our method on video and on healthcare data where it outperforms the baseline methods for rule discovery. </span>'}
{'title': 'Query2box: Reasoning over Knowledge Graphs in Vector Space Using Box Embeddings', 'authors': ['Hongyu Ren*', 'Weihua Hu*', 'Jure Leskovec'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=BJgr4kSFDS&name=pdf', 'abstract': '</span><span class="note_content_value">Answering complex logical queries on large-scale incomplete knowledge graphs (KGs) is a fundamental yet challenging task. Recently, a promising approach to this problem has been to embed KG entities as well as the query into a vector space such that entities that answer the query are embedded close to the query. However, prior work models queries as single points in the vector space, which is problematic because a complex query represents a potentially large set of its answer entities, but it is unclear how such a set can be represented as a single point. Furthermore, prior work can only handle queries that use conjunctions (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2227"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∧</mo></math></mjx-assistive-mml></mjx-container>) and existential quantifiers (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c2203"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">∃</mi></math></mjx-assistive-mml></mjx-container>). Handling queries with logical disjunctions (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2228"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∨</mo></math></mjx-assistive-mml></mjx-container>) remains an open problem. Here we propose query2box, an embedding-based framework for reasoning over arbitrary queries with <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="3" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2227"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∧</mo></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="4" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2228"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∨</mo></math></mjx-assistive-mml></mjx-container>, and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="5" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c2203"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">∃</mi></math></mjx-assistive-mml></mjx-container> operators in massive and incomplete KGs. Our main insight is that queries can be embedded as boxes (i.e., hyper-rectangles), where a set of points inside the box corresponds to a set of answer entities of the query. We show that conjunctions can be naturally represented as intersections of boxes and also prove a negative result that handling disjunctions would require embedding with dimension proportional to the number of KG entities. However, we show that by transforming queries into a Disjunctive Normal Form, query2box is capable of handling arbitrary logical queries with <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="6" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2227"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∧</mo></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="7" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2228"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∨</mo></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="8" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c2203"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">∃</mi></math></mjx-assistive-mml></mjx-container> in a scalable manner. We demonstrate the effectiveness of query2box on two large KGs and show that query2box achieves up to 25% relative improvement over the state of the art.\n</span>'}
{'title': 'Learning a Meta-Solver for Syntax-Guided Program Synthesis', 'authors': ['Xujie Si', 'Yuan Yang', 'Hanjun Dai', 'Mayur Naik', 'Le Song'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': 'Published: 20 Dec 2018, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Syl8Sn0cK7&name=pdf', 'abstract': '</span><span class="note_content_value">We study a general formulation of program synthesis called syntax-guided synthesis(SyGuS) that concerns synthesizing a program that follows a given grammar and satisfies a given logical specification. Both the logical specification and the grammar have complex structures and can vary from task to task, posing significant challenges for learning across different tasks. Furthermore, training data is often unavailable for domain specific synthesis tasks. To address these challenges, we propose a meta-learning framework that learns a transferable policy from only weak supervision. Our framework consists of three components: 1) an encoder, which embeds both the logical specification and grammar at the same time using a graph neural network; 2) a grammar adaptive policy network which enables learning a transferable policy; and 3) a reinforcement learning algorithm that jointly trains the embedding and adaptive policy. We evaluate the framework on 214 cryptographic circuit synthesis tasks. It solves 141 of them in the out-of-box solver setting, significantly outperforming a similar search-based approach but without learning, which solves only 31. The result is comparable to two state-of-the-art classical synthesis engines, which solve 129 and 153 respectively. In the meta-solver setting, the framework can efficiently adapt to unseen tasks and achieves speedup ranging from 2x up to 100x.</span>'}
{'title': 'Learning Language Representations with Logical Inductive Bias', 'authors': ['Jianshu Chen'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rGeZuBRahju&name=pdf', 'abstract': '</span><span class="note_content_value">Transformer architectures have achieved great success in solving natural language tasks, which learn strong language representations from large-scale unlabeled texts. In this paper, we seek to go further beyond and explore a new logical inductive bias for better language representation learning. Logic reasoning is known as a formal methodology to reach answers from given knowledge and facts. Inspired by such a view, we develop a novel neural architecture named FOLNet (First-Order Logic Network), to encode this new inductive bias. We construct a set of neural logic operators as learnable Horn clauses, which are further forward-chained into a fully differentiable neural architecture (FOLNet). Interestingly, we find that the self-attention module in transformers can be composed by two of our neural logic operators, which probably explains their strong reasoning performance. Our proposed FOLNet has the same input and output interfaces as other pretrained models and thus could be pretrained/finetuned by using similar losses. It also allows FOLNet to be used in a plug-and-play manner when replacing other pretrained models. With our logical inductive bias, the same set of ``logic deduction skills\'\' learned through pretraining are expected to be equally capable of solving diverse downstream tasks. For this reason, FOLNet learns language representations that have much stronger transfer capabilities. Experimental results on several language understanding tasks show that our pretrained FOLNet model outperforms the existing strong transformer-based approaches.</span>'}
{'title': 'Weakly Supervised Knowledge Transfer with Probabilistic Logical Reasoning for Object Detection', 'authors': ['Martijn Oldenhof', 'Adam Arany', 'Yves Moreau', 'Edward De Brouwer'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 01 Mar 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=4yqxDCbzS98&name=pdf', 'abstract': '</span><span class="note_content_value">Training object detection models usually requires instance-level annotations, such as the positions and labels of all objects present in each image. Such supervision is unfortunately not always available and, more often, only image-level information is provided, also known as weak supervision. \nRecent works have addressed this limitation by leveraging knowledge from a richly annotated domain. However, the scope of weak supervision supported by these approaches has been very restrictive, preventing them to use all available information. In this work, we propose ProbKT, a framework based on probabilistic logical reasoning to train object detection models with arbitrary types of weak supervision. We empirically show on different datasets that using all available information is beneficial as our ProbKT leads to significant improvement on target domain and better generalisation compared to existing baselines. We also showcase the ability of our approach to handle complex logic statements as supervision signal.</span>'}
{'title': 'Using Logical Specifications of Objectives in Multi-Objective Reinforcement Learning', 'authors': ['Kolby Nottingham', 'Anand Balakrishnan', 'Jyotirmoy Deshmukh', 'Connor Christopherson', 'David Wingate'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rJeuMREKwS&name=pdf', 'abstract': '</span><span class="note_content_value">In the multi-objective reinforcement learning (MORL) paradigm, the relative importance of each environment objective is often unknown prior to training, so agents must learn to specialize their behavior to optimize different combinations of environment objectives that are specified post-training. These are typically linear combinations, so the agent is effectively parameterized by a weight vector that describes how to balance competing environment objectives. However, many real world behaviors require non-linear combinations of objectives. Additionally, the conversion between desired behavior and weightings is often unclear.\nIn this work, we explore the use of a language based on propositional logic with quantitative semantics--in place of weight vectors--for specifying non-linear behaviors in an interpretable way. We use a recurrent encoder to encode logical combinations of objectives, and train a MORL agent to generalize over these encodings. We test our agent in several grid worlds with various objectives and show that our agent can generalize to many never-before-seen specifications with performance comparable to single policy baseline agents. We also demonstrate our agent\'s ability to generate meaningful policies when presented with novel specifications and quickly specialize to novel specifications.</span>'}
{'title': 'Neural Markov Logic Networks', 'authors': ['Giuseppe Marra', 'Ondřej Kuželka'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SkeGvaEtPr&name=pdf', 'abstract': '</span><span class="note_content_value">We introduce Neural Markov Logic Networks (NMLNs), a statistical relational learning system that borrows ideas from Markov logic. Like Markov Logic Networks (MLNs), NMLNs are an exponential-family model for modelling distributions over possible worlds, but unlike MLNs, they do not rely on explicitly specified first-order logic rules. Instead, NMLNs learn an implicit representation of such rules as a neural network that acts as a potential function on fragments of the relational structure. Interestingly, any MLN can be represented as an NMLN. Similarly to recently proposed Neural theorem provers (NTPs) (Rocktaschel at al. 2017), NMLNs can exploit embeddings of constants but, unlike NTPs, NMLNs work well also in their absence. This is extremely important for predicting in settings other than the transductive one. We showcase the potential of NMLNs on knowledge-base completion tasks and on generation of molecular (graph) data.</span>'}
{'title': 'KETG: A Knowledge Enhanced Text Generation Framework', 'authors': ['Yan Cui', 'Xi Chen', 'Jiang Qian', 'Bojin Zhuang', 'Shaojun Wang', 'Jing Xiao'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=xPw-dr5t1RH&name=pdf', 'abstract': '</span><span class="note_content_value">Embedding logical knowledge information into text generation is a challenging NLP task. In this paper, we propose a knowledge enhanced text generation (KETG) framework, which incorporates both the knowledge and associated text corpus to address logicality and diversity in text generation. Specifically, we validate our framework on rhetorical text generation from our newly built rhetoric knowledge graph. Experiments show that our framework outperforms baseline models such as Transformer and GPT-2, on rhetorical type control, semantic comprehensibility and diversity.</span>'}
{'title': 'Efficient Probabilistic Logic Reasoning with Graph Neural Networks', 'authors': ['Yuyu Zhang', 'Xinshi Chen', 'Yuan Yang', 'Arun Ramamurthy', 'Bo Li', 'Yuan Qi', 'Le Song'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rJg76kStwH&name=pdf', 'abstract': '</span><span class="note_content_value">Markov Logic Networks (MLNs), which elegantly combine logic rules and probabilistic graphical models, can be used to address many knowledge graph problems. However, inference in MLN is computationally intensive, making the industrial-scale application of MLN very difficult. In recent years, graph neural networks (GNNs) have emerged as efficient and effective tools for large-scale graph problems. Nevertheless, GNNs do not explicitly incorporate prior logic rules into the models, and may require many labeled examples for a target task. In this paper, we explore the combination of MLNs and GNNs, and use graph neural networks for variational inference in MLN. We propose a GNN variant, named ExpressGNN, which strikes a nice balance between the representation power and the simplicity of the model. Our extensive experiments on several benchmark datasets demonstrate that ExpressGNN leads to effective and efficient probabilistic logic reasoning.</span>'}
{'title': 'Learn to Explain Efficiently via Neural Logic Inductive Learning', 'authors': ['Yuan Yang', 'Le Song'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SJlh8CEYDB&name=pdf', 'abstract': '</span><span class="note_content_value">The capability of making interpretable and self-explanatory decisions is essential for developing responsible machine learning systems. In this work, we study the learning to explain the problem in the scope of inductive logic programming (ILP). We propose Neural Logic Inductive Learning (NLIL), an efficient differentiable ILP framework that learns first-order logic rules that can explain the patterns in the data. In experiments, compared with the state-of-the-art models, we find NLIL is able to search for rules that are x10 times longer while remaining x3 times faster. We also show that NLIL can scale to large image datasets, i.e. Visual Genome, with 1M entities.</span>'}
{'title': 'DL2: Training and Querying Neural Networks with Logic', 'authors': ['Marc Fischer', 'Mislav Balunovic', 'Dana Drachsler-Cohen', 'Timon Gehr', 'Ce Zhang', 'Martin Vechev'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=H1faSn0qY7&name=pdf', 'abstract': '</span><span class="note_content_value">We present DL2, a system for training and querying neural networks with logical constraints. The key idea is to translate these constraints into a differentiable loss with desirable mathematical properties and to then either train with this loss in an iterative manner or to use the loss for querying the network for inputs subject to the constraints. We empirically demonstrate that DL2 is effective in both training and querying scenarios, across a range of constraints and data sets.</span>'}
{'title': 'The Logical Expressiveness of Graph Neural Networks', 'authors': ['Pablo Barceló', 'Egor V. Kostylev', 'Mikael Monet', 'Jorge Pérez', 'Juan Reutter', 'Juan Pablo Silva'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=r1lZ7AEKvB&name=pdf', 'abstract': '</span><span class="note_content_value">The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.</span>'}
{'title': 'Neural Disjunctive Normal Form: Vertically Integrating Logic With Deep Learning For Classification', 'authors': ['Jialin Lu', 'Martin Ester'], 'Conference': 'ICLR 2021 Conference Withdrawn Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=nMefdZyJ7ie&name=pdf', 'abstract': '</span><span class="note_content_value">We present Neural Disjunctive Normal Form (Neural DNF), a hybrid neuro- symbolic classifier that vertically integrates propositional logic with a deep neural network. Here, we aim at a vertical integration of logic and deep learning: we utilize the ability of deep neural networks as feature extractors to extract intermediate representation from data, and then a Disjunctive Normal Form (DNF) module to perform logical rule-based classification; we also seek this integration to be tight that these two normally-incompatible modules can be learned in an end-to-end manner, for which we propose the BOAT algorithm.\nCompared with standard deep classifiers which use a linear model or variants of additive model as the classification head, Neural DNF provides a new choice of model based on logic rules. It offers interpretability via an explicit symbolic representation, strong model expressity, and a different type of model inductive bias. Neural DNF is particularly suited for certain tasks that require some logical composition and provides extra interpretability.</span>'}
{'title': 'DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases', 'authors': ['Donghan Yu', 'Sheng Zhang', 'Patrick Ng', 'Henghui Zhu', 'Alexander Hanbo Li', 'Jun Wang', 'Yiqun Hu', 'William Yang Wang', 'Zhiguo Wang', 'Bing Xiang'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 14 Apr 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=XHc5zRPxqV9&name=pdf', 'abstract': '</span><span class="note_content_value">Question answering over knowledge bases (KBs) aims to answer natural language questions with factual information such as entities and relations in KBs. Previous methods either generate logical forms that can be executed over KBs to obtain final answers or predict answers directly. Empirical results show that the former often produces more accurate answers, but it suffers from  non-execution issues due to potential syntactic and semantic errors in the generated logical forms. In this work, we propose a novel framework DecAF that jointly generates both logical forms and direct answers, and then combines the merits of them to get the final answers. Moreover, different from most of the previous methods, DecAF is based on simple free-text retrieval without relying on any entity linking tools --- this simplification eases its adaptation to different datasets. DecAF achieves new state-of-the-art accuracy on WebQSP, FreebaseQA, and GrailQA benchmarks, while getting competitive results on the ComplexWebQuestions benchmark.</span>'}
{'title': 'Neural Methods for Logical Reasoning over Knowledge Graphs', 'authors': ['Alfonso Amayuelas', 'Shuai Zhang', 'Xi Susie Rao', 'Ce Zhang'], 'Conference': 'ICLR 2022 Poster', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=tgcAoUVHRIB&name=pdf', 'abstract': '</span><span class="note_content_value">Reasoning is a fundamental problem for computers and deeply studied in Artificial Intelligence. In this paper, we specifically focus on answering multi-hop logical queries on Knowledge Graphs (KGs). This is a complicated task because, in real world scenarios, the graphs tend to be large and incomplete. Most previous works have been unable to create models that accept full First-Order Logical (FOL) queries, which includes negative queries, and have only been able to process a limited set of query structures. Additionally, most methods present logic operators that can only perform the logical operation they are made for. We introduce a set of models that use Neural Networks to create one-point vector embeddings to answer the queries. The versatility of neural networks allows the framework to  handle FOL queries with Conjunction, Disjunction and Negation operators. We demonstrate experimentally the performance of our models through extensive experimentation on well-known benchmarking datasets. Besides having more versatile operators, the models achieve a 10% relative increase over best performing state of the art and more than 30% over the original method based on single-point vector embeddings.</span>'}
{'title': 'Logical Activation Functions: Logit-space equivalents of Boolean Operators', 'authors': ['Scott C Lowe', 'Robert Earle', "Jason d'Eon", 'Thomas Trappenberg', 'Sageev Oore'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Ck_iw4jMC4l&name=pdf', 'abstract': '</span><span class="note_content_value">Neuronal representations within artificial neural networks are commonly understood as logits, representing the log-odds score of presence (versus absence) of features within the stimulus. Under this interpretation, we can derive the probability <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2229"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo>∩</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> that a pair of independent features are both present in the stimulus from their logits. By converting the resulting probability back into a logit, we obtain a logit-space equivalent of the AND operation. However, since this function involves taking multiple exponents and logarithms, it is not well suited to be directly used within neural networks. We thus constructed an efficient approximation named <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mtext class="mjx-n"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c4E"></mjx-c><mjx-c class="mjx-c44"></mjx-c></mjx-mtext><mjx-script style="vertical-align: -0.153em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c4C"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mtext>AND</mtext><mtext>AIL</mtext></msub></math></mjx-assistive-mml></mjx-container> (the AND operator Approximate for Independent Logits) utilizing only comparison and addition operations, which can be deployed as an activation function in neural networks. Like MaxOut, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mtext class="mjx-n"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c4E"></mjx-c><mjx-c class="mjx-c44"></mjx-c></mjx-mtext><mjx-script style="vertical-align: -0.153em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c4C"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mtext>AND</mtext><mtext>AIL</mtext></msub></math></mjx-assistive-mml></mjx-container> is a generalization of ReLU to two-dimensions. Additionally, we constructed efficient approximations of the logit-space equivalents to the OR and XNOR operators. We deployed these new activation functions, both in isolation and in conjunction, and demonstrated their effectiveness on a variety of tasks including image classification, transfer learning, abstract reasoning, and compositional zero-shot learning.</span>'}
{'title': 'Generalisation in Lifelong Reinforcement Learning through Logical Composition', 'authors': ['Geraud Nangue Tasse', 'Steven James', 'Benjamin Rosman'], 'Conference': 'ICLR 2022 Poster', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ZOcX-eybqoL&name=pdf', 'abstract': '</span><span class="note_content_value">We leverage logical composition in reinforcement learning to create a framework that enables an agent to autonomously determine whether a new task can be immediately solved using its existing abilities, or whether a task-specific skill should be learned. In the latter case, the proposed algorithm also enables the agent to learn the new task faster by generating an estimate of the optimal policy. Importantly, we provide two main theoretical results: we bound the performance of the transferred policy on a new task, and we give bounds on the necessary and sufficient number of tasks that need to be learned throughout an agent\'s lifetime to generalise over a distribution. We verify our approach in a series of experiments, where we perform transfer learning both after learning a set of base tasks, and after learning an arbitrary set of tasks. We also demonstrate that, as a side effect of our transfer learning approach, an agent can produce an interpretable Boolean expression of its understanding of the current task. Finally, we demonstrate our approach in the full lifelong setting where an agent receives tasks from an unknown distribution. Starting from scratch, an agent is able to quickly generalise over the task distribution after learning only a few tasks, which are sub-logarithmic in the size of the task space.</span>'}
{'title': 'Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic', 'authors': ['Zijun Wu', 'Zi Xuan Zhang', 'Atharva Naik', 'Zhijian Mei', 'Mauajama Firdaus', 'Lili Mou'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Hu4r-dedqR0&name=pdf', 'abstract': '</span><span class="note_content_value">Natural language inference (NLI) aims to determine the logical relationship between two sentences, such as Entailment, Contradiction, and Neutral. In recent years, deep learning models have become a prevailing approach to NLI, but they lack interpretability and explainability. In this work, we address the explainability of NLI by weakly supervised logical reasoning, and propose an Explainable Phrasal Reasoning (EPR) approach. Our model first detects phrases as the semantic unit and aligns corresponding phrases in the two sentences. Then, the model predicts the NLI label for the aligned phrases, and induces the sentence label by fuzzy logic formulas. Our EPR is almost everywhere differentiable and thus the system can be trained end to end. In this way, we are able to provide explicit explanations of phrasal logical relationships in a weakly supervised manner. We further show that such reasoning results help textual explanation generation.</span>'}
{'title': 'Interpretable Reinforcement Learning With Neural Symbolic Logic', 'authors': ['Zhihao Ma', 'Yuzheng Zhuang', 'Paul Weng', 'Dong Li', 'Kun Shao', 'Wulong Liu', 'Hankz Hankui Zhuo', 'Jianye HAO'], 'Conference': 'ICLR 2021 Conference Withdrawn Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=M_gk45ItxIp&name=pdf', 'abstract': '</span><span class="note_content_value">Recent progress in deep reinforcement learning (DRL) can be largely attributed to the use of neural networks.  However, this black-box approach fails to explain the learned policy in a human understandable way.  To address this challenge and improve the transparency, we introduce symbolic logic into DRL and propose a Neural Symbolic Reinforcement Learning framework, in which states and actions are represented in an interpretable way using first-order logic.  This framework features a relational reasoning module, which performs on task-level in Hierarchical Reinforcement Learning, enabling end-to-end learning with prior symbolic knowledge.  Moreover, interpretability is enabled by extracting the logical rules learned by the reasoning module in a symbolic rule space, providing explainability on task level. Experimental results demonstrate better interpretability of subtasks, along with competing performance compared with existing approaches.</span>'}
{'title': 'DEEP ADAPTIVE SEMANTIC LOGIC (DASL): COMPILING DECLARATIVE KNOWLEDGE INTO DEEP NEURAL NETWORKS', 'authors': ['Karan Sikka', 'Andrew Silberfarb', 'John Byrnes', 'Indranil Sur', 'Ed Chow', 'Ajay Divakaran', 'Richard Rohwer'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=mnj-9lYJgu&name=pdf', 'abstract': '</span><span class="note_content_value">We introduce Deep Adaptive Semantic Logic (DASL), a novel framework for automating the generation of deep neural networks that incorporates user-provided formal knowledge to improve learning from data. We provide formal semantics that demonstrate that our knowledge representation captures all of first order logic and that finite sampling from infinite domains converges to correct truth values. DASL’s representation improves on prior neuro-symbolic work by avoiding vanishing gradients, allowing deeper logical structure, and enabling richer interactions between the knowledge and learning components. We illustrate DASL through a toy problem in which we add structure to an image classification problem and demonstrate that knowledge of that structure\nreduces data requirements by a factor of 1000. We apply DASL on a visual relationship detection task and demonstrate that the addition of commonsense knowledge improves performance by 10.7% in a data scarce setting.</span>'}
{'title': 'Reinforcement Logic Rule Learning for Temporal Point Processes', 'authors': ['Chao Yang', 'Lu Wang', 'Kun Gao', 'Shuang Li'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ynD_LAMwar2&name=pdf', 'abstract': '</span><span class="note_content_value">We aim to learn a set of temporal logic rules to explain the occurrence of temporal events. Leveraging the temporal point process modeling and learning framework, the rule content and rule weights are jointly learned by maximizing the likelihood of the observed noisy event sequences. The proposed algorithm alternates between a master problem, where the rule weights are updated, and a subproblem, where a new rule is searched and included. The formulated master problem is convex and relatively easy to solve, whereas the subproblem requires searching the huge combinatorial rule predicate and relationship space. To tackle this challenge, we propose a neural search policy to learn to generate the new rule content as a sequence of actions. The policy parameters will be trained end-to-end using the reinforcement learning framework, where the reward signals can be efficiently queried by evaluating the subproblem objective. The trained policy can be used to generate new rules, and moreover, the well-trained policies can be directly transferred to other tasks to speed up the rule searching procedure in the new task. We evaluate our methods on both synthetic and real-world datasets, obtaining promising results.</span>'}
{'title': 'A Simple Loss Function for Convergent Algorithm Synthesis using RNNs', 'authors': ['Alexandre Salle', 'Shervin Malmasi'], 'Conference': 'Submitted to Tiny Papers @ ICLR 2023', 'date': '01 Mar 2023 (modified: 05 Jun 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=WaAJ883AqiY&name=pdf', 'abstract': '</span><span class="note_content_value">Running a Recurrent Neural Network (RNN) over the same input multiple times, or iterative reasoning, enables logical extrapolation, where a model can be run on problems larger than the models were trained on. The loss function used to train these networks has a profound impact on their extrapolation ability. In this paper, we propose using a simple loss function called the Delta Loss (Salle &amp; Prates, 2019). We show that the Delta Loss, like the state-of-the-art Progressive Loss (Bansal et al., 2022), leads to convergent algorithm synthesis, but with a simpler formulation, increased training efficiency, and greater robustness.</span>'}
{'title': 'Leveraging Constraint Logic Programming for Neural Guided Program Synthesis', 'authors': ['Lisa Zhang', 'Gregory Rosenblatt', 'Ethan Fetaya', 'Renjie Liao', 'William E. Byrd', 'Raquel Urtasun', 'Richard Zemel'], 'Conference': 'ICLR 2018 Workshop Submission', 'date': '12 Feb 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HJIHtIJvz&name=pdf', 'abstract': '</span><span class="note_content_value">We present a method for solving Programming by Example (PBE) problems that tightly integrates a neural network with a constraint logic programming system called miniKanren. Internally, miniKanren searches for a program that satisfies the recursive constraints imposed by the provided examples. Our Recurrent Neural Network (RNN) model uses these constraints as input to score candidate programs. We show evidence that using our method to guide miniKanren’s search is a promising approach to solving PBE problems.</span>'}
{'title': 'Robustness against Relational Adversary', 'authors': ['Yizhen Wang', 'Xiaozhu Meng', 'Mihai Christodorescu', 'Somesh Jha', 'Ke Wang'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=XtPeiGx6BwC&name=pdf', 'abstract': '</span><span class="note_content_value">Test-time adversarial attacks have posed serious challenges to the robustness of machine-learning models, and in many settings the adversarial perturbation need not be bounded by small lp-norms.  Motivated by the semantics-preserving attacks in vision and security domain, we investigate relational adversaries, a broad class of attackers who create adversarial examples that are in a reﬂexive-transitive closure of a logical relation. We analyze the conditions for robustness and propose normalize-and-predict – a learning framework with provable robustness guarantee. We compare our approach with adversarial training and derive an uniﬁed framework that provides beneﬁts of both approaches. Guided by our theoretical ﬁndings, we apply our framework to malware detection and image classiﬁcation. Results of both tasks show that attacks using relational adversaries frequently fool existing models, but our uniﬁed framework can signiﬁcantly enhance their robustness.\n</span>'}
{'title': 'Rule Mining in Feature Space', 'authors': ['Stefano Teso', 'Andrea Passerini'], 'Conference': 'Submitted to ICLR 2017', 'date': '04 Nov 2016 (modified: 21 Jul 2022)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=H1_QSDqxl&name=pdf', 'abstract': '</span><span class="note_content_value">Relational embeddings have emerged as an excellent tool for inferring novel facts\nfrom partially observed knowledge bases. Recently, it was shown that some\nclasses of embeddings can also be exploited to perform a simplified form of rule\nmining. By interpreting logical conjunction as a form of composition between re-\nlation embeddings, simplified logical theories can be mined directly in the space\nof latent representations. In this paper, we present a method to mine full-fledged\nlogical theories, which are significantly more expressive, by casting the semantics\nof the logical operators to the space of the embeddings. In order to extract relevant\nrules in the space of relation compositions we borrow sparse reconstruction pro-\ncedures from the field of compressed sensing. Our empirical analysis showcases\nthe advantages of our approach.</span>'}
{'title': 'Is the Deep Model Representation Sparse and Symbolic with Causal Patterns?', 'authors': ['Jie Ren', 'Mingjie Li', 'Qirui Chen', 'Huiqi Deng', 'Quanshi Zhang'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=-0jbdOhFn4g&name=pdf', 'abstract': '</span><span class="note_content_value">This paper aims to show that the inference logic of a deep model can be faithfully approximated as a sparse, symbolic causal graph. Such a causal graph potentially bridges the gap between connectionism and symbolism. To this end, the faithfulness of the causal graph is theoretically guaranteed, because we show that the causal graph can well mimic the model\'s output on an exponential number of different masked samples. Besides, such a causal graph can be further simplified and re-written as an And-Or graph (AOG), which explains the logical relationship between interactive concepts encoded by the deep model, without losing much explanation accuracy. The code will be released when the paper is accepted.</span>'}
{'title': 'HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving', 'authors': ['Cezary Kaliszyk', 'François Chollet', 'Christian Szegedy'], 'Conference': 'ICLR 2017 Poster', 'date': 'Published: 21 Jul 2022, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ryuxYmvel&name=pdf', 'abstract': '</span><span class="note_content_value">Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n</span>'}
{'title': 'RulE: Neural-Symbolic Knowledge Graph Reasoning with Rule Embedding', 'authors': ['Xiaojuan Tang', 'Song-Chun Zhu', 'Yitao Liang', 'Muhan Zhang'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=UBSPGUwjNV&name=pdf', 'abstract': '</span><span class="note_content_value">Knowledge graph (KG) reasoning is an important problem for knowledge graphs. It predicts missing links by reasoning on existing facts. Knowledge graph embedding (KGE) is one of the most popular methods to address this problem. It embeds entities and relations into low-dimensional vectors and uses the learned entity/relation embeddings to predict missing facts. However, KGE only uses zeroth-order (propositional) logic to encode existing triplets (e.g., ``Alice is Bob\'s wife."); it is unable to leverage first-order (predicate) logic to represent generally applicable logical \\textbf{rules} (e.g., ``<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c2200"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c3A"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mtext class="mjx-n"><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mtext class="mjx-n"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-mtext class="mjx-n"><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi><mjx-mtext class="mjx-n"><mjx-c class="mjx-c2019"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c66"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi><mjx-mtext class="mjx-n"><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mtext class="mjx-n"><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext><mjx-mtext class="mjx-n"><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mtext class="mjx-n"><mjx-c class="mjx-c2019"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c></mjx-mtext></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">∀</mi><mi>x</mi><mo>,</mo><mi>y</mi><mo data-mjx-texclass="PUNCT">:</mo><mi>x</mi><mtext>&nbsp;</mtext><mtext>is</mtext><mtext>&nbsp;</mtext><mi>y</mi><mtext>’s wife</mtext><mo stretchy="false">→</mo><mi>y</mi><mtext>&nbsp;</mtext><mtext>is</mtext><mtext>&nbsp;</mtext><mi>x</mi><mtext>’s husband</mtext></math></mjx-assistive-mml></mjx-container>\'\'). On the other hand, traditional rule-based KG reasoning methods usually rely on hard logical rule inference, making it brittle and hardly competitive with KGE. In this paper, we propose RulE, a novel and principled framework to represent and model logical rules and triplets. RulE jointly represents entities, relations and logical rules in a unified embedding space. By learning an embedding for each logical rule, RulE can perform logical rule inference in a soft way and give a confidence score to each grounded rule, similar to how KGE gives each triplet a confidence score. Compared to KGE alone, RulE allows injecting prior logical rule information into the embedding space, which improves the generalization of knowledge graph embedding. Besides, the learned confidence scores of rules improve the logical rule inference process by softly controlling the contribution of each rule, which alleviates the brittleness of logic. We evaluate our method with link prediction tasks. Experimental results on multiple benchmark KGs demonstrate the effectiveness of RulE.</span>'}
{'title': 'Learning Heuristics for Automated Reasoning through Reinforcement Learning', 'authors': ['Gil Lederman', 'Markus N. Rabe', 'Edward A. Lee', 'Sanjit A. Seshia'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HkeyZhC9F7&name=pdf', 'abstract': '</span><span class="note_content_value">We demonstrate how to learn efficient heuristics for automated reasoning algorithms through deep reinforcement learning. We focus on backtracking search algorithms for quantified Boolean logics, which already can solve formulas of impressive size - up to 100s of thousands of variables. The main challenge is to find a representation of these formulas that lends itself to making predictions in a scalable way. For challenging problems, the heuristic learned through our approach reduces execution time by a factor of 10 compared to the existing handwritten heuristics.</span>'}
{'title': 'The Logical Options Framework', 'authors': ['Brandon Araki', 'Xiao Li', 'Kiran Vodrahalli', 'Jonathan DeCastro', 'J Micah Fry', 'Daniela Rus'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=IbFcpYnwCvd&name=pdf', 'abstract': '</span><span class="note_content_value">Learning composable policies for environments with complex rules and tasks is a challenging problem. We introduce a hierarchical reinforcement learning framework called the Logical Options Framework (LOF) that learns policies that are satisfying, optimal, and composable. LOF efficiently learns policies that satisfy tasks by representing the task as an automaton and integrating it into learning and planning. We provide and prove conditions under which LOF will learn satisfying, optimal policies. And lastly, we show how LOF\'s learned policies can be composed to satisfy unseen tasks with only 10-50 retraining steps. We evaluate LOF on four tasks in discrete and continuous domains.</span>'}
{'title': 'Truth Table Deep Convolutional Neural Network, A New SAT-Encodable Architecture - Application To Complete Robustness', 'authors': ['Adrien Benamira', 'Thomas Peyrin', 'Bryan Hooi'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=jJJWwrMrEsx&name=pdf', 'abstract': '</span><span class="note_content_value">\nWith the expanding role of neural networks, the need for formal verification of their behavior, interpretability and human post-processing has become critical in many applications. In 2018, it has been shown that Binary Neural Networks (BNNs) have an equivalent representation in boolean logic and can be formally analyzed using logical reasoning tools such as SAT or MaxSAT solvers. This formulation is powerful as it allows us to address a vast range of questions: existential, probabilistic, explanation generation, etc. However, to date, only BNNs can be transformed into a SAT formula and their strong binary constraints limit their natural accuracy. Moreover, the corresponding SAT conversion method intrinsically leads to formulas with a large number of variables and clauses, impeding interpretability as well as formal verification scalability. In this work, we introduce Truth Table Deep Convolutional Neural Networks (TT-DCNNs), a new family of SAT-encodable models featuring real-valued weights and real intermediate values as well as a highly interpretable conversion method. The TT-DCNN architecture enables for the first time all the logical classification rules to be extracted from a performant neural network which can be then easily interpreted by anyone familiar with the domain. Therefore, this allows integrating human knowledge in post-processing as well as enumerating all possible inputs/outputs prior to deployment in production. We believe our new architecture paves the way between eXplainability AI (XAI) and formal verification. First, we experimentally show that TT-DCNNs offer a better tradeoff between natural accuracy and formal verification than BNNs. Then, in the robustness verification setting, we demonstrate that TT-DCNNs outperform the verifiable accuracy of BNNs with a comparable computation time. Finally, we also drastically decrease the number of clauses and variables, enabling the usage of general SAT solvers and exact model counting solvers. Our developed real-valued network has general applications and we believe that its demonstrated robustness constitutes a suitable response to the rising demand for functional formal verification. </span>'}
{'title': 'Quantum and Translation Embedding for Knowledge Graph Completion', 'authors': ['Panfeng Chen', 'Yisong Wang', 'Renyan Feng', 'Xiaomin Yu', 'Quan Yu'], 'Conference': 'ICLR 2021 Conference Withdrawn Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Z2_djlm7DmA&name=pdf', 'abstract': '</span><span class="note_content_value">Knowledge Graph Completion (KGC) mainly devotes to link predicting for an entity pair in Knowledge Graph (KG) according to known facts. In this work, we present a novel model for this end. In this model, Quantum and Translation Embedding are used as components for logical and structural feature capturing in the same vector subspace, respectively. The two components have synergy with each other and achieve impressive performance at low cost which is close to the efficient model TransE. Surprisingly, the performance on challenging datasets such as fb15k237 and WN18RR is up to 94.89% and 92.79% in metric Hits@1 while the dimension of embedding is only 4 in the process of training. The insight of this work enlightens the notion of dense feature model design for KGC which is a new alternative to Deep Neural networks (DNN) in this task or even a better choice.</span>'}
{'title': 'PRIMA: Planner-Reasoner Inside a Multi-task Reasoning Agent', 'authors': ['Daoming Lyu', 'Bo Liu', 'Jianshu Chen'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=B6YDcqpMk30&name=pdf', 'abstract': '</span><span class="note_content_value">In multi-task reasoning (MTR), an agent can solve multiple tasks via (first-order) logic reasoning. This capability is essential for human-like intelligence due to its strong generalizability and simplicity for handling multiple tasks. However, a major challenge in developing effective MTR is the intrinsic conflict between reasoning capability and efficiency. An MTR-capable agent must master a large set of "skills\'\' to perform diverse tasks, but executing a particular task at the inference stage requires only a small subset of immediately relevant skills. How can we maintain broad reasoning capability yet efficient specific-task performance? To address this problem, we propose a Planner-Reasoner framework capable of state-of-the-art MTR capability and high efficiency. The Reasoner models shareable (first-order) logic deduction rules, from which the Planner selects a subset to compose into efficient reasoning paths. The entire model is trained in an end-to-end manner using deep reinforcement learning, and experimental studies over various domains validate its effectiveness.</span>'}
{'title': 'Can recursive neural tensor networks learn logical reasoning?', 'authors': ['Samuel R. Bowman'], 'Conference': 'ICLR 2014 conference submission', 'date': '24 Dec 2013', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=4diyarNwq84_Q&name=pdf', 'abstract': '</span><span class="note_content_value">Recursive neural network models and their accompanying vector representations for words have seen success in an array of increasingly semantically sophisticated tasks, but almost nothing is known about their ability to accurately capture the aspects of linguistic meaning that are necessary for interpretation or reasoning. To evaluate this, I train a recursive model on a new corpus of constructed examples of logical reasoning in short sentences, like the inference of \'some animal walks\' from \'some dog walks\' or \'some cat walks,\' given that dogs and cats are animals. The results are promising for the ability of these models to capture logical reasoning, but the model tested here appears to learn representations that are quite specific to the templatic structures of the problems seen in training, and that generalize beyond them only to a limited degree.</span>'}
{'title': 'Logical Message Passing Networks with One-hop Inference on Atomic Formulas', 'authors': ['Zihao Wang', 'Yangqiu Song', 'Ginny Wong', 'Simon See'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 12 Apr 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SoyOsp7i_l&name=pdf', 'abstract': '</span><span class="note_content_value">Complex Query Answering (CQA) over Knowledge Graphs (KGs) has attracted a lot of attention to potentially support many applications. Given that KGs are usually incomplete, neural models are proposed to answer the logical queries by parameterizing set operators with complex neural networks. However, such methods usually train neural set operators with a large number of entity and relation embeddings from the zero, where whether and how the embeddings or the neural set operators contribute to the performance remains not clear. In this paper, we propose a simple framework for complex query answering that decomposes the KG embeddings from neural set operators. We propose to represent the complex queries into the query graph. On top of the query graph, we propose the Logical Message Passing Neural Network (LMPNN) that connects the local one-hop inferences on atomic formulas to the global logical reasoning for complex query answering. We leverage existing effective KG embeddings to conduct one-hop inferences on atomic formulas, the results of which are regarded as the messages passed in LMPNN. The reasoning process over the overall logical formulas is turned into the forward pass of LMPNN that incrementally aggregates local information to finally predict the answers\' embeddings. The complex logical inference across different types of queries will then be learned from training examples based on the LMPNN architecture. Theoretically, our query-graph represenation is more general than the prevailing operator-tree formulation, so our approach applies to a broader range of complex KG queries. Empirically, our approach yields the new state-of-the-art neural CQA model. Our research bridges the gap between complex KG query answering tasks and the long-standing achievements of knowledge graph representation learning. Our implementation can be found at <a href="https://github.com/HKUST-KnowComp/LMPNN" target="_blank" rel="nofollow">https://github.com/HKUST-KnowComp/LMPNN</a>.</span>'}
{'title': 'Weighted Clock Logic Point Process', 'authors': ['Ruixuan Yan', 'Yunshi Wen', 'Debarun Bhattacharjya', 'Ronny Luss', 'Tengfei Ma', 'Achille Fokoue', 'Anak Agung Julius'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 28 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=YfUICnZMwk7&name=pdf', 'abstract': '</span><span class="note_content_value">Datasets involving multivariate event streams are prevalent in numerous applications. We present a novel framework for modeling temporal point processes called clock logic neural networks (CLNN) which learn weighted clock logic (wCL) formulas as interpretable temporal rules by which some events promote or inhibit other events. Specifically, CLNN models temporal relations between events using conditional intensity rates informed by a set of wCL formulas, which are more expressive than related prior work. Unlike conventional approaches of searching for generative rules through expensive combinatorial optimization, we design smooth activation functions for components of wCL formulas that enable a continuous relaxation of the discrete search space and efficient learning of wCL formulas using gradient-based methods. Experiments on synthetic datasets manifest our model\'s ability to recover the ground-truth rules and improve computational efficiency. In addition, experiments on real-world datasets show that our models perform competitively when compared with state-of-the-art models. </span>'}
{'title': 'Going Deeper with Spiking Neurons: Towards Binary Outputs of Deep Logic Spiking Neural Network', 'authors': ['Tao Sun', 'Li Yuan', 'Yibing Song', 'Wei Fang', 'Yanqi Chen', 'Munan Ning', 'Haonan Qiu', 'Zhengyu Ma', 'Yonghong Tian'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=gR5yMO1pRRc&name=pdf', 'abstract': '</span><span class="note_content_value">For the simulation of spikes in biological neurons, a natural fit is the spiking neural networks, which produce binary outputs from spiking neurons. SNN receives arising investigations for its high biological plausibility and efficient inference on neuromorphic chips. However, it is still a challenge to train SNNs with more than 50 layers due to the gradient vanishing problem caused by the spiking neuron layers, which greatly prevents SNNs from going deeper to obtain higher performance. In this paper, we first investigate the variants of spiking residual blocks and find that deep SNNs with binary outputs can not be constructed by simply replacing the activation function in the existing residual structure in ANN with the spiking neuron layer. We thus propose a logic spiking network (LSN) to benefit deep SNN training. Our LSN contains two functionally distinct branches, a structure inspired by excitatory and inhibitory pathways followed by a logical operation for binary spike outputs. We demonstrate both theoretically and experimentally that LSN can implement identity mapping as well as overcome the vanishing gradient problem. Our LSN can be expanded by more than 100 layers with binary outputs and performs favorably against existing spiking ResNet and its variants. Our proposed LSN achieved 94.68% accuracy on CIFAR10, 71.86% accuracy on ImageNet, and 75.1% accuracy on CIFAR10-DVS.</span>'}
{'title': 'Explaining Point Processes by Learning Interpretable Temporal Logic Rules', 'authors': ['Shuang Li', 'Mingquan Feng', 'Lu Wang', 'Abdelmajid Essofi', 'Yufeng Cao', 'Junchi Yan', 'Le Song'], 'Conference': 'ICLR 2022 Poster', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=P07dq7iSAGr&name=pdf', 'abstract': '</span><span class="note_content_value">We propose a principled method to learn a set of human-readable logic rules to explain temporal point processes. \nWe assume that the generative mechanisms underlying the temporal point processes are governed by a set of first-order temporal logic rules, as a compact representation of domain knowledge. Our method formulates the rule discovery process from noisy event data as a maximum likelihood problem, and designs an efficient and tractable branch-and-price algorithm to progressively search for new rules and expand existing rules. The proposed algorithm alternates between the rule generation stage and the rule evaluation stage, and uncovers the most important collection of logic rules within a fixed time limit for both synthetic and real event data. In a real healthcare application, we also had human experts (i.e., doctors) verify the learned temporal logic rules and provide further improvements. These expert-revised interpretable rules lead to a point process model which outperforms previous state-of-the-arts for symptom prediction, both in their occurrence times and types. </span>'}
{'title': 'Does Entity Abstraction Help Generative Transformers Reason?', 'authors': ['Nicolas Gontier', 'Siva Reddy', 'Christopher Pal'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rSI-tyrv-ni&name=pdf', 'abstract': '</span><span class="note_content_value">Pre-trained language models (LMs) often struggle to reason logically or generalize in a compositional fashion. Recent work suggests that incorporating external entity knowledge can improve language models\' abilities to reason and generalize. However the effect of explicitly providing entity abstraction remains unclear, especially with recent studies suggesting that pre-trained models already encode some of that knowledge in their parameters. In this work, we study the utility of incorporating entity type abstractions into pre-trained Transformers and test these methods on three different NLP tasks requiring different forms of logical reasoning: (1) compositional language understanding with text-based relational reasoning (CLUTRR), (2) multi-hop question answering (HotpotQA), and (3) conversational question answering (CoQA). We propose and empirically explore three different ways to add such abstraction: (i) as additional input embeddings, (ii) as a separate sequence to encode, and (iii) as an auxiliary prediction task for the model. Overall our analysis demonstrate that models with abstract entity knowledge performs slightly better than without it. However, our experiments also show that the benefits strongly depend on the technique used and the task at hand. The best abstraction aware model achieved an overall accuracy of 88.8% compared to the baseline model achieving 62.3% on CLUTRR. In addition, abstraction-aware models showed improved compositional generalization in both interpolation and extrapolation settings. However, for HotpotQA and CoQA, we find that F1 scores improve by only 0.5% on average. Our results suggest that the benefits of explicit abstraction could be very significant in formally defined logical reasoning settings such as CLUTRR, but point to the notion that explicit abstraction is likely less beneficial for NLP tasks having less formal logical structure.</span>'}
{'title': 'AUTOMATA GUIDED HIERARCHICAL REINFORCEMENT LEARNING FOR ZERO-SHOT SKILL COMPOSITION', 'authors': ['Xiao Li', 'Yao Ma', 'Calin Belta'], 'Conference': 'ICLR 2018 Conference Blind Submission', 'date': '15 Feb 2018 (modified: 15 Feb 2018)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=BJgVaG-Ab&name=pdf', 'abstract': '</span><span class="note_content_value">An obstacle that prevents the wide adoption of (deep) reinforcement learning (RL) in control systems is its need for a large number of interactions with the environment in order to master a skill. The learned skill usually generalizes poorly across domains and re-training is often necessary when presented with a new task. We present a framework that combines techniques in \\textit{formal methods} with \\textit{hierarchical reinforcement learning} (HRL). The set of techniques we provide allows for the convenient specification of tasks with logical expressions, learns hierarchical policies (meta-controller and low-level controllers) with well-defined intrinsic rewards using any RL methods and is able to construct new skills from existing ones without additional learning. We evaluate the proposed methods in a simple grid world simulation as well as simulation on a Baxter robot. </span>'}
{'title': 'Agent, do you see it now? systematic generalisation in deep reinforcement learning', 'authors': ['Borja G. León', 'Murray Shanahan', 'Francesco Belardinelli'], 'Conference': 'ALOE@ICLR2022', 'date': 'Published: 23 Apr 2022, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=BHHG47Db8-q&name=pdf', 'abstract': '</span><span class="note_content_value">Systematic generalisation, i.e., the algebraic capacity to understand and execute unseen tasks by combining already known primitives, is one of the most desirable features for a computational model. Good adaptation to novel tasks in open-ended settings rely heavily on the ability of agents to reuse their past experience and recombine meaningful learning pieces to tackle new goals. In this work, we analyse how the architecture of convolutional layers impacts on the performance of autonomous agents when generalising to zero-shot, unseen tasks while executing human instructions. Our findings suggest that the convolutional architecture that is correctly suited to the environment the agent will interact with, may be of greater importance than having a generic convolutional network trained in the given environment.</span>'}
{'title': 'Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas', 'authors': ['Fei Wang', 'Zhanfu Yang', 'Ziliang Chen', 'Guannan Wei', 'Tiark Rompf'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SJl28R4YPr&name=pdf', 'abstract': '</span><span class="note_content_value">It is valuable yet remains challenging to apply neural networks in logical reasoning tasks. Despite some successes witnessed in learning SAT (Boolean Satisfiability) solvers for propositional logic via Graph Neural Networks (GNN),  there haven\'t been any successes in learning solvers for more complex predicate logic. In this paper, we target the QBF (Quantified Boolean Formula) satisfiability problem, the complexity of which is in-between propositional logic and predicate logic, and investigate the feasibility of learning GNN-based solvers and GNN-based heuristics for the cases with a universal-existential quantifier alternation (so-called 2QBF problems).\n\nWe conjecture, with empirical support, that GNNs have certain limitations in learning 2QBF solvers, primarily due to the inability to reason about a set of assignments. Then we show the potential of GNN-based heuristics in CEGAR-based solvers and explore the interesting challenges to generalize them to larger problem instances. In summary, this paper provides a comprehensive surveying view of applying GNN-based embeddings to 2QBF problems and aims to offer insights in applying machine learning tools to more complicated symbolic reasoning problems.\n</span>'}
{'title': 'DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer', 'authors': ['Joseph Suarez', 'Justin Johnson', 'L. Fei-Fei'], 'Conference': 'ICLR 2018 Conference Blind Submission', 'date': '15 Feb 2018 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HypkN9yRW&name=pdf', 'abstract': '</span><span class="note_content_value">We present a generic dynamic architecture that employs a problem specific differentiable forking mechanism to leverage discrete logical information about the problem data structure. We adapt and apply our model to CLEVR Visual Question Answering, giving rise to the DDRprog architecture; compared to previous approaches, our model achieves higher accuracy in half as many epochs with five times fewer learnable parameters. Our model directly models underlying question logic using a recurrent controller that jointly predicts and executes functional neural modules; it explicitly forks subprocesses to handle logical branching. While FiLM and other competitive models are static architectures with less supervision, we argue that inclusion of program labels enables learning of higher level logical operations -- our architecture achieves particularly high performance on questions requiring counting and integer comparison. We further demonstrate the generality of our approach though DDRstack -- an application of our method to reverse Polish notation expression evaluation in which the inclusion of a stack assumption allows our approach to generalize to long expressions, significantly outperforming an LSTM with ten times as many learnable parameters.</span>'}
{'title': 'Metagross: Meta Gated Recursive Controller Units for Sequence Modeling', 'authors': ['Yi Tay', 'Yikang Shen', 'Alvin Chan', 'Yew Soon Ong'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Sygn20VtwH&name=pdf', 'abstract': '</span><span class="note_content_value">This paper proposes Metagross (Meta Gated Recursive Controller), a new neural sequence modeling unit. Our proposed unit is characterized by recursive parameterization of its gating functions, i.e., gating mechanisms of Metagross are controlled by instances of itself, which are repeatedly called in a recursive fashion. This can be interpreted as a form of meta-gating and recursively parameterizing a recurrent model. We postulate that our proposed inductive bias provides modeling benefits pertaining to learning with inherently hierarchically-structured sequence data (e.g., language, logical or music tasks). To this end, we conduct extensive experiments on recursive logic tasks (sorting, tree traversal, logical inference), sequential pixel-by-pixel classification, semantic parsing, code generation, machine translation and polyphonic music modeling, demonstrating the widespread utility of the proposed approach, i.e., achieving state-of-the-art (or close) performance on all tasks.</span>'}
{'title': 'Hyper-SAGNN: a self-attention based graph neural network for hypergraphs', 'authors': ['Ruochi Zhang', 'Yuesong Zou', 'Jian Ma'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ryeHuJBtPH&name=pdf', 'abstract': '</span><span class="note_content_value">Graph representation learning for hypergraphs can be utilized to extract patterns among higher-order interactions that are critically important in many real world problems. Current approaches designed for hypergraphs, however, are unable to handle different types of hypergraphs and are typically not generic for various learning tasks. Indeed, models that can predict variable-sized heterogeneous hyperedges have not been available. Here we develop a new self-attention based graph neural network called Hyper-SAGNN applicable to homogeneous and heterogeneous hypergraphs with variable hyperedge sizes. We perform extensive evaluations on multiple datasets, including four benchmark network datasets and two single-cell Hi-C datasets in genomics. We demonstrate that Hyper-SAGNN significantly outperforms state-of-the-art methods on traditional tasks while also achieving great performance on a new task called outsider identification. We believe that Hyper-SAGNN will be useful for graph representation learning to uncover complex higher-order interactions in different applications. </span>'}
{'title': 'Unveiling Transformers with LEGO: A Synthetic Reasoning Task', 'authors': ['Yi Zhang', 'Arturs Backurs', 'Sebastien Bubeck', 'Ronen Eldan', 'Suriya Gunasekar', 'Tal Wagner'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=1jDN-RfQfrb&name=pdf', 'abstract': '</span><span class="note_content_value">We propose a synthetic reasoning task, LEGO (Learning Equality and Group Operations), that encapsulates the problem of following a chain of reasoning, and we study how the Transformer architectures learn this task. We pay special attention to data effects such as pretraining (on seemingly unrelated NLP tasks) and dataset composition (e.g., differing chain length at training and test time), as well as architectural variants such as weight-tied layers or adding convolutional components. We study how the trained models eventually succeed at the task, and in particular, we are able to understand (to some extent) some of the attention heads as well as how the information flows in the network. Based on these observations we propose a hypothesis that here pretraining helps for LEGO tasks due to certain structured attention patterns, and we experimentally verify this hypothesis. We also observe that in some data regimes the trained transformer finds ``shortcut" solutions to follow the chain of reasoning, which impedes the model\'s robustness, and moreover we propose ways to prevent it. Motivated by our findings on structured attention patterns, we propose to replace certain attention heads with hardcoded patterns. This architectural change significantly reduces Flops and maintains or even improves the model\'s performance at large-scale pretraining.</span>'}
{'title': 'Metagross: Meta Gated Recursive Controller Units for Sequence Modeling', 'authors': ['Yi Tay', 'Yikang Shen', 'Alvin Chan', 'Yew Soon Ong'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Sygn20VtwH&name=pdf', 'abstract': '</span><span class="note_content_value">This paper proposes Metagross (Meta Gated Recursive Controller), a new neural sequence modeling unit. Our proposed unit is characterized by recursive parameterization of its gating functions, i.e., gating mechanisms of Metagross are controlled by instances of itself, which are repeatedly called in a recursive fashion. This can be interpreted as a form of meta-gating and recursively parameterizing a recurrent model. We postulate that our proposed inductive bias provides modeling benefits pertaining to learning with inherently hierarchically-structured sequence data (e.g., language, logical or music tasks). To this end, we conduct extensive experiments on recursive logic tasks (sorting, tree traversal, logical inference), sequential pixel-by-pixel classification, semantic parsing, code generation, machine translation and polyphonic music modeling, demonstrating the widespread utility of the proposed approach, i.e., achieving state-of-the-art (or close) performance on all tasks.</span>'}
{'title': 'CARD: Certifiably Robust Machine Learning Pipeline via Domain Knowledge Integration', 'authors': ['Jiawei Zhang', 'Linyi Li', 'Bo Li'], 'Conference': 'ICLR 2022 Conference Withdrawn Submission', 'date': '28 Sept 2021 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=roaZrQMGsd6&name=pdf', 'abstract': '</span><span class="note_content_value">The advent of ubiquitous machine learning (ML) has led to exciting revolution in computing today. However, recent studies have shown that ML, especially deep neural networks (DNNs), are vulnerable to adversarial examples, which are able to mislead DNNs with carefully crafted stealthy perturbations. So far, many defense approaches have been proposed against such adversarial attacks, both empirically and theoretically. Though effective under certain conditions, existing empirical defenses are usually found vulnerable against new attacks; existing certified defenses are only able to certify robustness against limited perturbation radius. As current pure data-driven defenses have reached a bottleneck towards certifiably robust ML, in this paper we propose a certifiably robust ML pipeline CARD, aiming to integrate exogenous information, such as domain knowledge, as logical rules with ML models to improve the certified robustness. Intuitively, domain knowledge (e.g., cat belongs to the animal category) will prevent attacks that violate these knowledge rules, and it is also challenging to construct adaptive attacks satisfying such pre-defined logical relationships. In particular, we express the domain knowledge as first-order logic rules and embed these logic rules in a probabilistic graphical model. We then prove that such a probabilistic graphical model can be mapped to a 1-layer NN for efficient training. We conduct extensive experiments on several high-dimensional datasets and show that our proposed CARD achieves the state-of-the-art certified robustness.</span>'}
{'title': 'Learning Continuous Semantic Representations of Symbolic Expressions', 'authors': ['Miltiadis Allamanis', 'Pankajan Chanthirasegaran', 'Pushmeet Kohli', 'Charles Sutton'], 'Conference': 'ICLR 2017 Invite to Workshop', 'date': '04 Nov 2016 (modified: 21 Jul 2022)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=B1vRTeqxg&name=pdf', 'abstract': '</span><span class="note_content_value">The question of how procedural knowledge is represented and inferred is a fundamental problem in machine learning and artificial intelligence. Recent work on program induction has proposed neural architectures, based on abstractions like stacks, Turing machines, and interpreters,  that operate on abstract computational machines or on execution traces. But the recursive abstraction that is central to procedural knowledge is perhaps most naturally represented by symbolic representations that have syntactic structure, such as logical expressions and source code. Combining abstract, symbolic reasoning with continuous neural reasoning is a grand challenge of representation learning. As a step in this direction, we propose a new architecture, called neural equivalence networks, for the problem of learning continuous semantic representations of mathematical and logical expressions. These networks are trained to represent semantic equivalence, even of expressions that are syntactically very different. The challenge is that semantic representations must be computed in a syntax-directed manner, because semantics is compositional, but at the same time, small changes in syntax can lead to very large changes in semantics, which can be difficult for continuous neural architectures. We perform an exhaustive evaluation  on the task of checking equivalence on a highly diverse class of symbolic algebraic and boolean expression types, showing that our model significantly outperforms existing architectures.\n</span>'}
{'title': 'Generating Plannable Lifted Action Models for Visually Generated Logical Predicates', 'authors': ['Masataro Asai'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=tJz_QUXB7C&name=pdf', 'abstract': '</span><span class="note_content_value">We propose FOSAE++, an unsupervised end-to-end neural system that generates a compact discrete state transition model (dynamics / action model) from raw visual observations. Our representation can be exported to Planning Domain Description Language (PDDL), allowing symbolic state-of-the-art classical planners to perform high-level task planning on raw observations. FOSAE++ expresses states and actions in First Order Logic (FOL), a superset of so-called object-centric representation. It is the first unsupervised neural system that fully supports FOL in PDDL action modeling, while existing systems are limited to continuous, propositional, or property-based representations, and/or require manually labeled input for actions/predicates/propositions.</span>'}
{'title': 'Thinking Deeper With Recurrent Networks: Logical Extrapolation Without Overthinking', 'authors': ['Arpit Bansal', 'Avi Schwarzschild', 'Eitan Borgnia', 'Zeyad Emam', 'Furong Huang', 'Micah Goldblum', 'Tom Goldstein'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=kDF4Owotj5j&name=pdf', 'abstract': '</span><span class="note_content_value">Classical machine learning systems perform best when they are trained and tested on the same distribution, and they lack a mechanism to increase model power after training is complete. In contrast, recent work has observed that recurrent networks can exhibit logical extrapolation; models trained only on small/simple problem instances can extend their abilities to solve large/complex instances at test time simply by performing more recurrent iterations.  While preliminary results on these ``thinking systems\'\' are promising, existing recurrent systems, when iterated many times, often collapse rather than improve their performance.  This ``overthinking\'\' phenomenon has prevented thinking systems from scaling to particularly large and complex problems. In this paper, we design a recall architecture that keeps an explicit copy of the problem instance in memory so that it cannot be forgotten.  We also propose an incremental training routine that prevents the model from learning behaviors that are specific to iteration number and instead pushes it to learn behaviors that can be repeated indefinitely. Together, these design choices encourage models to converge to a steady state solution rather than deteriorate when many iterations are used. These innovations help to tackle the overthinking problem and boost deep thinking behavior on each of the benchmark tasks proposed by  Schwarzschild et al. (2021a).</span>'}
{'title': 'Global Explainability of GNNs via Logic Combination of Learned Concepts', 'authors': ['Steve Azzolin', 'Antonio Longa', 'Pietro Barbiero', 'Pietro Lio', 'Andrea Passerini'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=OTbRTIY4YS&name=pdf', 'abstract': '</span><span class="note_content_value">While instance-level explanation of GNN is a well-studied problem with plenty of approaches being developed, providing a global explanation for the behaviour of a GNN is much less explored, despite its potential in interpretability and debugging. Existing solutions either simply list local explanations for a given class, or generate a synthetic prototypical graph with maximal score for a given class, completely missing any combinatorial aspect that the GNN could have learned.\nIn this work, we propose GLGExplainer (Global Logic-based GNN Explainer), the first Global Explainer capable of generating explanations as arbitrary Boolean combinations of learned graphical concepts. GLGExplainer is a fully differentiable architecture that takes local explanations as inputs and combines them into a logic formula over graphical concepts, represented as clusters of local explanations. \nContrary to existing solutions, GLGExplainer provides accurate and human-interpretable global explanations that are perfectly aligned with ground-truth explanations (on synthetic data) or match existing domain knowledge (on real-world data). Extracted formulas are faithful to the model predictions, to the point of providing insights into some occasionally incorrect rules learned by the model, making GLGExplainer a promising diagnostic tool for learned GNNs.</span>'}
{'title': 'TILP: Differentiable Learning of Temporal Logical Rules on Knowledge Graphs', 'authors': ['Siheng Xiong', 'Yuan Yang', 'Faramarz Fekri', 'James Clayton Kerce'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 27 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=_X12NmQKvX&name=pdf', 'abstract': '</span><span class="note_content_value">Compared with static knowledge graphs, temporal knowledge graphs (tKG), which can capture the evolution and change of information over time, are more realistic and general. However, due to the complexity that the notion of time introduces to the learning of the rules, an accurate graph reasoning, e.g., predicting new links between entities, is still a difficult problem. In this paper, we propose TILP, a differentiable framework for temporal logical rules learning. By designing a constrained random walk mechanism and the introduction of temporal operators, we ensure the efficiency of our model. We present temporal features modeling in tKG, e.g., recurrence, temporal order, interval between pair of relations, and duration, and incorporate it into our learning process. We compare TILP with state-of-the-art methods on two benchmark datasets. We show that our proposed framework can improve upon the performance of baseline methods while providing interpretable results. In particular, we consider various scenarios in which training samples are limited, data is biased, and the time range between training and inference are different. In all these cases, TILP works much better than the state-of-the-art methods.</span>'}
{'title': 'Learning Heuristics for Quantified Boolean Formulas through Reinforcement Learning', 'authors': ['Gil Lederman', 'Markus Rabe', 'Sanjit Seshia', 'Edward A. Lee'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=BJluxREKDB&name=pdf', 'abstract': '</span><span class="note_content_value">We demonstrate how to learn efficient heuristics for automated reasoning algorithms for quantified Boolean formulas through deep reinforcement learning. We focus on a backtracking search algorithm, which can already solve formulas of impressive size - up to hundreds of thousands of variables. The main challenge is to find a representation of these formulas that lends itself to making predictions in a scalable way. For a family of challenging problems, we learned a heuristic that solves significantly more formulas compared to the existing handwritten heuristics.</span>'}
{'title': 'Question Generation using a Scratchpad Encoder', 'authors': ['Ryan Y Benmalek', 'Madian Khabsa', 'Suma Desu', 'Claire Cardie', 'Michele Banko'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HklAhi09Y7&name=pdf', 'abstract': '</span><span class="note_content_value">In this paper we introduce the Scratchpad Encoder, a novel addition to the sequence to sequence (seq2seq) framework and explore its effectiveness in generating natural language questions from a given logical form. The Scratchpad encoder enables the decoder at each time step to modify all the encoder outputs, thus using the encoder as a "scratchpad" memory to keep track of what has been generated so far and to guide future generation. Experiments on a knowledge based question generation dataset show that our approach generates more fluent and expressive questions according to quantitative metrics and human judgments.</span>'}
{'title': 'ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning', 'authors': ['Olga Golovneva', 'Moya Peng Chen', 'Spencer Poff', 'Martin Corredor', 'Luke Zettlemoyer', 'Maryam Fazel-Zarandi', 'Asli Celikyilmaz'], 'Conference': 'ICLR 2023 notable top 25%', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=xYlJRpzZtsY&name=pdf', 'abstract': '</span><span class="note_content_value">Large language models show improved downstream task performance when prompted to generate step-by-step reasoning to justify their final answers. These reasoning steps greatly improve model interpretability and verification, but objectively studying their correctness (independent of the final answer) is difficult without reliable methods for automatic evaluation. We simply do not know how often the stated reasoning steps actually support the final end task predictions. In this work, we present ROSCOE, a suite of interpretable, unsupervised automatic scores that improve and extend previous text generation evaluation metrics. To evaluate ROSCOE against baseline metrics, we design a typology of reasoning errors and collect synthetic and human evaluation scores on commonly used reasoning datasets. In contrast with existing metrics, ROSCOE can measure semantic consistency, logicality, informativeness, fluency, and factuality — among other traits — by leveraging properties of step-by-step rationales. We empirically verify the strength of our metrics on five human annotated and six programmatically perturbed diagnostics datasets - covering a diverse set of tasks that require reasoning skills and show that ROSCOE can consistently outperform baseline metrics.</span>'}
{'title': 'Iterative Circuit Repair Against Formal Specifications', 'authors': ['Matthias Cosler', 'Frederik Schmitt', 'Christopher Hahn', 'Bernd Finkbeiner'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SEcSahl0Ql&name=pdf', 'abstract': '</span><span class="note_content_value">We present a deep learning approach for repairing sequential circuits against formal specifications given in linear-time temporal logic (LTL). Given a defective circuit and its formal specification, we train Transformer models to output circuits that satisfy the corresponding specification. We propose a separated hierarchical Transformer for multimodal representation learning of the formal specification and the circuit. We introduce a data generation algorithm that enables generalization to more complex specifications and out-of-distribution datasets. In addition, our proposed repair mechanism significantly improves the automated synthesis of circuits from LTL specifications with Transformers. It improves the state-of-the-art by <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>6.8</mn></math></mjx-assistive-mml></mjx-container> percentage points on held-out instances and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>11.8</mn></math></mjx-assistive-mml></mjx-container> percentage points on an out-of-distribution dataset from the annual reactive synthesis competition.</span>'}
{'title': 'Characterizing the Accuracy/Complexity Landscape of Explanations of Deep Networks through Knowledge Extraction', 'authors': ['Simon Odense', "Artur d'Avila Garcez"], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ByEtPiAcY7&name=pdf', 'abstract': '</span><span class="note_content_value">Knowledge extraction techniques are used to convert neural networks into symbolic descriptions with the objective of producing more comprehensible learning models. The central challenge is to find an explanation which is more comprehensible than the original model while still representing that model faithfully. The distributed nature of deep networks has led many to believe that the hidden features of a neural network cannot be explained by logical descriptions simple enough to be understood by humans, and that decompositional knowledge extraction should be abandoned in favour of other methods. In this paper we examine this question systematically by proposing a knowledge extraction method using \\textit{M-of-N} rules which allows us to map the complexity/accuracy landscape of rules describing hidden features in a Convolutional Neural Network (CNN). Experiments reported in this paper show that the shape of this landscape reveals an optimal trade off between comprehensibility and accuracy, showing that each latent variable has an optimal \\textit{M-of-N} rule to describe its behaviour. We find that the rules with optimal tradeoff in the first and final layer have a high degree of explainability whereas the rules with the optimal tradeoff in the second and third layer are less explainable. The results shed light on the feasibility of rule extraction from deep networks, and point to the value of decompositional knowledge extraction as a method of explainability.</span>'}
{'title': 'Recurrently Controlling a Recurrent Network with Recurrent Networks Controlled by More Recurrent Networks', 'authors': ['Yi Tay', 'Yikang Shen', 'Alvin Chan', 'Aston Zhang', 'Shuai Zhang'], 'Conference': 'ICLR 2021 Conference Withdrawn Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=gnAGreyEzP2&name=pdf', 'abstract': '</span><span class="note_content_value">This paper explores an intriguing idea of recursively parameterizing recurrent nets. Simply speaking, this refers to recurrently controlling a recurrent network with recurrent networks controlled by recurrent networks. The proposed architecture recursively parameterizes its gating functions whereby gating mechanisms of X-RNN are controlled by instances of itself, which are repeatedly called in a recursive fashion. We postulate that our proposed inductive bias provides modeling benefits pertaining to learning with inherently hierarchically-structured sequence data. To this end, we conduct extensive experiments on recursive logic tasks (sorting, tree traversal, logical inference), sequential pixel-by-pixel classification, semantic parsing, code generation, machine translation and polyphonic music modeling, demonstrating the widespread utility of the proposed approach, i.e., achieving optimistic and competitive results on all tasks.</span>'}
{'title': 'Answering Questions Over Knowledge Graphs Using Logic Programming Along with Language Models', 'authors': ['Navid Madani', 'Kenneth Joseph'], 'Conference': 'Submitted to Tiny Papers @ ICLR 2023', 'date': '01 Mar 2023 (modified: 10 Apr 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=D2lo4toTUTo&name=pdf', 'abstract': '</span><span class="note_content_value">Question Answering over Knowledge Graphs (KGQA) is the task of answering natural language questions over a knowledge graph (KG). This task requires a model to reason over multiple edges of the KG to reach the right answer. In this work,  we present a method to equip large language models (LLMs) with classic logical programming languages to provide an explainable solution to the problem. Our goal is to extract the representation of the question in the form of a Prolog query, which can then be used to answer the query programmatically. To demonstrate the effectiveness of this approach, we use the MetaQA dataset and show that our method finds the correct answer entities for all the questions in the test dataset.</span>'}
{'title': 'Robust Natural Language Representation Learning for Natural Language Inference by Projecting Superficial Words out', 'authors': ['Wanyun Cui', 'Guangyu Zheng', 'Wei Wang'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HkxQzlHFPr&name=pdf', 'abstract': '</span><span class="note_content_value">In natural language inference, the semantics of some words do not affect the inference. Such information is considered superficial and brings overfitting. How can we represent and discard such superficial information? In this paper, we use first order logic (FOL) - a classic technique from meaning representation language – to explain what information is superficial for a given sentence pair. Such explanation also suggests two inductive biases according to its properties. We proposed a neural network-based approach that utilizes the two inductive biases. We obtain substantial improvements over extensive experiments.</span>'}
{'title': 'Efficient Training and Inference of Hypergraph Reasoning Networks', 'authors': ['Guangxuan Xiao', 'Leslie Pack Kaelbling', 'Jiajun Wu', 'Jiayuan Mao'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=WKWAkkXGpWN&name=pdf', 'abstract': '</span><span class="note_content_value">We study the problem of hypergraph reasoning in large domains, e.g., predicting the relationship between several entities based on the input facts. We observe that in logical reasoning, logical rules (e.g., my parent\'s parent is my grandparent) usually apply locally (e.g., only three people are involved in a grandparent rule), and sparsely (e.g., the grandparent relationship is sparse across all pairs of people in the world). Inspired by these observations, we propose Sparse and Local Neural Logic Machines (SpaLoc), a structured neural network for hypergraph reasoning. To leverage the sparsity in hypergraph neural networks, SpaLoc represents the grounding of relationships such as parent and grandparent as sparse tensors and uses neural networks and finite-domain quantification operations to infer new facts based on the input. We further introduce a sparsification loss to regularize the number of hyperedges in intermediate layers of a SpaLoc model. To enable training on large-scale graphs such as real-world knowledge graphs, SpaLoc makes training and inference-time sub-sampling of the input graphs. To remedy the information loss in sampled sub-graphs, we propose a novel sampling and label calibration paradigm based on an information-theoretic measure information sufficiency. Our SpaLoc shows superior accuracy and efficiency on synthetic datasets compared with prior art and achieves state-of-the-art performance on several real-world knowledge graph reasoning benchmarks.</span>'}
{'title': 'Knowledge Based Multilingual Language Model', 'authors': ['Linlin Liu', 'Xin Li', 'Ruidan He', 'Lidong Bing', 'Shafiq Joty', 'Luo Si'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SCSonHu4p0W&name=pdf', 'abstract': '</span><span class="note_content_value">Knowledge enriched language representation learning has shown promising performance across various knowledge-intensive NLP tasks. However, existing knowledge based language models are all trained with monolingual knowledge graph data, which limits their application to more languages. In this work, we present a novel framework to pretrain knowledge based multilingual language models (KMLMs). We first generate a large amount of code-switched synthetic sentences and reasoning-based multilingual training data using the Wikidata knowledge graphs. Then based on the intra- and inter-sentence structures of the generated data, we design pretraining tasks to facilitate knowledge learning, which allows the language models to not only memorize the factual knowledge but also learn useful logical patterns. Our pretrained KMLMs demonstrate significant performance improvements on a wide range of knowledge-intensive cross-lingual NLP tasks, including named entity recognition, factual knowledge retrieval, relation classification, and a new task designed by us, namely, logic reasoning. Our code and pretrained language models will be made publicly available.</span>'}
{'title': 'Hybrid Neuro-Symbolic Reasoning based on Multimodal Fusion', 'authors': ['Subrata Das', 'Bodong Zhou'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SFyOjfEOJO&name=pdf', 'abstract': '</span><span class="note_content_value">Deep neural models and symbolic Artificial Intelligence (AI) systems have contrasting advantages and disadvantages. Neural models can be trained from raw, incomplete and noisy data to obtain abstraction of features at various levels, but their uninterpretability is well-known. On the other hand, the traditional rule-based symbolic reasoning encodes domain knowledge, but its failure is often attributed to the acquisition bottleneck. We propose to build a hybrid learning and reasoning system which is based on multimodal fusion approach that brings together\nadvantageous features from both the paradigms. Specifically, we enhance convolutional neural networks (CNNs) with the structured information of ‘if-then’ symbolic logic rules obtained via word embeddings corresponding to propositional symbols and terms. With many dozens of intuitive rules relating the type of a scene with its typical constituent objects, we are able to achieve significant improvement over the base CNN-based classification. Our approach is extendible to handle first-order logical syntax for rules and other deep learning models.</span>'}
{'title': 'Inductive Relation Prediction Using Analogy Subgraph Embeddings', 'authors': ['Jiarui Jin', 'Yangkun Wang', 'Kounianhua Du', 'Weinan Zhang', 'Zheng Zhang', 'David Wipf', 'Yong Yu', 'Quan Gan'], 'Conference': 'ICLR 2022 Poster', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=PTRo58zPt3P&name=pdf', 'abstract': '</span><span class="note_content_value">Prevailing methods for relation prediction in heterogeneous graphs aim at learning latent representations (i.e., embeddings) of observed nodes and relations, and thus are limited to the transductive setting where the relation types must be known during training.  Here,  we propose ANalogy  SubGraphEmbeddingLearning (GraphANGEL), a novel relation prediction framework that predicts relations5between each node pair based on the subgraphs containing the pair, as well as other  (analogy)  subgraphs with the same graph patterns.   Each graph pattern explicitly represents a specific logical rule, which contributes to an inductive bias that facilitates generalization to unseen relations and leads to more explainable predictive models. Moreover, our method also removes the limited neighborhood constraint of graph neural networks. Our model consistently outperforms existing models on heterogeneous graph based recommendation as well as knowledge graph completion.  We also empirically demonstrate our model’s capability in generalizing to new relations while producing explainable heat maps of attention scores across the discovered logic.</span>'}
{'title': 'PhraseTransformer: Self-Attention using Local Context for Semantic Parsing', 'authors': ['Phuong Minh Nguyen', 'Vu Tran', 'Minh Le Nguyen'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=VG3i3CfFN__&name=pdf', 'abstract': '</span><span class="note_content_value">Semantic parsing is a challenging task whose purpose is to convert a natural language utterance to machine-understandable information representation. Recently, solutions using Neural Machine Translation have achieved many promising results, especially Transformer because of the ability to learn long-range word dependencies. However, the one drawback of adapting the original Transformer to the semantic parsing is the lack of detail in expressing the information of sentences. Therefore, this work proposes a PhraseTransformer architecture that is capable of a more detailed meaning representation by learning the phrase dependencies in the sentence. The main idea is to incorporate Long Short-Term Memory (LSTM) into the Self-Attention mechanism of the original Transformer to capture more local context of phrases. Experimental results show that the proposed model captures the detailed meaning better than Transformer, raises local context awareness and achieves strong competitive performance on Geo, MSParS datasets, and leads to SOTA performance on Atis dataset in methods using Neural Network.</span>'}
{'title': 'Neuro-Symbolic Forward Reasoning', 'authors': ['Hikaru Shindo', 'Devendra Singh Dhami', 'Kristian Kersting'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=UkgBSwjxwe&name=pdf', 'abstract': '</span><span class="note_content_value">Reasoning is an essential part of human intelligence and thus has been a long-standing goal in artificial intelligence research. With the recent success of deep learning, incorporating reasoning with deep learning systems i.e. neuro-symbolic AI has become a major field of interest. We propose Neuro-Symbolic Forward Reasoner (NS-FR), a new approach for reasoning tasks taking advantage of differentiable forward-chaining using first-order logic. The key idea is to combine differentiable forward-chaining reasoning with object-centric learning. Differentiable forward-chaining reasoning computes logical entailments smoothly, i.e., it deduces new facts from given facts and rules in a differentiable manner. The object-centric learning approach factorizes raw inputs into representations in terms of objects. This allows us to provide a consistent framework to perform the forward-chaining inference from raw  inputs. NS-FR factorizes the raw inputs into the object-centric representations, then converts them into probabilistic ground atoms and finally performs differentiable forward-chaining inference using weighted rules for inference. Our comprehensive experimental evaluations on object-centric reasoning data sets, 2D Kandinsky patterns and 3D CLEVR-Hans, and variety of tasks show the effectiveness and advantage of our approach.</span>'}
{'title': 'Generalizing and Tensorizing Subgraph Search in the Supernet', 'authors': ['Hansi Yang', 'quanming yao'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Oi-Kh379U0&name=pdf', 'abstract': '</span><span class="note_content_value">Recently, a special kind of graph, i.e., supernet, which allows two nodes connected by multi-choice edges, has exhibited its power in neural architecture search (NAS) by searching better architectures for computer vision (CV) and natural language processing (NLP) tasks. In this paper, we discover that the design of such discrete architectures also appears in many other important learning tasks, e.g., logical chain inference in knowledge graphs (KGs) and meta-path discovery in heterogeneous information networks (HINs). Thus, we are motivated to generalize the supernet search problem on a broader horizon. However, none of the existing works are effective since the supernet\'s topology is highly task-dependent and diverse. To address this issue, we propose to tensorize the supernet, i.e. unify the subgraph search problems by a tensor formulation and encode the topology inside the supernet by a tensor network. We further propose an efficient algorithm that admits both stochastic and deterministic objectives to solve the search problem. Finally, we perform extensive experiments on diverse learning tasks, i.e., architecture design for CV, logic inference for KG, and meta-path discovery for HIN. Empirical results demonstrate that our method leads to better performance and architectures.\n</span>'}
{'title': 'Transformer Embeddings of Irregularly Spaced Events and Their Participants', 'authors': ['Hongyuan Mei', 'Chenghao Yang', 'Jason Eisner'], 'Conference': 'ICLR 2022 Poster', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Rty5g9imm7H&name=pdf', 'abstract': '</span><span class="note_content_value">The neural Hawkes process (Mei &amp; Eisner, 2017) is a generative model of irregularly spaced sequences of discrete events. To handle complex domains with many event types, Mei et al. (2020a) further consider a setting in which each event in the sequence updates a deductive database of facts (via domain-specific pattern-matching rules); future events are then conditioned on the database contents. They show how to convert such a symbolic system into a neuro-symbolic continuous-time generative model, in which each database fact and possible event has a time-varying embedding that is derived from its symbolic provenance. \n\nIn this paper, we modify both models, replacing their recurrent LSTM-based architectures with flatter attention-based architectures (Vaswani et al., 2017), which are simpler and more parallelizable. This does not appear to hurt our accuracy, which is comparable to or better than that of the original models as well as (where applicable) previous attention-based methods (Zuo et al., 2020; Zhang et al., 2020a).</span>'}
{'title': 'Knowledge Graph Papers @ ICLR 2021', 'authors': [], 'Conference': 'BT@ICLR2022', 'date': 'Published: 27 Mar 2022, Last Modified: 05 May 2023', 'link': 'PDF not available', 'abstract': '</span><span class="note_content_value">This post aims at providing an overview of ICLR 2021 papers focusing on knowledge graphs (KGs). In particular, we highlight the research in four wide areas: complex query answering and reasoning in KGs, temporal logics and KGs, NLP point of view and entity linking, multimodal question answering with KGs. We hope this post could be of use for researchers and practitioners from adjacent areas to demonstrate the benefits of employing knowledge graphs in those various domains solving important problems.</span>'}
{'title': 'SLASH: Embracing Probabilistic Circuits into Neural Answer Set Programming', 'authors': ['Arseny Skryagin', 'Wolfgang Stammer', 'Daniel Ochs', 'Devendra Singh Dhami', 'Kristian Kersting'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=0U0C2pXfTZl&name=pdf', 'abstract': '</span><span class="note_content_value">The goal of combining the robustness of neural networks and the expressivity of symbolic methods has rekindled the interest in Neuro-Symbolic AI. Recent advancements in Neuro-Symbolic AI often consider specifically-tailored architectures consisting of disjoint neural and symbolic components, and thus do not exhibit desired gains that can be achieved by integrating them into a unifying framework. We introduce SLASH -- a novel deep probabilistic programming language (DPPL). At its core, SLASH consists of Neural-Probabilistic Predicates (NPPs) and logical programs which are united via answer set programming. The probability estimates resulting from NPPs act as the binding element between the logical program and raw input data, thereby allowing SLASH to answer task-dependent logical queries. This allows SLASH to elegantly integrate the symbolic and neural components in a unified framework. We evaluate SLASH on the benchmark data of MNIST addition as well as novel tasks for DPPLs such as missing data prediction and set prediction with state-of-the-art performance, thereby showing the effectiveness and generality of our method.</span>'}
{'title': 'Mathematical Reasoning via Self-supervised Skip-tree Training', 'authors': ['Markus Norman Rabe', 'Dennis Lee', 'Kshitij Bansal', 'Christian Szegedy'], 'Conference': 'ICLR 2021 Spotlight', 'date': 'Published: 12 Jan 2021, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=YmqAnY0CMEy&name=pdf', 'abstract': '</span><span class="note_content_value">We demonstrate that self-supervised language modeling applied to mathematical formulas enables logical reasoning. To measure the logical reasoning abilities of language models, we formulate several evaluation (downstream) tasks, such as inferring types, suggesting missing assumptions and completing equalities. For training language models for formal mathematics, we propose a novel skip-tree task. We find that models trained on the skip-tree task show surprisingly strong mathematical reasoning abilities, and outperform models trained on standard skip-sequence tasks. We also analyze the models\' ability to formulate new conjectures by measuring how often the predictions are provable and useful in other proofs.</span>'}
{'title': 'Constrained Hierarchical Deep Reinforcement Learning with Differentiable Formal Specifications', 'authors': ['Zikang Xiong', 'Joe Eappen', 'Ahmed H Qureshi', 'Suresh Jagannathan'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=LUOSN8opID1&name=pdf', 'abstract': '</span><span class="note_content_value">Formal logic specifications are a useful tool to describe desired agent behavior and have been explored as a means to shape rewards in Deep Reinforcement Learning (DRL) systems over a variety of problems and domains. Prior work, however, has failed to consider the possibility of making these specifications differentiable, which would yield a more informative signal of the objective via the specification gradient. This paper examines precisely such an approach by exploring a Lagrangian method to constrain policy updates using a differentiable style of temporal logic specifications that associates logic formulae with real-valued quantitative semantics. This constrained learning mechanism is then used in a hierarchical setting where a high-level specification-guided neural network path planner works with a low-level control policy to navigate through planned waypoints. The effectiveness of our approach is demonstrated over four robot dynamics with five different types of Linear Temporal Logic (LTL) specifications. Our demo videos are collected at <a href="https://sites.google.com/view/schrl" target="_blank" rel="nofollow">https://sites.google.com/view/schrl</a>.</span>'}
{'title': 'Learning explanations that are hard to vary', 'authors': ['Giambattista Parascandolo', 'Alexander Neitz', 'ANTONIO ORVIETO', 'Luigi Gresele', 'Bernhard Schölkopf'], 'Conference': 'ICLR 2021 Poster', 'date': 'Published: 12 Jan 2021, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=hb1sDDSLbV&name=pdf', 'abstract': '</span><span class="note_content_value">In this paper, we investigate the principle that good explanations are hard to vary in the context of deep learning.\nWe show that averaging gradients across examples -- akin to a logical OR of patterns -- can favor memorization and `patchwork\' solutions that sew together different strategies, instead of identifying invariances.\nTo inspect this, we first formalize a notion of consistency for minima of the loss surface, which measures to what extent a minimum appears only when examples are pooled.\nWe then propose and experimentally validate a simple alternative algorithm based on a logical AND, that focuses on invariances and prevents memorization in a set of real-world tasks. \nFinally, using a synthetic dataset with a clear distinction between invariant and spurious mechanisms, we dissect learning signals and compare this approach to well-established regularizers.</span>'}
{'title': 'Abductive Knowledge Induction from Raw Data', 'authors': ['Wang-Zhou Dai', 'Stephen Muggleton'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=UAAJMiVjTY_&name=pdf', 'abstract': '</span><span class="note_content_value">For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D452 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44E TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.153em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi><mi>e</mi><mi>t</mi><msub><mi>a</mi><mrow data-mjx-texclass="ORD"><mi>A</mi><mi>b</mi><mi>d</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D452 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44E TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.153em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi><mi>e</mi><mi>t</mi><msub><mi>a</mi><mrow data-mjx-texclass="ORD"><mi>A</mi><mi>b</mi><mi>d</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D440 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D452 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44E TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.153em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D434 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi><mi>e</mi><mi>t</mi><msub><mi>a</mi><mrow data-mjx-texclass="ORD"><mi>A</mi><mi>b</mi><mi>d</mi></mrow></msub></math></mjx-assistive-mml></mjx-container> is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.</span>'}
{'title': 'Top-Down Neural Model For Formulae', 'authors': ['Karel Chvalovský'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': 'Published: 20 Dec 2018, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Byg5QhR5FQ&name=pdf', 'abstract': '</span><span class="note_content_value">We present a simple neural model that given a formula and a property tries to answer the question whether the formula has the given property, for example whether a propositional formula is always true. The structure of the formula is captured by a feedforward neural network recursively built for the given formula in a top-down manner. The results of this network are then processed by two recurrent neural networks. One of the interesting aspects of our model is how propositional atoms are treated. For example, the model is insensitive to their names, it only matters whether they are the same or distinct.</span>'}
{'title': 'Towards Axiomatic, Hierarchical, and Symbolic Explanation for Deep Models', 'authors': ['Jie Ren', 'Mingjie Li', 'Qirui Chen', 'Huiqi Deng', 'Quanshi Zhang'], 'Conference': 'ICLR 2022 Conference Withdrawn Submission', 'date': '28 Sept 2021 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=I7Tuih6s7Dj&name=pdf', 'abstract': '</span><span class="note_content_value">This paper proposes a hierarchical and symbolic And-Or graph (AOG) to objectively explain the internal logic encoded by a well-trained deep model for inference. We first define the objectiveness of an explainer model in game theory, and we develop a rigorous representation of the And-Or logic encoded by the deep model. The objectiveness and trustworthiness of the AOG explainer are both theoretically guaranteed and experimentally verified. Furthermore, we propose several techniques to boost the conciseness of the explanation.</span>'}
{'title': 'Discrete Word Embedding for Logical Natural Language Understanding', 'authors': ['Zilu Tang', 'Masataro Asai'], 'Conference': 'ICLR 2021 Conference Withdrawn Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=4LHz4IFGLQ-&name=pdf', 'abstract': '</span><span class="note_content_value">We propose an unsupervised neural model for learning a discrete embedding of words.\nUnlike existing discrete embeddings, our binary embedding supports vector arithmetic operations similar to continuous embeddings.\nOur embedding represents each word as a set of propositional statements describing a transition rule in classical/STRIPS planning formalism.\nThis makes the embedding directly compatible with symbolic, state of the art classical planning solvers.</span>'}
{'title': 'Marginal Probability Explanation: A Saliency Map with Closed-loop Validation', 'authors': ['Yao Li', 'Jialin Song', 'Shengzhu Shi', 'Zhichang Guo', 'Weiwei Gao'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=h_Ma6BSi9Q&name=pdf', 'abstract': '</span><span class="note_content_value">In this work, we propose a saliency map with pixel-level resolution, called Marginal Probability Explanation (MPE), for a black-box classifier. MPE visualizes the contribution of each input dimension to the classifier by calculating marginal probabilities when only one dimension is considered. Marginal probabilities are estimated using Monte Carlo by sampling from the training dataset. Based on MPE, we propose typical samples, i.e. samples that maximize their marginal probability in every input dimension. We verify that our proposed MPE is meaningful through closed-loop validation experiments, where replacing a few pixels with the lowest marginal probability with pixels in the typical sample ``corrects" the classification. Based on experiments, we found deep neural networks are probably still using pixel-level logics for image classification. Moreover, the critical pixels are not necessary related to the subject. </span>'}
{'title': 'Efficient generation of structured objects with Constrained Adversarial Networks', 'authors': ['Jacopo Gobbi', 'Luca Di Liello', 'Pierfrancesco Ardino', 'Paolo Morettin', 'Stefano Teso', 'Andrea Passerini'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HyeCnkHtwH&name=pdf', 'abstract': '</span><span class="note_content_value">Despite their success, generative adversarial networks (GANs) cannot easily generate structured objects like molecules or game maps. The issue is that such objects must satisfy structural requirements (e.g., molecules must be chemically valid, game maps must guarantee reachability of the end goal) that are difficult to capture with examples alone.  As a remedy, we     propose constrained adversarial networks (CANs), which embed the constraints into the model during training by penalizing the generator whenever it outputs invalid structures. As in unconstrained GANs, new objects can be sampled straightforwardly from the generator, but in addition they satisfy the constraints with high probability.  Our approach handles arbitrary logical constraints and leverages knowledge compilation techniques to efficiently evaluate the expected disagreement between the     model and the constraints.  This setup is further extended to hybrid logical-neural constraints for capturing complex requirements like graph reachability.  An extensive empirical analysis on constrained images, molecules, and video game levels shows that CANs efficiently generate valid structures that are both high-quality and novel.</span>'}
{'title': 'In Search for a SAT-friendly Binarized Neural Network Architecture', 'authors': ['Nina Narodytska', 'Hongce Zhang', 'Aarti Gupta', 'Toby Walsh'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SJx-j64FDr&name=pdf', 'abstract': '</span><span class="note_content_value">Analyzing the behavior of neural networks is  one of the most pressing challenges in deep learning.  Binarized Neural Networks are an important class of networks that allow equivalent representation in Boolean logic and can be analyzed formally with logic-based reasoning tools like SAT solvers. Such tools can be used to answer existential and probabilistic queries about the network, perform explanation generation, etc. However, the main bottleneck for all methods is their ability to reason about large BNNs efficiently. In this work, we analyze architectural design choices of BNNs and discuss how they affect the performance of logic-based reasoners. We propose changes to the BNN architecture and the training procedure to get a simpler network for SAT solvers without sacrificing accuracy on the primary task. Our experimental results demonstrate that our approach scales to larger deep neural networks compared to existing work for existential and probabilistic queries, leading to significant speed ups on all tested datasets.\n</span>'}
{'title': 'Mathematical Reasoning in Latent Space', 'authors': ['Dennis Lee', 'Christian Szegedy', 'Markus Rabe', 'Sarah Loos', 'Kshitij Bansal'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Ske31kBtPr&name=pdf', 'abstract': '</span><span class="note_content_value">We design and conduct a simple experiment to study whether neural networks can perform several steps of approximate reasoning in a fixed dimensional latent space. The set of rewrites (i.e. transformations) that can be successfully performed on a statement represents essential semantic features of the statement. We can compress this information by embedding the formula in a vector space, such that the vector associated with a statement can be used to predict whether a statement can be rewritten by other theorems. Predicting the embedding of a formula generated by some rewrite rule is naturally viewed as approximate reasoning in the latent space. In order to measure the effectiveness of this reasoning, we perform approximate deduction sequences in the latent space and use the resulting embedding to inform the semantic features of the corresponding formal statement (which is obtained by performing the corresponding rewrite sequence using real formulas). Our experiments show that graph neural networks can make non-trivial predictions about the rewrite-success of statements, even when they propagate predicted latent representations for several steps. Since our corpus of mathematical formulas includes a wide variety of mathematical disciplines, this experiment is a strong indicator for the feasibility of deduction in latent space in general.</span>'}
{'title': 'Stacked Filters Stationary Flow For Hardware-Oriented Acceleration Of Deep Convolutional Neural Networks', 'authors': ['Gao Yuechao', 'Liu Nianhong', 'Zhang Sheng'], 'Conference': 'ICLR 2018 Workshop Submission', 'date': '22 Jan 2018 (modified: 05 Feb 2018)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HkeAoQQHM&name=pdf', 'abstract': '</span><span class="note_content_value">To address memory and computation resource limitations for hardware-oriented acceleration of deep convolutional neural networks(CNNs), we present a computation flow, stacked filters stationary flow (SFS), and a corresponding data encoding format, relative indexed compressed sparse filter format (CSF), to make the best of data sparsity, and simplify data handling at execution time. Comparing with the state-of-the-art result (Han et al., 2016b), our methods achieve 1.11x improvement in reducing the storage required by AlexNet, and 1.09x improvement in reducing the storage required by SqueezeNet, without loss of accuracy on the ImageNet dataset. Moreover, using these approaches, chip area for logics handling irregular sparse data access can be saved. Comparing with the 2D-SIMD processure structures in DVAS, ENVISION, etc., our methods achieve about 3.65x\x02 processing element (PE) array utilization rate improvement (from 26.4% to 96.5%), using the data from Deep Compression on AlexNet.</span>'}
{'title': 'Informed Temporal Modeling via Logical Specification of Factorial LSTMs', 'authors': ['Hongyuan Mei', 'Guanghui Qin', 'Minjie Xu', 'Jason Eisner'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=S1ghzlHFPS&name=pdf', 'abstract': '</span><span class="note_content_value">Consider a world in which events occur that involve various entities. Learning how to predict future events from patterns of past events becomes more difficult as we consider more types of events. Many of the patterns detected in the dataset by an ordinary LSTM will be spurious since the number of potential pairwise correlations, for example, grows quadratically with the number of events. We propose a type of factorial LSTM architecture where different blocks of LSTM cells are responsible for capturing different aspects of the world state. We use Datalog rules to specify how to derive the LSTM structure from a database of facts about the entities in the world. This is analogous to how a probabilistic relational model (Getoor &amp; Taskar, 2007) specifies a recipe for deriving a graphical model structure from a database. In both cases, the goal is to obtain useful inductive biases by encoding informed independence assumptions into the model. We specifically consider the neural Hawkes process, which uses an LSTM to modulate the rate of instantaneous events in continuous time. In both synthetic and real-world domains, we show that we obtain better generalization by using appropriate factorial designs specified by simple Datalog programs.\n</span>'}
{'title': 'Logical Activation Functions: Logit-space equivalents of Boolean Operators', 'authors': ['Scott C Lowe', 'Robert Earle', "Jason d'Eon", 'Thomas Trappenberg', 'Sageev Oore'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Ck_iw4jMC4l&name=pdf', 'abstract': '</span><span class="note_content_value">Neuronal representations within artificial neural networks are commonly understood as logits, representing the log-odds score of presence (versus absence) of features within the stimulus. Under this interpretation, we can derive the probability <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2229"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo>∩</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> that a pair of independent features are both present in the stimulus from their logits. By converting the resulting probability back into a logit, we obtain a logit-space equivalent of the AND operation. However, since this function involves taking multiple exponents and logarithms, it is not well suited to be directly used within neural networks. We thus constructed an efficient approximation named <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mtext class="mjx-n"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c4E"></mjx-c><mjx-c class="mjx-c44"></mjx-c></mjx-mtext><mjx-script style="vertical-align: -0.153em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c4C"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mtext>AND</mtext><mtext>AIL</mtext></msub></math></mjx-assistive-mml></mjx-container> (the AND operator Approximate for Independent Logits) utilizing only comparison and addition operations, which can be deployed as an activation function in neural networks. Like MaxOut, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mtext class="mjx-n"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c4E"></mjx-c><mjx-c class="mjx-c44"></mjx-c></mjx-mtext><mjx-script style="vertical-align: -0.153em;"><mjx-mtext class="mjx-n" size="s"><mjx-c class="mjx-c41"></mjx-c><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c4C"></mjx-c></mjx-mtext></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mtext>AND</mtext><mtext>AIL</mtext></msub></math></mjx-assistive-mml></mjx-container> is a generalization of ReLU to two-dimensions. Additionally, we constructed efficient approximations of the logit-space equivalents to the OR and XNOR operators. We deployed these new activation functions, both in isolation and in conjunction, and demonstrated their effectiveness on a variety of tasks including image classification, transfer learning, abstract reasoning, and compositional zero-shot learning.</span>'}
{'title': 'Query Embedding on Hyper-Relational Knowledge Graphs', 'authors': ['Dimitrios Alivanistos', 'Max Berrendorf', 'Michael Cochez', 'Mikhail Galkin'], 'Conference': 'ICLR 2022 Poster', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=4rLw09TgRw9&name=pdf', 'abstract': '</span><span class="note_content_value">Multi-hop logical reasoning is an established problem in the field of representation learning on knowledge graphs (KGs). It subsumes both one-hop link prediction as well as other more complex types of logical queries. Existing algorithms operate only on classical, triple-based graphs, whereas modern KGs often employ a hyper-relational modeling paradigm. In this paradigm, typed edges may have several key-value pairs known as qualifiers that provide fine-grained context for facts. In queries, this context modifies the meaning of relations, and usually reduces the answer set. Hyper-relational queries are often observed in real-world KG applications, and existing approaches for approximate query answering cannot make use of qualifier pairs. In this work, we bridge this gap and extend the multi-hop reasoning problem to hyper-relational KGs allowing to tackle this new type of complex queries. Building upon recent advancements in Graph Neural Networks and query embedding techniques, we study how to embed and answer hyper-relational conjunctive queries. Besides that, we propose a method to answer such queries and demonstrate in our experiments that qualifiers improve query answering on a diverse set of query patterns.</span>'}
{'title': 'Learning from Explanations with Neural Execution Tree', 'authors': ['Ziqi Wang*', 'Yujia Qin*', 'Wenxuan Zhou', 'Jun Yan', 'Qinyuan Ye', 'Leonardo Neves', 'Zhiyuan Liu', 'Xiang Ren'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rJlUt0EYwS&name=pdf', 'abstract': '</span><span class="note_content_value">While deep neural networks have achieved impressive performance on a range of NLP tasks, these data-hungry models heavily rely on labeled data, which restricts their applications in scenarios where data annotation is expensive. Natural language (NL) explanations have been demonstrated very useful additional supervision, which can provide sufficient domain knowledge for generating more labeled data over new instances, while the annotation time only doubles. However, directly applying them for augmenting model learning encounters two challenges: (1) NL explanations are unstructured and inherently compositional, which asks for a modularized model to represent their semantics, (2) NL explanations often have large numbers of linguistic variants, resulting in low recall and limited generalization ability. In this paper, we propose a novel Neural Execution Tree (NExT) framework to augment training data for text classification using NL explanations. After transforming NL explanations into executable logical forms by semantic parsing, NExT generalizes different types of actions specified by the logical forms for labeling data instances, which substantially increases the coverage of each NL explanation. Experiments on two NLP tasks (relation extraction and sentiment analysis) demonstrate its superiority over baseline methods. Its extension to multi-hop question answering achieves performance gain with light annotation effort.</span>'}
{'title': 'DeepSAT: An EDA-Driven Learning Framework for SAT', 'authors': ['Min Li', 'Zhengyuan Shi', 'Qiuxia LAI', 'Sadaf Khan', 'Shaowei Cai', 'Qiang Xu'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ep_8uwxouZO&name=pdf', 'abstract': '</span><span class="note_content_value">We present DeepSAT, a novel end-to-end learning framework for the Boolean satisfiability (SAT) problem. Unlike existing solutions trained on random SAT instances with relatively weak supervision, we propose applying the knowledge of the well-developed electronic design automation (EDA) field for SAT solving. Specifically, we first resort to logic synthesis algorithms to pre-process SAT instances into optimized and-inverter graphs (AIGs). By doing so, the distribution diversity among various SAT instances can be dramatically reduced, which facilitates improving the generalization capability of the learned model. Next, we regard the distribution of SAT solutions being a product of conditional Bernoulli distributions. Based on this observation, we approximate the SAT solving procedure with a conditional generative model, leveraging a novel directed acyclic graph neural network (DAGNN) with two polarity prototypes for conditional SAT modeling. To effectively train the generative model,  with the help of logic simulation tools, we obtain the probabilities of nodes in the AIG being logic ‘1’ as rich supervision. We conduct comprehensive experiments on various SAT problems. Our results show that, DeepSAT achieves significant accuracy improvements over state-of-the-art learning-based SAT solutions, especially when generalized to SAT instances that are relatively large or with diverse distributions. </span>'}
{'title': 'Emergent Symbols through Binding in External Memory', 'authors': [], 'Conference': 'BT@ICLR2022', 'date': 'Published: 27 Mar 2022, Last Modified: 16 Sept 2023', 'link': 'PDF not available', 'abstract': '</span><span class="note_content_value">In this blog post, we describe the paper \'Emergent Symbols through Binding in External Memory\', which introduces the Emergent Symbol Binding Network (ESBN), a recurrent neural network with factorized augmented memory to solve several logical reasoning tasks. We describe the motivation and design choices of the ESBN in great detail, compare it to strong baselines, and perform a qualitative validation of the generalization claims from the original paper.\n</span>'}
{'title': 'Automata Guided Skill Composition', 'authors': ['Xiao Li', 'Yao Ma', 'Calin Belta'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HkfwpiA9KX&name=pdf', 'abstract': '</span><span class="note_content_value">Skills learned through (deep) reinforcement learning often generalizes poorly\nacross tasks and re-training is necessary when presented with a new task. We\npresent a framework that combines techniques in formal methods with reinforcement\nlearning (RL) that allows for the convenient specification of complex temporal\ndependent tasks with logical expressions and construction of new skills from existing\nones with no additional exploration. We provide theoretical results for our\ncomposition technique and evaluate on a simple grid world simulation as well as\na robotic manipulation task.</span>'}
{'title': 'Formal Specifications from Natural Language', 'authors': ['Christopher Hahn', 'Frederik Schmitt', 'Julia Janice Tillman', 'Niklas Metzger', 'Julian Siber', 'Bernd Finkbeiner'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ywAjQw-spmY&name=pdf', 'abstract': '</span><span class="note_content_value">We study the generalization abilities of language models when translating natural language into formal specifications with complex semantics. In particular, we fine-tune language models on three datasets consisting of English sentences and their corresponding formal representation: 1) regular expressions (regex), frequently used in programming and search; 2) First-order logic (FOL), commonly used in software verification and theorem proving; and 3) linear-time temporal logic (LTL), which forms the basis for industrial hardware specification languages. Our experiments show that, in these diverse domains, the language models maintain their generalization capabilities from pre-trained knowledge of natural language to generalize, e.g., to new variable names or operator descriptions. Additionally, they achieve competitive performance, and even outperform the state-of-the-art for translating into regular expressions, with the benefits of being easy to access, efficient to fine-tune, and without a particular need for domain-specific reasoning.</span>'}
{'title': 'CASR: Generating Complex Sequences with Autoregressive Self-Boost Refinement', 'authors': ['Hongwei Han', 'Mengyu Zhou', 'Shi Han', 'Xiu Li', 'Dongmei Zhang'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 02 Mar 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SVl1w1u3InX&name=pdf', 'abstract': '</span><span class="note_content_value">There are sequence generation tasks where the best order to generate the target sequence is not left-to-right. For example, an answer to the Sudoku game, a structured code like s-expression, and even a logical natural language answer where the analysis may be generated after the decision. We define the target sequences of those tasks as complex sequences. Obviously, a complex sequence should be constructed with multiple logical steps, and has dependencies among each part of itself (e.g. decisions depend on analyses). It\'s a great challenge for the classic left-to-right autoregressive generation system to generate complex sequences. Current approaches improve one-pass left-to-right generation on NLG tasks by generating different heuristic intermediate sequences in multiple stages. However, for complex sequences, the heuristic rules to break down them may hurt performance, and increase additional exposure bias. To tackle these challenges, we propose a PLM-friendly autoregressive self-boost refinement framework, CASR. When training, CASR inputs the predictions generated by the model itself at the previous refinement step (instead of those produced by heuristic rules). To find an optimal design, we also discuss model architecture, parameter efficiency and initialization strategy. By evaluating CASR on Sudoku, WebQSP, MTOP and KVRET through controlled experiments and empirical studies, we find that CASR produces high-quality outputs. CASR also improves Accuracy on Sudoku (70.93% --&gt; 97.28%) and achieves state-of-the-art performance on KVRET with Micro F1 score (67.88% --&gt; 70.00%).</span>'}
{'title': 'Scenario-based Question Answering with Interacting Contextual Properties', 'authors': ['Haitian Sun', 'William W. Cohen', 'Ruslan Salakhutdinov'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 22 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=tPrRs6YB2P&name=pdf', 'abstract': '</span><span class="note_content_value">In the scenario-based Question Answering (QA) task, models are asked to find answers that are appropriate to the user scenarios associated with the question and identify information that is missing from the scenarios but is necessary for the answers to hold. Scenarios commonly include multiple properties of users, such as age, employment status, and income level for the question “How much can I claim from this benefit”. The properties relevant to a potential answer are given in a document, which will state conditions necessary for the answer to hold. Documents also may specify how conditions interact with each other, e.g. with text like “one of the conditions below must apply”. Although understanding the relationship between conditions is crucial for solving this challenging QA task, limited work has been done so far in modeling this. In this paper, we propose the T-Reasoner model, which solves this problem with three jointly learned modules: an entailment module which checks whether a condition has been satisfied by the scenario, a decoding module which locates eligible answers from documents, and a reasoning module which infers the relationship between conditions and performs a reasoning step to determine the logically consistent answers and identify missing conditions. T-Reasoner outperforms strong baselines on a synthetic scenario-based QA dataset and achieves a new state-of-the-art on two scenario-based QA benchmarks, outperforming the prior best models by 3-10 points.</span>'}
{'title': 'On Deep Neural Network Calibration by Regularization and its Impact on Refinement', 'authors': ['Aditya Singh'], 'Conference': 'ICLR 2022 Conference Withdrawn Submission', 'date': '28 Sept 2021 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=jkpT8c7jal4&name=pdf', 'abstract': '</span><span class="note_content_value">Deep neural networks have been shown to be highly miscalibrated. often they tend to be overconfident in their predictions. It poses a significant challenge for safety-critical systems to utilise deep neural networks  (DNNs), reliably. Many recently proposed approaches  to mitigate this have demonstrated substantial progress in improving DNN calibration. However, they hardly touch upon refinement, which historically has been an essential aspect of calibration. Refinement indicates separability of a network\'s correct and incorrect predictions. This paper presents a theoretically and empirically supported exposition reviewing refinement of a calibrated model. Firstly, we show the breakdown of expected calibration error  (ECE), into predicted confidence and refinement under the assumption of over-confident predictions. Secondly, linking with this result, we highlight that regularisation based calibration only focuses on naively reducing a model\'s confidence. This logically has a severe downside to a model\'s refinement as correct and incorrect predictions become tightly coupled. Lastly, connecting refinement with ECE also provides support to existing refinement based approaches which improve calibration but do not explain the reasoning behind it. We support our claims through rigorous empirical evaluations of many state of the art calibration approaches on widely used datasets and neural networks. We find that many calibration approaches with the likes of label smoothing, mixup etc. lower the usefulness of a DNN by degrading its refinement. Even under natural data shift, this calibration-refinement trade-off holds for the majority of calibration methods.</span>'}
{'title': 'CASR: Generating Complex Sequences with Autoregressive Self-Boost Refinement', 'authors': ['Hongwei Han', 'Mengyu Zhou', 'Shi Han', 'Xiu Li', 'Dongmei Zhang'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 02 Mar 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SVl1w1u3InX&name=pdf', 'abstract': '</span><span class="note_content_value">There are sequence generation tasks where the best order to generate the target sequence is not left-to-right. For example, an answer to the Sudoku game, a structured code like s-expression, and even a logical natural language answer where the analysis may be generated after the decision. We define the target sequences of those tasks as complex sequences. Obviously, a complex sequence should be constructed with multiple logical steps, and has dependencies among each part of itself (e.g. decisions depend on analyses). It\'s a great challenge for the classic left-to-right autoregressive generation system to generate complex sequences. Current approaches improve one-pass left-to-right generation on NLG tasks by generating different heuristic intermediate sequences in multiple stages. However, for complex sequences, the heuristic rules to break down them may hurt performance, and increase additional exposure bias. To tackle these challenges, we propose a PLM-friendly autoregressive self-boost refinement framework, CASR. When training, CASR inputs the predictions generated by the model itself at the previous refinement step (instead of those produced by heuristic rules). To find an optimal design, we also discuss model architecture, parameter efficiency and initialization strategy. By evaluating CASR on Sudoku, WebQSP, MTOP and KVRET through controlled experiments and empirical studies, we find that CASR produces high-quality outputs. CASR also improves Accuracy on Sudoku (70.93% --&gt; 97.28%) and achieves state-of-the-art performance on KVRET with Micro F1 score (67.88% --&gt; 70.00%).</span>'}
{'title': 'Proving Theorems using Incremental Learning and Hindsight Experience Replay', 'authors': ['Eser Aygün', 'Laurent Orseau', 'Ankit Anand', 'Xavier Glorot', 'Vlad Firoiu', 'Lei M Zhang', 'Doina Precup', 'Shibl Mourad'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=QDDVxweQJy0&name=pdf', 'abstract': '</span><span class="note_content_value">Traditional automated theorem provers for first-order logic depend on speed-optimized search and many handcrafted heuristics that are designed to work best over a wide range of domains. Machine learning approaches in literature either depend on these traditional provers to bootstrap themselves or fall short on reaching comparable performance. In this paper, we propose a general incremental learning algorithm for training domain-specific provers for first-order logic without equality, based only on a basic given-clause algorithm, but using a learned clause-scoring function. Clauses are represented as graphs and presented to transformer networks with spectral features. To address the sparsity and the initial lack of training data as well as the lack of a natural curriculum, we adapt hindsight experience replay to theorem proving, so as to be able to learn even when no proof can be found. We show that provers trained this way can match and sometimes surpass state-of-the-art traditional provers on the TPTP dataset in terms of both quantity and quality of the proofs.</span>'}
{'title': 'Learning Approximate Distribution-Sensitive Data Structures', 'authors': ['Zenna Tavares', 'Armando Solar-Lezama'], 'Conference': 'Submitted to ICLR 2017', 'date': '04 Nov 2016 (modified: 21 Jul 2022)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=BJVEEF9lx&name=pdf', 'abstract': '</span><span class="note_content_value">We present a computational model of mental representations as data-structures which are distribution sensitive, i.e., which exploit non-uniformity in their usage patterns to reduce time or space complexity.\nAbstract data types equipped with axiomatic specifications specify classes of concrete data structures with equivalent logical behavior.\nWe extend this formalism to distribution-sensitive data structures with the concept of a probabilistic axiomatic specification, which is implemented by a concrete data structure only with some probability.\nWe employ a number of approximations to synthesize several distribution-sensitive data structures from probabilistic specification as deep neural networks, such as a stack, queue, natural number, set, and binary tree.</span>'}
{'title': 'Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples', 'authors': ['Ashwin Kalyan', 'Abhishek Mohta', 'Oleksandr Polozov', 'Dhruv Batra', 'Prateek Jain', 'Sumit Gulwani'], 'Conference': 'ICLR 2018 Conference Blind Submission', 'date': '15 Feb 2018 (modified: 23 Feb 2018)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rywDjg-RW&name=pdf', 'abstract': '</span><span class="note_content_value">Synthesizing user-intended programs from a small number of input-output exam-\nples is a challenging problem with several important applications like spreadsheet\nmanipulation, data wrangling and code refactoring. Existing synthesis systems\neither completely rely on deductive logic techniques that are extensively hand-\nengineered or on purely statistical models that need massive amounts of data, and in\ngeneral fail to provide real-time synthesis on challenging benchmarks. In this work,\nwe propose Neural Guided Deductive Search (NGDS), a hybrid synthesis technique\nthat combines the best of both symbolic logic techniques and statistical models.\nThus, it produces programs that satisfy the provided specifications by construction\nand generalize well on unseen examples, similar to data-driven systems. Our\ntechnique effectively utilizes the deductive search framework to reduce the learning\nproblem of the neural component to a simple supervised learning setup. Further,\nthis allows us to both train on sparingly available real-world data and still leverage\npowerful recurrent neural network encoders. We demonstrate the effectiveness\nof our method by evaluating on real-world customer scenarios by synthesizing\naccurate programs with up to 12× speed-up compared to state-of-the-art systems.</span>'}
{'title': 'A Semantic Loss Function for Deep Learning with Symbolic Knowledge', 'authors': ['Jingyi Xu', 'Zilu Zhang', 'Tal Friedman', 'Yitao Liang', 'Guy Van den Broeck'], 'Conference': 'ICLR 2018 Conference Blind Submission', 'date': '15 Feb 2018 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HkepKG-Rb&name=pdf', 'abstract': '</span><span class="note_content_value">This paper develops a novel methodology for using symbolic knowledge in deep learning. From first principles, we derive a semantic loss function that bridges between neural output vectors and logical constraints. This loss function captures how close the neural network is to satisfying the constraints on its output. An experimental evaluation shows that our semantic loss function effectively guides the learner to achieve (near-)state-of-the-art results on semi-supervised multi-class classification. Moreover, it significantly increases the ability of the neural network to predict structured objects, such as rankings and shortest paths. These discrete concepts are tremendously difficult to learn, and benefit from a tight integration of deep learning and symbolic reasoning methods.</span>'}
{'title': 'Compositional Visual Generation with Energy Based Models', 'authors': ['Yilun Du', 'Shuang Li', 'Igor Mordatch'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=BygZARVFDH&name=pdf', 'abstract': '</span><span class="note_content_value">Humans are able to both learn quickly and rapidly adapt their knowledge. One major component is the ability to incrementally combine many simple concepts to accelerates the learning process. We show that energy based models are a promising class of models towards exhibiting these properties by directly combining probability distributions. This allows us to combine an arbitrary number of different distributions in a globally coherent manner. We show this compositionality property allows us to define three basic operators, logical conjunction, disjunction, and negation, on different concepts to generate plausible naturalistic images. Furthermore, by applying these abilities, we show that we are able to extrapolate concept combinations, continually combine previously learned concepts, and infer concept properties in a compositional manner.</span>'}
{'title': 'MILE: Memory-Interactive Learning Engine for Solving Mathematical Problems', 'authors': ['Yuxuan Wu', 'Hideki Nakayama'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=nQtcJ24_45K&name=pdf', 'abstract': '</span><span class="note_content_value">Mathematical problem solving is a task that examines the capacity of machine learning models for performing logical reasoning. Existing work employed formulas as intermediate labels in this task to formulate the computing and reasoning processes and achieved remarkable performance. However, we are questioning the limitations of existing methods from two perspectives: the expressive capacity of formulas and the learning capacity of existing models. In this work, we proposed Memory-Interactive Learning Engine (MILE), a new framework for solving mathematical problems. Our main contribution in this work includes a new formula representing technique and a new decoding method. In our experiment on Math23K dataset, MILE outperformed existing methods on not only question answering accuracy but also robustness and generalization capacity.</span>'}
{'title': 'NLProlog: Reasoning with Weak Unification for Natural Language Question Answering', 'authors': ['Leon Weber', 'Pasquale Minervini', 'Ulf Leser', 'Tim Rocktäschel'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ByfXe2C5tm&name=pdf', 'abstract': '</span><span class="note_content_value">Symbolic logic allows practitioners to build systems that perform rule-based reasoning which is interpretable and which can easily be augmented with prior knowledge. However, such systems are traditionally difficult to apply to problems involving natural language due to the large linguistic variability of language. Currently, most work in natural language processing focuses on neural networks which learn distributed representations of words and their composition, thereby performing well in the presence of large linguistic variability. We propose to reap the benefits of both approaches by applying a combination of neural networks and logic programming to natural language question answering. We propose to employ an external, non-differentiable Prolog prover which utilizes a similarity function over pretrained sentence encoders. We fine-tune these representations via Evolution Strategies with the goal of multi-hop reasoning on natural language.  This allows us to create a system that can apply rule-based reasoning to natural language and induce domain-specific natural language rules from training data. We evaluate the proposed system on two different question answering tasks, showing that it complements two very strong baselines – BIDAF (Seo et al., 2016a) and FASTQA (Weissenborn et al.,2017) – and outperforms both when used in an ensemble.</span>'}
{'title': 'A Probabilistic Model for Discriminative and Neuro-Symbolic Semi-Supervised Learning', 'authors': ['Carl Allen', 'Ivana Balazevic', 'Timothy Hospedales'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=PpOtGYNVT6A&name=pdf', 'abstract': '</span><span class="note_content_value">Strong progress has been achieved in semi-supervised learning (SSL) by combining several methods, some of which relate to properties of the data distribution p(x), others to the model outputs p(y|x), e.g. minimising the entropy of unlabelled predictions. Focusing on the latter, we fill a gap in the standard text by introducing a probabilistic model for discriminative semi-supervised learning, mirroring the classical generative model. Several SSL methods are theoretically explained by our model as inducing (approximate) strong priors over parameters of p(y|x). Applying this same probabilistic model to tasks in which labels represent binary attributes, we theoretically justify a family of neuro-symbolic SSL approaches, taking a step towards bridging the divide between statistical learning and logical reasoning.</span>'}
{'title': 'Tree-Structured Variational Autoencoder', 'authors': ['Richard Shin', 'Alexander A. Alemi', 'Geoffrey Irving', 'Oriol Vinyals'], 'Conference': 'Submitted to ICLR 2017', 'date': '04 Nov 2016 (modified: 21 Jul 2022)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Hy0L4t5el&name=pdf', 'abstract': '</span><span class="note_content_value">Many kinds of variable-sized data we would like to model contain an internal hierarchical structure in the form of a tree, including source code, formal logical statements, and natural language sentences with parse trees. For such data it is natural to consider a model with matching computational structure. In this work, we introduce a variational autoencoder-based generative model for tree-structured data. We evaluate our model on a synthetic dataset, and a dataset with applications to automated theorem proving. By learning a latent representation over trees, our model can achieve similar test log likelihood to a standard autoregressive decoder, but with the number of sequentially dependent computations proportional to the depth of the tree instead of the number of nodes in the tree.</span>'}
{'title': 'Towards Generic Interface for Human-Neural Network Knowledge Exchange', 'authors': ['Yunhao Ge', 'Yao Xiao', 'Zhi Xu', 'Linwei Li', 'Ziyan Wu', 'Laurent Itti'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=c8JDlJMBeyh&name=pdf', 'abstract': '</span><span class="note_content_value">Neural Networks (NN) outperform humans in multiple domains. Yet they suffer from a lack of transparency and interpretability, which hinders intuitive and effective human interactions with them. Especially when NN makes mistakes, humans can hardly locate the reason for the error, and correcting it is even harder. While recent advances in explainable AI have substantially improved the explainability of NNs, effective knowledge exchange between humans and NNs is still under-explored. To fill this gap, we propose Human-NN-Interface (HNI), a framework using a structural representation of visual concepts as a ”language” for humans and NN to communicate, interact, and exchange knowledge. Take image classification as an example, HNI visualizes the reasoning logic of a NN with class-specific Structural Concept Graphs (c-SCG), which are human-interpretable. On the other hand, humans can effectively provide feedback and guidance to the NN by modifying the c-SCG, and transferring the knowledge back to NN through HNI. We demonstrate the efficacy of HNI with image classification tasks and 3 different types of interactions: (1) Explaining the reasoning logic of NNs so humans can intuitively identify and locate errors of NN; (2) human users can correct the errors and improve NN’s performance by modifying the c-SCG and distilling the knowledge back to the original NN; (3) human users can intuitively guide NN and provide a new solution for zero-shot learning.</span>'}
{'title': 'Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks', 'authors': ['Yikang Shen', 'Shawn Tan', 'Alessandro Sordoni', 'Aaron Courville'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': 'Published: 20 Dec 2018, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=B1l6qiR5F7&name=pdf', 'abstract': '</span><span class="note_content_value">Natural language is hierarchically structured: smaller units (e.g., phrases) are nested within larger units (e.g., clauses). When a larger constituent ends, all of the smaller constituents that are nested within it must also be closed. While the standard LSTM architecture allows different neurons to track information at different time scales, it does not have an explicit bias towards modeling a hierarchy of constituents. This paper proposes to add such inductive bias by ordering the neurons; a vector of master input and forget gates ensures that when a given neuron is updated, all the neurons that follow it in the ordering are also updated. Our novel recurrent architecture, ordered neurons LSTM (ON-LSTM), achieves good performance on four different tasks: language modeling, unsupervised parsing, targeted syntactic evaluation, and logical inference.</span>'}
{'title': 'Natural Language Inference over Interaction Space', 'authors': ['Yichen Gong', 'Heng Luo', 'Jian Zhang'], 'Conference': 'ICLR 2018 Conference Blind Submission', 'date': '15 Feb 2018 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=r1dHXnH6-&name=pdf', 'abstract': '</span><span class="note_content_value">Natural Language Inference (NLI) task requires an agent to determine the logical relationship between a natural language premise and a natural language hypothesis. We introduce Interactive Inference Network (IIN), a novel class of neural network architectures that is able to achieve high-level understanding of the sentence pair by hierarchically extracting semantic features from interaction space. We show that an interaction tensor (attention weight) contains semantic information to solve natural language inference, and a denser interaction tensor contains richer semantic information. One instance of such architecture, Densely Interactive Inference Network (DIIN), demonstrates the state-of-the-art performance on large scale NLI copora and large-scale NLI alike corpus. It\'s noteworthy that DIIN achieve a greater than 20% error reduction on the challenging Multi-Genre NLI (MultiNLI) dataset with respect to the strongest published system.</span>'}
{'title': 'Entailment Graph Learning with Textual Entailment and Soft Transitivity', 'authors': ['Zhibin Chen', 'Yansong Feng', 'Dongyan Zhao'], 'Conference': 'DLG4NLP 2022 Poster', 'date': 'Published: 28 Apr 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rdZgVwpB-Mq&name=pdf', 'abstract': '</span><span class="note_content_value">Typed entailment graphs try to learn the entailment relations between predicates from text and model them as edges between predicate nodes. The construction of entailment graphs usually suffers from severe sparsity and unreliability of distributional similarity. We propose a two-stage method, Entailment Graph with Textual Entailment and Transitivity (EGT2). EGT2 learns the local entailment relations by recognizing the textual entailment between template sentences formed by typed CCG-parsed predicates. Based on the generated local graph, EGT2 then uses three novel soft transitivity constraints to consider the logical transitivity in entailment structures. Experiments on benchmark datasets show that EGT2 can well model the transitivity in entailment graph to alleviate the sparsity, and leads to significant improvement over current state-of-the-art methods. The released paper can be found in <a href="https://arxiv.org/abs/2204.03286" target="_blank" rel="nofollow">https://arxiv.org/abs/2204.03286</a>.</span>'}
{'title': 'Learning Kolmogorov Models for Binary Random Variables', 'authors': ['Hadi Ghauch', 'Hossein S. Ghadikolaei', 'Mikael Skoglund', 'Carlo Fischione'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=BJfguoAcFm&name=pdf', 'abstract': '</span><span class="note_content_value">We propose a framework for learning a Kolmogorov model, for a collection of binary random variables. More specifically, we derive conditions that link (in the sense of implications in mathematical logic) outcomes of specific random variables and extract valuable relations from the data. We also propose an efficient algorithm for computing the model and show its first-order optimality, despite the combinatorial nature of the learning problem. We exemplify our general framework to recommendation systems and gene expression data. We believe that the work is a significant step toward interpretable machine learning. </span>'}
{'title': 'On the Expressiveness and Learning of Relational Neural Networks on Hypergraphs', 'authors': ['Zhezheng Luo', 'Jiayuan Mao', 'Joshua B. Tenenbaum', 'Leslie Pack Kaelbling'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HRF6T1SsyDn&name=pdf', 'abstract': '</span><span class="note_content_value">This paper presents a framework for analyzing the expressiveness and learning of relational models applied to hypergraph reasoning tasks. We start with a general framework that unifies several relational neural network architectures: graph neural networks, neural logical machines, and transformers. Our first contribution is a fine-grained analysis of the expressiveness of these neural networks, that is, the set of functions that they can realize and the set of problems that they can solve. Our result is a hierarchy of problems they can solve, defined in terms of various hyperparameters such as depth and width. Next, we analyze the learning properties of these neural networks, especially focusing on how they can be trained on a small graphs and generalize to larger graphs. Our theoretical results are further supported by the empirical results illustrating the optimization and generalization of these models based on gradient-descent training.</span>'}
{'title': 'Neural Combinatorial Optimization with Reinforcement Learning : Solving theVehicle Routing Problem with Time Windows', 'authors': ['Abdelhakim Abdellaoui', 'Issmail El Hallaoui', 'Loubna Benabbou'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=gLqnSGXVJ6l&name=pdf', 'abstract': '</span><span class="note_content_value">In contrast to the classical techniques for solving combinatorial optimization problems, recent advancements in reinforcement learning yield the potential to independently learn heuristics without any human interventions. In this context, the current paper aims to present a complete framework for solving the vehicle routing problem with time windows (VRPTW) relying on neural networks and reinforcement learning. Our approach is mainly based on an attention model (AM) that predicts the near-optimal distribution over different problem instances. To optimize its parameters, this model is trained in a reinforcement learning(RL) environment using a stochastic policy gradient and through a real-time evaluation of the reward, quantity to meet the problem business and logical constraints. Using synthetic data, the proposed model outperforms some existing baselines. This performance comparison was on the basis of the solution quality (total tour length) and the computation time (inference time) for small and medium-sized samples.</span>'}
{'title': 'Neural Enquirer: Learning to Query Tables in Natural Language', 'authors': ['Pengcheng Yin', 'Zhengdong Lu', 'Hang Li', 'Ben Kao'], 'Conference': 'ICLR 2016 workshop submission', 'date': '18 Feb 2016', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=3QxgvRAolhp7y9wltPg8&name=pdf', 'abstract': '</span><span class="note_content_value">We propose Neural Enquirer — a neural network architecture for answering natural language (NL) questions given a knowledge base (KB) table. Unlike previous work on end-to-end training of semantic parsers, Neural Enquirer is fully “neuralized”: it gives distributed representations of queries and KB tables, and executes queries through a series of differentiable operations. The model can be trained with gradient descent using both end-to-end and step-by-step supervision. During training the representations of queries and the KB table are jointly optimized with the query execution logic. Our experiments show that the model can learn to execute complex NL queries on KB tables with rich structures.</span>'}
{'title': 'QuAnt: Quantum Annealing with Learnt Couplings', 'authors': ['Marcel Seelbach Benkner', 'Maximilian Krahn', 'Edith Tretschk', 'Zorah Lähner', 'Michael Moeller', 'Vladislav Golyanik'], 'Conference': 'ICLR 2023 notable top 25%', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=isiQ5KIXbjj&name=pdf', 'abstract': '</span><span class="note_content_value">Modern quantum annealers can find high-quality solutions to combinatorial optimisation objectives given as quadratic unconstrained binary optimisation (QUBO) problems. Unfortunately, obtaining suitable QUBO forms in computer vision remains challenging and currently requires problem-specific analytical derivations. Moreover, such explicit formulations impose tangible constraints on solution encodings. In stark contrast to prior work, this paper proposes to learn QUBO forms from data through gradient backpropagation instead of deriving them. As a result, the solution encodings can be  chosen flexibly and compactly. Furthermore, our methodology is general and virtually independent of the specifics of the target problem type. We demonstrate the advantages of learnt  QUBOs on the diverse problem types of graph matching, 2D point cloud alignment and 3D rotation estimation. Our results are competitive with the previous quantum state of the art while requiring much fewer logical and physical qubits, enabling our method to scale to larger problems. The code and the new dataset are available at <a href="https://4dqv.mpi-inf.mpg.de/QuAnt/" target="_blank" rel="nofollow">https://4dqv.mpi-inf.mpg.de/QuAnt/</a>.</span>'}
{'title': 'R5: Rule Discovery with Reinforced and Recurrent Relational Reasoning', 'authors': ['Shengyao Lu', 'Bang Liu', 'Keith G Mills', 'SHANGLING JUI', 'Di Niu'], 'Conference': 'ICLR 2022 Spotlight', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=2eXhNpHeW6E&name=pdf', 'abstract': '</span><span class="note_content_value">Systematicity, i.e., the ability to recombine known parts and rules to form new sequences while reasoning over relational data, is critical to machine intelligence. A model with strong systematicity is able to train on small-scale tasks and generalize to large-scale tasks. In this paper, we propose R5, a relational reasoning framework based on reinforcement learning that reasons over relational graph data and explicitly mines underlying compositional logical rules from observations. R5 has strong systematicity and being robust to noisy data. It consists of a policy value network equipped with Monte Carlo Tree Search to perform recurrent relational prediction and a backtrack rewriting mechanism for rule mining. By alternately applying the two components, R5 progressively learns a set of explicit rules from data and performs explainable and generalizable relation prediction. We conduct extensive evaluations on multiple datasets. Experimental results show that R5 outperforms various embedding-based and rule induction baselines on relation prediction tasks while achieving a high recall rate in discovering ground truth rules. </span>'}
{'title': 'TransINT: Embedding Implication Rules in Knowledge Graphs with Isomorphic Intersections of Linear Subspaces', 'authors': ['So Yeon Min', 'Preethi Raghavan', 'Peter Szolovits'], 'Conference': 'ICLR 2020 Conference Withdrawn Submission', 'date': '25 Sept 2019 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=r1lxvxBtvr&name=pdf', 'abstract': '</span><span class="note_content_value">Knowledge Graphs (KG), composed of entities and relations, provide a structured representation of knowledge. For easy access to statistical approaches on relational data, multiple methods to embed a KG as components of R^d have been introduced. We propose TransINT, a novel and interpretable KG embedding method that isomorphically preserves the implication ordering among relations in the embedding space. TransINT maps set of entities (tied by a relation) to continuous sets of vectors that are inclusion-ordered isomorphically to relation implications. With a novel parameter sharing scheme, TransINT enables automatic training on missing but implied facts without rule grounding. We achieve new state-of-the-art performances with signficant margins in Link Prediction and Triple Classification on FB122 dataset, with boosted performance even on test instances that cannot be inferred by logical rules. The angles between the continuous sets embedded by TransINT provide an interpretable way to mine semantic relatedness and implication rules among relations. </span>'}
{'title': 'Net-DNF: Effective Deep Modeling of Tabular Data', 'authors': ['Liran Katzir', 'Gal Elidan', 'Ran El-Yaniv'], 'Conference': 'ICLR 2021 Poster', 'date': 'Published: 12 Jan 2021, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=73WTGs96kho&name=pdf', 'abstract': '</span><span class="note_content_value">A challenging open question in deep learning is how to handle tabular data. Unlike domains such as image and natural language processing, where deep architectures prevail, there is still no widely accepted neural architecture that dominates tabular data. As a step toward bridging this gap, we present Net-DNF a novel generic architecture whose inductive bias elicits models whose structure corresponds to logical Boolean formulas in disjunctive normal form (DNF) over affine soft-threshold decision terms. Net-DNFs also promote localized decisions that are taken over small subsets of the features. We present an extensive experiments showing that Net-DNFs significantly and consistently outperform fully connected networks over tabular data. With relatively few hyperparameters, Net-DNFs open the door to practical end-to-end handling of tabular data using neural networks. We present ablation studies, which justify the design choices of Net-DNF including the inductive bias elements, namely, Boolean formulation, locality, and feature selection. \n</span>'}
{'title': 'Matrix Shuffle-Exchange Networks for Hard 2D Tasks', 'authors': ['Emīls Ozoliņš', 'Karlis Freivalds', 'Agris Šostaks'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Ns8v4jHGyAV&name=pdf', 'abstract': '</span><span class="note_content_value">Convolutional neural networks have become the main tools for processing two-dimensional data. They work well for images, yet convolutions have a limited receptive field that prevents its applications to more complex 2D tasks. We propose a new neural model, called Matrix Shuffle-Exchange network, that can efficiently exploit long-range dependencies in 2D data and has comparable speed to a convolutional neural network. It is derived from  Neural Shuffle-Exchange network and has <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c4F TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-n"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-texatom space="2" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">O</mi></mrow><mo stretchy="false">(</mo><mi>log</mi><mo data-mjx-texclass="NONE">\u2061</mo><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> layers and <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-cal mjx-i"><mjx-c class="mjx-c4F TEX-C"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup><mjx-mi class="mjx-n" space="2"><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c67"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2061"></mjx-c></mjx-mo><mjx-texatom space="2" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi data-mjx-variant="-tex-calligraphic" mathvariant="script">O</mi></mrow><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mi>log</mi><mo data-mjx-texclass="NONE">\u2061</mo><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> total time and space complexity for processing a <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-cD7"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>×</mo><mi>n</mi></math></mjx-assistive-mml></mjx-container> data matrix. We show that the Matrix Shuffle-Exchange network is well-suited for algorithmic and logical reasoning tasks on matrices and dense graphs, exceeding convolutional and graph neural network baselines. Its distinct advantage is the capability of retaining full long-range dependency modelling when generalizing to larger instances -- much larger than could be processed with models equipped with a dense attention mechanism.</span>'}
{'title': 'Knowledge Graph Completion as Tensor Decomposition: A Genreal Form and Tensor N-rank Regularization', 'authors': ['Changyi Xiao', 'Xiangnan He', 'Yixin Cao'], 'Conference': 'ICLR 2022 Conference Withdrawn Submission', 'date': '28 Sept 2021 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=TFzHbrMveuZ&name=pdf', 'abstract': '</span><span class="note_content_value">Knowledge graph completion (KGC) is a 3rd-order binary tensor completion task. Tensor decomposition based (TDB) models have shown great performance in KGC. In this paper, we summarize existing TDB models and derive a general form for them. Based on the general form, we show the principles of model design to satisfy logical rules. However, these models suffer from the overfitting problem severely. Therefore, we propose a regularization term based on the tensor <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container>-rank which enforces the low-rankness of the tensor. First, we relax the tensor <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></mjx-assistive-mml></mjx-container>-rank to the sum of the nuclear norms of the unfolding matrix along each mode of the tensor. In order to be computationally efficient, we further give an upper bound of the sum of the nuclear norms. Finally, we use the upper bound as the regularization term to achieve low-rank matrix decomposition of each unfolding matrix. Experiments show that our model achieves state-of-the-art performance on benchmark datasets.</span>'}
{'title': 'Explainable GNN-Based Models over Knowledge Graphs', 'authors': ['David Jaime Tena Cucala', 'Bernardo Cuenca Grau', 'Egor V. Kostylev', 'Boris Motik'], 'Conference': 'ICLR 2022 Poster', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=CrCvGNHAIrz&name=pdf', 'abstract': '</span><span class="note_content_value">Graph Neural Networks (GNNs) are often used to learn transformations of graph data. While effective in practice, such approaches make predictions via numeric manipulations so their output cannot be easily explained symbolically. We propose a new family of GNN-based transformations of graph data that can be trained effectively, but where all predictions can be explained symbolically as logical inferences in Datalog—a well-known rule-based formalism. In particular, we show how to encode an input knowledge graph into a graph with numeric feature vectors, process this graph using a GNN, and decode the result into an output knowledge graph. We use a new class of monotonic GNNs (MGNNs) to ensure that this process is equivalent to a round of application of a set of Datalog rules. We also show that, given an arbitrary MGNN, we can automatically extract rules that completely characterise the transformation. We evaluate our approach by applying it to classification tasks in knowledge graph completion.</span>'}
{'title': 'Composing Features: Compositional Model Augmentation for Steerability of Music Transformers', 'authors': ['Halley Young', 'Vincent Dumoulin', 'Pablo Samuel Castro', 'Jesse Engel', 'Cheng-Zhi Anna Huang'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Xa8sKVPnDJq&name=pdf', 'abstract': '</span><span class="note_content_value">Music is a combinatorial art. Given a starting sequence, many continuations are possible, yet often only one is written down. With generative models, we can explore many. However, finding a continuation with specific combinations of features (such as rising pitches, with block chords played in syncopated rhythm) can take many trials.\nTo tackle the combinatorial nature of composing features, we propose a compositional approach to steering music transformers, building on lightweight fine-tuning methods such as prefix tuning and bias tuning. We introduce a novel contrastive loss function that enables us to steer compositional models over logical features using supervised learning. We examine the difficulty in steering based on whether features musically follow a prime or not, using existing music as a proxy. We show that with a relatively small number of extra parameters, our method allows bias tuning to perform successful fine-tuning in both the single-feature and compositional setting.</span>'}
{'title': 'New Definitions and Evaluations for Saliency Methods: Staying Intrinsic and Sound', 'authors': ['Arushi Gupta', 'Nikunj Saunshi', 'Dingli Yu', 'Kaifeng Lyu', 'Sanjeev Arora'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Mo9R9oqzPo&name=pdf', 'abstract': '</span><span class="note_content_value">  Saliency methods seek to provide human-interpretable explanations for the output of machine learning model on a given input. A plethora of saliency methods exist, as well as an extensive literature on their justifications/criticisms/evaluations. This paper focuses on heat maps based saliency methods that often provide explanations that look best to humans. It tries to introduce methods and evaluations for masked-based saliency methods that are {\\em intrinsic} --- use just the training dataset and the trained net, and do not use separately trained nets, distractor distributions, human evaluations or annotations. Since a mask can be seen as a "certificate" justifying the net\'s answer, we introduce notions of {\\em completeness} and {\\em soundness} (the latter being the new contribution) motivated by logical proof systems. These notions allow a new evaluation of  saliency methods, that experimentally provides a novel and stronger justification for several heuristic tricks in the field (T.V. regularization, upscaling). </span>'}
{'title': 'Sentence Ordering using Recurrent Neural Networks', 'authors': ['Lajanugen Logeswaran', 'Honglak Lee', 'Dragomir Radev'], 'Conference': 'Submitted to ICLR 2017', 'date': '03 Nov 2016 (modified: 21 Jul 2022)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=S1AG8zYeg&name=pdf', 'abstract': '</span><span class="note_content_value">Modeling the structure of coherent texts is a task of great importance in NLP. The task of organizing a given set of sentences into a coherent order has been\ncommonly used to build and evaluate models that understand such structure. In this work we propose an end-to-end neural approach based on the recently proposed\nset to sequence mapping framework to address the sentence ordering problem. Our model achieves state-of-the-art performance in the order discrimination task\non two datasets widely used in the literature. We also consider a new interesting task of ordering abstracts from conference papers and research proposals and\ndemonstrate strong performance against recent methods. Visualizing the sentence representations learned by the model shows that the model has captured high\nlevel logical structure in these paragraphs. The model also learns rich semantic sentence representations by learning to order texts, performing comparably to\nrecent unsupervised representation learning methods in the sentence similarity and paraphrase detection tasks.</span>'}
{'title': 'Code Summarization: Do Transformers Really Understand Code?', 'authors': ['Ankita Nandkishor Sontakke', 'Manasi Patwardhan', 'Lovekesh Vig', 'Raveendra Kumar Medicherla', 'Ravindra Naik', 'Gautam Shroff'], 'Conference': 'DL4C 2022', 'date': 'Published: 25 Mar 2022, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rI5ll2_-1Zc&name=pdf', 'abstract': '</span><span class="note_content_value">Recent approaches for automatic code summarization rely on fine-tuned transformer-based language Models often injected with program analysis information. We perform empirical studies to analyze the extent to which these models understand the code they attempt to summarize. We observe that these models rely heavily on the textual cues present in comments/function names/variable names and that masking this information negatively impacts the generated summaries. Further, subtle code transformations which drastically alter program logic have no corresponding impact on the generated summaries. Overall, the quality of the generated summaries even from state-of-the-art (SOTA)  models is quite poor, raising questions about the utility of current approaches and datasets.</span>'}
{'title': 'A Representation Bottleneck of Bayesian Neural Networks', 'authors': ['Qihan Ren', 'Huiqi Deng', 'Yunuo Chen', 'Siyu Lou', 'Quanshi Zhang'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=DWDPhB6Hi7k&name=pdf', 'abstract': '</span><span class="note_content_value">Unlike standard deep neural networks (DNNs), Bayesian neural networks (BNNs) formulate network weights as probability distributions, which results in distinctive representation capacities from standard DNNs. In this paper, we explore the representation bottleneck of BNNs from the perspective of conceptual representations. It is proven that the logic of a neural network can be faithfully mimicked by a specific sparse causal graph, where each causal pattern can be considered as a concept encoded by the neural network. Then, we formally define the complexity of concepts, and prove that compared to standard DNNs, it is more difficult for BNNs to encode complex concepts. Extensive experiments verify our theoretical proofs. The code will be released when the paper is accepted.</span>'}
{'title': 'Seq2SQL: Generating Structured Queries From Natural Language Using Reinforcement Learning', 'authors': ['Victor Zhong', 'Caiming Xiong', 'Richard Socher'], 'Conference': 'ICLR 2018 Conference Blind Submission', 'date': '15 Feb 2018 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Syx6bz-Ab&name=pdf', 'abstract': '</span><span class="note_content_value">Relational databases store a significant amount of the worlds data. However, accessing this data currently requires users to understand a query language such as SQL. We propose Seq2SQL, a deep neural network for translating natural language questions to corresponding SQL queries. Our model uses rewards from in the loop query execution over the database to learn a policy to generate the query, which contains unordered parts that are less suitable for optimization via cross entropy loss. Moreover, Seq2SQL leverages the structure of SQL to prune the space of generated queries and significantly simplify the generation problem. In addition to the model, we release WikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL queries distributed across 24241 tables fromWikipedia that is an order of magnitude larger than comparable datasets. By applying policy based reinforcement learning with a query execution environment to WikiSQL, Seq2SQL outperforms a state-of-the-art semantic parser, improving execution accuracy from 35.9% to 59.4% and logical form accuracy from 23.4% to 48.3%.</span>'}
{'title': 'Cut the CARP: Fishing for zero-shot story evaluation', 'authors': ['Shahbuland Matiana', 'JR Smith', 'Ryan Teehan', 'Louis Castricato', 'Stella Biderman', 'Leo Gao', 'Spencer Frazier'], 'Conference': 'ICLR 2022 Conference Withdrawn Submission', 'date': '28 Sept 2021 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=e6MVRAlKWGD&name=pdf', 'abstract': '</span><span class="note_content_value">Recent advances in large-scale language models (Raffel et al., 2019; Brown et al., 2020) have brought significant qualitative and quantitative improvements in machine-driven text generation. Despite this, generation and evaluation of machine-generated narrative text remains a challenging problem. Objective evaluation of computationally-generated stories may be prohibitively expensive, require meticulously annotated datasets, or may not adequately measure the logical coherence of a generated story’s narratological structure. Informed by recent advances in contrastive learning (Radford et al., 2021),we present Contrastive Authoring and Reviewing Pairing (CARP): a scalable, efficient method for performing qualitatively superior, zero-shot evaluation of stories. We show a strong correlation between human evaluation of stories and those of CARP. Model outputs more significantly correlate with corresponding human input than those language-model based methods which utilize finetuning or prompt engineering approaches. We also present and analyze the Story-Critique Dataset, a new corpora composed of 1.3 million aligned story-critique pairs derived from over 80,000 stories. We expect this corpus to be of interest to NLP researchers.</span>'}
{'title': 'LambdaNet: Probabilistic Type Inference using Graph Neural Networks', 'authors': ['Jiayi Wei', 'Maruth Goyal', 'Greg Durrett', 'Isil Dillig'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Hkx6hANtwH&name=pdf', 'abstract': '</span><span class="note_content_value">As gradual typing becomes increasingly popular in languages like Python and TypeScript, there is a growing need to infer type annotations automatically. While type annotations help with tasks like code completion and static error catching, these annotations cannot be fully inferred by compilers and are tedious to annotate by hand. This paper proposes a probabilistic type inference scheme for TypeScript based on a graph neural network. Our approach first uses lightweight source code analysis to generate a program abstraction called a type dependency graph, which links type variables with logical constraints as well as name and usage information. Given this program abstraction, we then use a graph neural network to propagate information between related type variables and eventually make type predictions. Our neural architecture can predict both standard types, like number or string, as well as user-defined types that have not been encountered during training. Our experimental results show that our approach outperforms prior work in this space by 14% (absolute) on library types, while having the ability to make type predictions that are out of scope for existing techniques. </span>'}
{'title': 'Learning to Infer Run-Time Invariants from Source code', 'authors': ['Vincent Josua Hellendoorn', 'Premkumar Devanbu', 'Alex Polozov', 'Mark Marron'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=dzZaIeG9-fW&name=pdf', 'abstract': '</span><span class="note_content_value">Source code is notably different from natural language in that it is meant to be executed. Experienced developers infer complex "invariants" about run-time state while reading code, which helps them to constrain and predict program behavior. Knowing these invariants can be helpful; yet developers rarely encode these explicitly, so machine-learning methods don\'t have much aligned data to learn from. We propose an approach that adapts cues within existing if-statements  regarding explicit run-time expectations to generate aligned datasets of code and implicit invariants. We also propose a contrastive loss to inhibit generation of illogical invariants. Our model learns to infer a wide vocabulary of invariants for arbitrary code, which can be used to detect and repair real bugs. This is entirely complementary to established approaches, which either use logical engines that scale poorly, or run-time traces that are expensive to obtain; when present, that data can complement our tool, as we demonstrate in conjunction with Daikon, an existing tool. Our results show that neural models can derive useful representations of run-time behavior directly from source code.</span>'}
{'title': 'RRL: A Scalable Classifier for Interpretable Rule-Based Representation Learning', 'authors': ['Zhuo Wang', 'Wei Zhang', 'Ning Liu', 'Jianyong Wang'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=UwOMufsTqCy&name=pdf', 'abstract': '</span><span class="note_content_value">Rule-based models, e.g., decision trees, are widely used in scenarios demanding high model interpretability for their transparent inner structures and good model expressivity. However, rule-based models are hard to optimize, especially on large data sets, due to their discrete parameters and structures. Ensemble methods and fuzzy/soft rules are commonly used to tackle these issues, but they sacrifice the model interpretability. In this paper, we propose a new classifier, named Rule-based Representation Learner (RRL), that automatically learns interpretable non-fuzzy rules for data representation. To train the non-differentiable RRL effectively, we project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to discretize the continuous features end-to-end. Exhaustive experiments on 9 small and 4 large data sets show that RRL outperforms the competitive approaches, has low complexity close to the simple decision trees, and is rational for its main technical contributions.</span>'}
{'title': 'Do Transformers Understand Polynomial Simplification?', 'authors': ['Vishesh Agarwal', 'Somak Aditya', 'Navin Goyal'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=yZkF6xqhfQ&name=pdf', 'abstract': '</span><span class="note_content_value">Recently researchers have demonstrated that Transformers can be trained to learn symbolic tasks such as solving integration and differential equations in an end-to-end fashion. In these setups, for an input symbolic expression, the Transformer predicts the final solution in a single step. Since such tasks may consist of a sequence of logical steps, question remains whether such networks have understood and learnt individual steps to reach the solution. To take a deeper look, we consider the task of polynomial simplification. Polynomials can be written in a simple normal form as a sum of monomials which are ordered in a lexicographic order. For a polynomial which is not necessarily in this normal form, a sequence of simplification steps is applied to reach the fully simplified (i.e., in the normal form) polynomial. For this task, we describe a synthetic Polynomial dataset generation algorithm which generates polynomials with unique proof steps. Then, we conduct an extensive analysis of the Transformer’s abilities to learn the polynomial simplification task along different dimensions.</span>'}
{'title': 'Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small', 'authors': ['Kevin Ro Wang', 'Alexandre Variengien', 'Arthur Conmy', 'Buck Shlegeris', 'Jacob Steinhardt'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 01 Mar 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=NpsVSN6o4ul&name=pdf', 'abstract': '</span><span class="note_content_value">Research in mechanistic interpretability seeks to explain behaviors of ML models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models, or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task that requires logical reasoning: indirect object identification (IOI). Our explanation encompasses 28 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches including causal interventions and projections.\nTo our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior "in the wild" in a language model.  We evaluate the reliability of our explanation using three quantitative criteria - faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. \nOur work provides evidence that a mechanistic understanding of large ML models is feasible, opening opportunities to scale our understanding to both larger models and more complex tasks.</span>'}
{'title': 'Therbligs in Action: Video Understanding through Motion Primitives', 'authors': ['Eadom T Dessalene', 'Michael Maynord', 'Cornelia Fermuller', 'Yiannis Aloimonos'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rpWw6Ki2b5s&name=pdf', 'abstract': '</span><span class="note_content_value">In this paper we introduce a rule-based, compositional, and hierarchical modelling of action using Therbligs as our atoms - a consistent, expressive, contact-centered representation of action. Over these atoms we introduce a differentiable method of rule-based reasoning to regularize for logical consistency. Our approach is complementary to other approaches in that the Therblig-based representations produced by our architecture augment rather than replace existing architectures\' representations. We release the first Therblig-centered annotations over two popular video datasets - EPIC Kitchens 100 and 50-Salads. We evaluate our system for the task of action segmentation, demonstrating a substantial improvement using a base GRU architecture over baseline of 5.6% and 4.1% (14.4% and 6.5% relative) increase in accuracy (and increases with respect to all other metrics as well) over EPIC Kitchens and 50-Salads, respectively. We also demonstrate benefits to adopting Therblig representations for two state-of-the-art approaches - MSTCN++ and ASFormer - observing a 10.3%/10.7% relative improvement, respectively, over EPIC Kitchens and 9.3%/6.1% relative improvement, respectively, over 50 Salads. All code and data is to be released upon paper acceptance.</span>'}
{'title': 'Learning to Reason in Large Theories without Imitation', 'authors': ['Kshitij Bansal', 'Christian Szegedy', 'Markus Norman Rabe', 'Sarah M. Loos', 'Viktor Toman'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=qbRv1k2AcH&name=pdf', 'abstract': '</span><span class="note_content_value">In this paper, we demonstrate how to do automated higher-order logic theorem proving in the presence of a large knowledge base of potential premises without learning from human proofs. We augment the exploration of premises based on a simple tf-idf (term frequency-inverse document frequency) based lookup in a deep reinforcement learning scenario. Our experiments show that our theorem prover trained with this exploration mechanism but no human proofs, dubbed DeepHOL Zero, outperforms provers that are trained only on human proofs. It approaches the performance of a prover trained by a combination of imitation and reinforcement learning. We perform multiple experiments to understand the importance of the underlying assumptions that make our exploration approach work, thus explaining our design choices.</span>'}
{'title': 'Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer', 'authors': ['Zhun Yang', 'Adam Ishay', 'Joohyung Lee'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 03 Mar 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=udNhDCr2KQe&name=pdf', 'abstract': '</span><span class="note_content_value">Constraint satisfaction problems (CSPs) are about finding values of variables that satisfy the given constraints. We show that Transformer extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over state-of-the-art methods such as Graph Neural Networks, SATNet, and some neuro-symbolic models. With the ability of Transformer to handle visual input, the proposed Recurrent Transformer can straightforwardly be applied to visual constraint reasoning problems while successfully addressing the symbol grounding problem. We also show how to leverage deductive knowledge of discrete constraints in the Transformer\'s inductive learning to achieve sample-efficient learning and semi-supervised learning for CSPs.</span>'}
{'title': 'Thinking Like Transformers', 'authors': ['Gail Weiss', 'Yoav Goldberg', 'Eran Yahav'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=TmkN9JmDJx1&name=pdf', 'abstract': '</span><span class="note_content_value">What is the computational model behind a transformer? Where recurrent neural networks have direct parallels in finite state machines, allowing clear discussion and thought around architecture variants or trained models, transformers have no such familiar parallel. In this paper we aim to change that, proposing a computational model for the transformer-encoder in the form of a programming language. We map the basic components of a transformer-encoder – attention and feed-forward computation – into the simple primitives of select, aggregate, and zipmap, around which we form a programming language: the Restricted Access Sequence Process-ing Language (RASP). We show how RASP can be used to program solutions to tasks that could conceivably be learned by a transformer, augmenting it with tools we discover in our work. In particular, we provide RASP programs for histograms, sorting, and even logical inference similar to that of Clark et al. (2020). We further use our model to relate their difficulty in terms of the number of required layers and attention heads. Finally, we see how insights gained from our abstraction might be used to explain phenomena seen in recent works.</span>'}
{'title': 'Learning a Natural Language Interface with Neural Programmer', 'authors': ['Arvind Neelakantan', 'Quoc V. Le', 'Martin Abadi', 'Andrew McCallum', 'Dario Amodei'], 'Conference': 'ICLR 2017 Poster', 'date': 'Published: 21 Jul 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ry2YOrcge&name=pdf', 'abstract': '</span><span class="note_content_value">Learning a natural language interface for database tables is a challenging task that involves deep language understanding and multi-step reasoning. The task is often approached by mapping natural language queries to logical forms or programs that provide the desired response when executed on the database. To our knowledge, this paper presents the first weakly supervised, end-to-end neural network model to induce such programs on a real-world dataset. We enhance the objective function of Neural Programmer, a neural network with built-in discrete operations, and apply it on WikiTableQuestions, a natural language question-answering dataset. The model is trained end-to-end with weak supervision of question-answer pairs, and does not require domain-specific grammars, rules, or annotations that are key elements in previous approaches to program induction. The main experimental result in this paper is that a single Neural Programmer model achieves 34.2% accuracy using only 10,000 examples with weak supervision. An ensemble of 15 models, with a trivial combination technique, achieves 37.7% accuracy, which is competitive to the current state-of-the-art accuracy of 37.1% obtained by a traditional natural language semantic parser.</span>'}
{'title': "What's in a name? The Influence of Personal Names on Spatial Reasoning in BLOOM Large Language Models", 'authors': ['Sumit Kumar Jha', 'Rickard Ewetz', 'Alvaro Velasquez', 'Susmit Jha'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=hZ2H2Ps5dp6&name=pdf', 'abstract': '</span><span class="note_content_value">Large language models have been shown to exhibit reasoning capability. But the ability of these models to truly comprehend the reasoning task is not yet clear. An ideal model capable of reasoning would not be affected by the names of the entities over which the relations are defined. In this paper, we consider an algorithmically generated spatial reasoning task over the names of persons. We show that the choice of names has a significant impact on the reasoning accuracy of BLOOM large language models. Using popular names from different countries of the world, we show that BLOOM large language models are susceptible to undesirable variations in reasoning ability even though the underlying logical reasoning challenge does not depend on these names. We further identify that the conditional log probability scores characterizing the uncertainty in prediction produced by BLOOM models are not well-calibrated and cannot be used to detect such reasoning errors. We then suggest a new approach based on model self-explanations and iterative model introspection that performs better than BLOOM conditional log probability scores in detecting such errors and may help alleviate the bias exhibited by these models.</span>'}
{'title': 'Edge Partition Modulated Graph Convolutional Networks', 'authors': ['Yilin He', 'Chaojie Wang', 'Hao Zhang', 'Bo Chen', 'Mingyuan Zhou'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ET1UAOYeU42&name=pdf', 'abstract': '</span><span class="note_content_value">Graph convolutional networks (GCNs), which propagate the node features through the edges and learn how to transform the aggregated features under label supervision, have achieved great success in supervised feature extraction for both graph-level and node-level classification tasks. However, GCNs typically treat the graph adjacency matrix as given and ignore how the edges could be formed by different latent inter-node relations. In this paper, we introduce a relational graph generative process to model how the observed edges are generated by aggregating the node interactions over multiple overlapping node communities, each of which represents a particular type of relation that contributes to the edges via a logical OR mechanism. Based on this relational generative model, we partition each edge into the summation of multiple relation-specific weighted edges, and use the weighted edges in each community to define a relation-specific GCN. We introduce a variational inference framework to jointly learn how to partition the edges into different communities and combine relation-specific GCNs for the end classification tasks. Extensive evaluations on real-world datasets have demonstrated the working mechanisms of the edge partition modulated GCNs and their efficacy in learning both node and graph-level representations.</span>'}
{'title': 'Combining Learned Representations for Combinatorial Optimization', 'authors': ['Saavan Patel', 'Sayeef Salahuddin'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SkeQniAqK7&name=pdf', 'abstract': '</span><span class="note_content_value">We propose a new approach to combine Restricted Boltzmann Machines (RBMs) that can be used to solve combinatorial optimization problems. This allows synthesis of larger models from smaller RBMs that have been pretrained, thus effectively bypassing the problem of learning in large RBMs, and creating a system able to model a large, complex multi-modal space. We validate this approach by using learned representations to create ``invertible boolean logic\'\', where we can use Markov chain Monte Carlo (MCMC) approaches to find the solution to large scale boolean satisfiability problems and show viability towards other combinatorial optimization problems. Using this method, we are able to solve 64 bit addition based problems, as well as factorize 16 bit numbers. We find that these combined representations can provide a more accurate result for the same sample size as compared to a fully trained model.  </span>'}
{'title': 'Formulating and Proving the Trend of DNNs Learning Simple Concepts', 'authors': ['Dongrui Liu', 'Huiqi Deng', 'Xu Cheng', 'Qihan Ren', 'Kangrui Wang', 'Quanshi Zhang'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=pG9RSmBrY3&name=pdf', 'abstract': '</span><span class="note_content_value">This paper theoretically explains the intuition that simple concepts are more likely to be learned by deep neural networks (DNNs) than complex concepts. Beyond empirical studies, our research first specifies an exact definition of the complexity of the concept that boosts the learning difficulty. Specifically, it is proven that the inference logic of a neural network can be represented as a causal graph. In this way, causal patterns in the causal graph can be used to formulate interactive concepts learned by the neural network. Based on such formulation, we explain the reason why simple interactive concepts in the data are more likely to be learned than complex interactive concepts. More crucially, we discover that our research provides a new perspective to explain previous understandings of the conceptual complexity. The code will be released when the paper is accepted.</span>'}
{'title': 'In a Nutshell, the Human Asked for This: Latent Goals for Following Temporal Specifications', 'authors': ['Borja G. León', 'Murray Shanahan', 'Francesco Belardinelli'], 'Conference': 'ICLR 2022 Poster', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rUwm9wCjURV&name=pdf', 'abstract': '</span><span class="note_content_value">We address the problem of building agents whose goal is to learn to execute out-of distribution (OOD) multi-task instructions expressed in temporal logic (TL) by using deep reinforcement learning (DRL). Recent works provided evidence that the agent\'s neural architecture is a key feature when DRL agents are learning to solve OOD tasks in TL. Yet, the studies on this topic are still in their infancy. In this work, we propose a new deep learning configuration with inductive biases that lead agents to generate latent representations of their current goal, yielding a stronger generalization performance. We use these latent-goal networks within a neuro-symbolic framework that executes multi-task formally-defined instructions and contrast the performance of the proposed neural networks against employing different state-of-the-art (SOTA) architectures when generalizing to unseen instructions in OOD environments. </span>'}
{'title': 'Multimodal Subtask Graph Generation from Instructional Videos', 'authors': ['Yunseok Jang', 'Sungryull Sohn', 'Lajanugen Logeswaran', 'Tiange Luo', 'Moontae Lee', 'Honglak Lee'], 'Conference': 'MRL 2023', 'date': 'Published: 06 Mar 2023, Last Modified: 01 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=zJhWyDcmgNs&name=pdf', 'abstract': '</span><span class="note_content_value">Real-world tasks consist of multiple inter-dependent subtasks (e.g., a dirty pan needs to be washed before cooking). In this work, we aim to model the causal dependencies between such subtasks from instructional videos describing the task. This is a challenging problem since complete information about the world is often inaccessible from videos, which demands robust learning mechanisms to understand the causal structure of events. We present Multimodal Subtask Graph Generation (MSG<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-n"></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi></mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container>), an approach that constructs a Subtask Graph defining the dependency between a task’s subtasks relevant to a task from noisy web videos. Graphs generated by our multimodal approach are closer to human-annotated graphs compared to prior approaches. MSG<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-mi class="mjx-n"></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi></mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container> further performs the downstream task of next subtask prediction 85% and 30% more accurately than recent video transformer models in the ProceL and CrossTask datasets, respectively.</span>'}
{'title': 'Learning Symbolic Rules for Reasoning in Quasi-Natural Language', 'authors': ['Kaiyu Yang', 'Jia Deng'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=7zFokR7k_86&name=pdf', 'abstract': '</span><span class="note_content_value">Symbolic reasoning, rule-based symbol manipulation, is a hallmark of human intelligence.  However, rule-based systems have had limited success competing with learning-based systems outside formalized domains such as automated theorem proving. We hypothesize that this is due to the manual construction of rules in past attempts. In this work, we ask how we can build a rule-based system that can reason with natural language input but without the manual construction of rules. We propose MetaQNL, a "Quasi-Natural" language that can express both formal logic and natural language sentences, and MetaInduce, a learning algorithm that induces MetaQNL rules from training data consisting of questions and answers, with or without intermediate reasoning steps. Our approach achieves state-of-the-art accuracy on multiple reasoning benchmarks; it learns compact models with much less data and produces not only answers but also checkable proofs.</span>'}
{'title': 'Deep Reasoning Networks: Thinking Fast and Slow, for Pattern De-mixing', 'authors': ['Di Chen', 'Yiwei Bai', 'Wenting Zhao', 'Sebastian Ament', 'John M. Gregoire', 'Carla P. Gomes'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HkehD3VtvS&name=pdf', 'abstract': '</span><span class="note_content_value">We introduce Deep Reasoning Networks (DRNets), an end-to-end framework that combines deep learning with reasoning for solving pattern de-mixing problems, typically in an unsupervised or weakly-supervised setting.  DRNets exploit problem structure and prior knowledge by tightly combining logic and constraint reasoning with stochastic-gradient-based neural network optimization.  We illustrate the power of DRNets on de-mixing overlapping hand-written Sudokus (Multi-MNIST-Sudoku) and on a substantially more complex task in scientific discovery that concerns inferring crystal structures of materials from X-ray diffraction data (Crystal-Structure-Phase-Mapping). DRNets significantly outperform the state of the art and experts\' capabilities on Crystal-Structure-Phase-Mapping, recovering more precise and physically meaningful crystal structures. On Multi-MNIST-Sudoku, DRNets perfectly recovered the mixed Sudokus\' digits, with 100% digit accuracy, outperforming the supervised state-of-the-art MNIST de-mixing models.</span>'}
{'title': 'S3TA: A Soft, Spatial, Sequential, Top-Down Attention Model', 'authors': ['Alex Mott', 'Daniel Zoran', 'Mike Chrzanowski', 'Daan Wierstra', 'Danilo J. Rezende'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=B1gJOoRcYQ&name=pdf', 'abstract': '</span><span class="note_content_value">We present a soft, spatial, sequential, top-down attention model (S3TA). This model uses a soft attention mechanism to bottleneck its view of the input. A recurrent core is used to generate query vectors, which actively select information from the input by correlating the query with input- and space-dependent key maps at different spatial locations.\n\nWe demonstrate the power and interpretabilty of this model under two settings. First, we build an agent which uses this attention model in RL environments and show that we can achieve performance competitive with state-of-the-art models while producing attention maps that elucidate some of the strategies used to solve the task. Second, we use this model in supervised learning tasks and show that it also achieves competitive performance and provides interpretable attention maps that show some of the underlying logic in the model\'s decision making.</span>'}
{'title': 'SCAN: Learning Hierarchical Compositional Visual Concepts', 'authors': ['Irina Higgins', 'Nicolas Sonnerat', 'Loic Matthey', 'Arka Pal', 'Christopher P Burgess', 'Matko Bošnjak', 'Murray Shanahan', 'Matthew Botvinick', 'Demis Hassabis', 'Alexander Lerchner'], 'Conference': 'ICLR 2018 Conference Blind Submission', 'date': '15 Feb 2018 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rkN2Il-RZ&name=pdf', 'abstract': '</span><span class="note_content_value">The seemingly infinite diversity of the natural world arises from a relatively small set of coherent rules, such as the laws of physics or chemistry. We conjecture that these rules give rise to regularities that can be discovered through primarily unsupervised experiences and represented as abstract concepts. If such representations are compositional and hierarchical, they can be recombined into an exponentially large set of new concepts. This paper describes SCAN (Symbol-Concept Association Network), a new framework for learning such abstractions in the visual domain. SCAN learns concepts through fast symbol association, grounding them in disentangled visual primitives that are discovered in an unsupervised manner. Unlike state of the art multimodal generative model baselines, our approach requires very few pairings between symbols and images and makes no assumptions about the form of symbol representations. Once trained, SCAN is capable of multimodal bi-directional inference, generating a diverse set of image samples from symbolic descriptions and vice versa. It also allows for traversal and manipulation of the implicit hierarchy of visual concepts through symbolic instructions and learnt logical recombination operations. Such manipulations enable SCAN to break away from its training data distribution and imagine novel visual concepts through symbolically instructed recombination of previously learnt concepts.</span>'}
{'title': 'Discovering Latent Knowledge in Language Models Without Supervision', 'authors': ['Collin Burns', 'Haotian Ye', 'Dan Klein', 'Jacob Steinhardt'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ETKGuby0hcs&name=pdf', 'abstract': '</span><span class="note_content_value">Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can\'t detect. We propose circumventing this issue by directly finding latent knowledge inside the internal activations of a language model in a purely unsupervised way. Specifically, we introduce a method for accurately answering yes-no questions given only unlabeled model activations. It works by finding a direction in activation space that satisfies logical consistency properties, such as that a statement and its negation have opposite truth values. We show that despite using no supervision and no model outputs, our method can recover diverse knowledge represented in large language models: across 6 models and 10 question-answering datasets, it outperforms zero-shot accuracy by 4\\% on average. We also find that it cuts prompt sensitivity in half and continues to maintain high accuracy even when models are prompted to generate incorrect answers. Our results provide an initial step toward discovering what language models know, distinct from what they say, even when we don\'t have access to explicit ground truth labels.</span>'}
{'title': 'Differentiable learning of numerical rules in knowledge graphs', 'authors': ['Po-Wei Wang', 'Daria Stepanova', 'Csaba Domokos', 'J. Zico Kolter'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rJleKgrKwS&name=pdf', 'abstract': '</span><span class="note_content_value">Rules over a knowledge graph (KG) capture interpretable patterns in data and can be used for KG cleaning and completion. Inspired by the TensorLog differentiable logic framework, which compiles rule inference into a sequence of differentiable operations, recently a method called Neural LP has been proposed for learning the parameters as well as the structure of rules. However, it is limited with respect to the treatment of numerical features like age, weight or scientific measurements. We address this limitation by extending Neural LP to learn rules with numerical values, e.g., ”People younger than 18 typically live with their parents“. We demonstrate how dynamic programming and cumulative sum operations can be exploited to ensure efficiency of such extension. Our novel approach allows us to extract more expressive rules with aggregates, which are of higher quality and yield more accurate predictions compared to rules learned by the state-of-the-art methods, as shown by our experiments on synthetic and real-world datasets.</span>'}
{'title': 'Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation', 'authors': ['Byung Hoon Ahn', 'Prannoy Pilligundla', 'Amir Yazdanbakhsh', 'Hadi Esmaeilzadeh'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 05 May 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rygG4AVFvH&name=pdf', 'abstract': '</span><span class="note_content_value">Achieving faster execution with shorter compilation time can foster further diversity and innovation in neural networks. However, the current paradigm of executing neural networks either relies on hand-optimized libraries, traditional compilation heuristics, or very recently genetic algorithms and other stochastic methods. These methods suffer from frequent costly hardware measurements rendering them not only too time consuming but also suboptimal. As such, we devise a solution that can learn to quickly adapt to a previously unseen design space for code optimization, both accelerating the search and improving the output performance. This solution dubbed Chameleon leverages reinforcement learning whose solution takes fewer steps to converge, and develops an adaptive sampling algorithm that not only focuses on the costly samples (real hardware measurements) on representative points but also uses a domain-knowledge inspired logic to improve the samples itself. Experimentation with real hardware shows that Chameleon provides 4.45x speed up in optimization time over AutoTVM, while also improving inference time of the modern deep networks by 5.6%.</span>'}
{'title': 'Evidence-Aware Entropy Decomposition For Active Deep Learning', 'authors': ['Weishi Shi', 'Xujiang Zhao', 'Feng Chen', 'Qi Yu'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=B1lC62EKwr&name=pdf', 'abstract': '</span><span class="note_content_value">We present a novel multi-source uncertainty prediction approach that enables deep learning (DL) models to be actively trained with much less labeled data. By leveraging the second-order uncertainty representation provided by subjective logic (SL), we conduct evidence-based theoretical analysis and formally decompose the predicted entropy over multiple classes into two distinct sources of uncertainty: vacuity and dissonance, caused by lack of evidence and conflict of strong evidence, respectively. The evidence based entropy decomposition provides deeper insights on the nature of uncertainty, which can help effectively explore a large and high-dimensional unlabeled data space. We develop a novel loss function that augments DL based evidence prediction with uncertainty anchor sample identification through kernel density estimation (KDE). The accurately estimated multiple sources of uncertainty are systematically integrated and dynamically balanced using a data sampling function for label-efficient active deep learning (ADL). Experiments conducted over both synthetic and real data and comparison with competitive AL methods demonstrate the effectiveness of the proposed ADL model.   </span>'}
{'title': 'Multi-Task Learning for Semantic Parsing with Cross-Domain Sketch', 'authors': ['Huan Wang', 'Yuxiang Hu', 'Li Dong', 'Feijun Jiang', 'Zaiqing Nie'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=r1fO8oC9Y7&name=pdf', 'abstract': '</span><span class="note_content_value">Semantic parsing which maps a natural language sentence into a formal machine-readable representation of its meaning, is highly constrained by the limited annotated training data. Inspired by the idea of coarse-to-fine, we propose a general-to-detailed neural network(GDNN) by incorporating cross-domain sketch(CDS) among utterances and their logic forms. For utterances in different domains, the General Network will extract CDS using an encoder-decoder model in a multi-task learning setup. Then for some utterances in a specific domain, the Detailed Network will generate the detailed target parts using sequence-to-sequence architecture with advanced attention to both utterance and generated CDS. Our experiments show that compared to direct multi-task learning, CDS has improved the performance in semantic parsing task which converts users\' requests into meaning representation language(MRL). We also use experiments to illustrate that CDS works by adding some constraints to the target decoding process, which further proves the effectiveness and rationality of CDS.</span>'}
{'title': 'Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought', 'authors': ['Abulhair Saparov', 'He He'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 01 Mar 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=qFVVBzXxR2V&name=pdf', 'abstract': '</span><span class="note_content_value">Large language models (LLMs) have shown remarkable reasoning capabilities given chain-of-thought prompts (examples with intermediate reasoning steps). Existing benchmarks measure reasoning ability indirectly, by evaluating accuracy on downstream tasks such as mathematical reasoning. However, it is unclear how these models obtain the answers and whether they rely on simple heuristics rather than the generated chain-of-thought. To enable systematic exploration of the reasoning ability of LLMs, we present a new synthetic question-answering dataset called PrOntoQA, where each example is generated from a synthetic world model represented in first-order logic. This allows us to parse the generated chain-of-thought into symbolic proofs for formal analysis. Our analysis on InstructGPT and GPT-3 shows that LLMs are quite capable of making correct individual deduction steps, and so are generally capable of reasoning, even in fictional contexts. However, they have difficulty with proof planning: When multiple valid deduction steps are available, they are not able to systematically explore the different options.</span>'}
{'title': 'Unified Probabilistic Modeling of Image Aesthetic Rating Distributions towards Measuring Subjectivity', 'authors': ['Hyeongnam Jang', 'Yeejin Lee', 'Jong-Seok Lee'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rEKl9rzR7S&name=pdf', 'abstract': '</span><span class="note_content_value">Assessing image aesthetics is a challenging computer vision task. One reason is that aesthetic preference is highly subjective and may vary significantly among people for certain images. Thus, it is important to properly model and quantify such subjectivity, but there has not been much effort to resolve this issue. In this paper, we propose a novel unified probabilistic framework that can model and quantify subjective aesthetic preference based on the subjective logic. In this framework, the distribution of aesthetic ratings is modeled as a beta distribution, from which the probabilities of being definitely pleasing, being definitely unpleasing, and being uncertain can be obtained. We use the probability of being uncertain to define an intuitive metric of subjectivity. Furthermore, we present a method to learn deep neural networks for prediction of image aesthetics, which is shown to be effective in improving the performance of subjectivity prediction via experiments. We also present an application scenario where the framework is beneficial for aesthetics-based image recommendation.</span>'}
{'title': 'Structured Federated Aggregation for Personalizing On-device Intelligence', 'authors': ['Fengwen Chen', 'Guodong Long', 'Tianyi Zhou', 'Zonghan Wu', 'Jing Jiang'], 'Conference': 'ICLR 2022 Conference Withdrawn Submission', 'date': '28 Sept 2021 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=E9UL8UJvysW&name=pdf', 'abstract': '</span><span class="note_content_value">Personalizing on-device intelligence with privacy-preserving is an emerging requirement for the Mobile Internet and many other service areas. The recent development of federated learning is to embody personalization by tackling statistical heterogeneity across devices. However, these methods ignore the structural information between clients which can indicate a similar behavior pattern or decision logic among clients who are connected to each other in a graph. For example, the traffic condition is very similar to its adjacent blocks. Motivated by this assumption, we propose structured federated learning(SFL) to update each device\'s personalized model by leveraging its neighbors\' local model. This problem has been formulated to a new optimization problem to integrate the prediction loss, federated aggregation, and structured aggregation into a unified framework. Moreover, it could be further enhanced by adding the structure learning component to learn the relation graph in the same optimization framework. The effectiveness of the proposed method has been demonstrated in experimental analysis by comparing it with other baselines in public datasets.</span>'}
{'title': 'Deep Epitome for Unravelling Generalized Hamming Network: A Fuzzy Logic Interpretation of Deep Learning', 'authors': [], 'Conference': 'ICLR 2018 Conference Withdrawn Submission', 'date': '04 Jan 2018 (modified: 25 Jan 2018)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=r1PaPUsXM&name=pdf', 'abstract': '</span><span class="note_content_value">This paper gives a rigorous analysis of trained Generalized Hamming Networks (GHN) proposed by Fan (2017) and discloses an interesting finding about GHNs, i.e. stacked convolution layers in a GHN is equivalent to a single yet wide convolution layer. The revealed equivalence, on the theoretical side, can be regarded as a constructive manifestation of the universal approximation theorem Cybenko (1989); Hornik (1991). In practice, it has profound and multi-fold implications. For network visualization, the constructed deep epitomes at each layer provide a visualization of network internal representation that does not rely on the input data. Moreover, deep epitomes allows the direct extraction of features in just one step, without resorting to regularized optimizations used in existing visualization tools.</span>'}
{'title': 'Adversarial Spheres', 'authors': ['Justin Gilmer', 'Luke Metz', 'Fartash Faghri', 'Sam Schoenholz', 'Maithra Raghu', 'Martin Wattenberg'], 'Conference': 'ICLR 2018 Conference Blind Submission', 'date': '15 Feb 2018 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SyUkxxZ0b&name=pdf', 'abstract': '</span><span class="note_content_value">    State of the art computer vision models have been shown to be vulnerable to small adversarial perturbations of the input. In other words, most images in the data distribution are both correctly classified by the model and are very close to a visually similar misclassified image. Despite substantial research interest, the cause of the phenomenon is still poorly understood and remains unsolved. We hypothesize that this counter intuitive behavior is a naturally occurring result of the high dimensional geometry of the data manifold. As a first step towards exploring this hypothesis, we study a simple synthetic dataset of classifying between two concentric high dimensional spheres. For this dataset we show a fundamental tradeoff between the amount of test error and the average distance to nearest error. In particular, we prove that any model which misclassifies a small constant fraction of a sphere will be vulnerable to adversarial perturbations of size <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.156em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><msqrt><mi>d</mi></msqrt><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>. Surprisingly, when we train several different architectures on this dataset, all of their error sets naturally approach this theoretical bound. As a result of the theory, the vulnerability of neural networks to small adversarial perturbations is a logical consequence of the amount of test error observed. We hope that our theoretical analysis of this very simple case will point the way forward to explore how the geometry of complex real-world data sets leads to adversarial examples.</span>'}
{'title': 'Adversarial Spheres', 'authors': ['Justin Gilmer', 'Luke Metz', 'Fartash Faghri', 'Samuel S. Schoenholz', 'Maithra Raghu', 'Martin Wattenberg', 'Ian Goodfellow'], 'Conference': 'ICLR 2018 Workshop Submission', 'date': '30 Jan 2018 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=rJ1a97Rrf&name=pdf', 'abstract': '</span><span class="note_content_value">State of the art computer vision models have been shown to be vulnerable to small adversarial perturbations of the input. In other words, most images in the data distribution are both correctly classified by the model and are very close to a visually similar misclassified image. Despite substantial research interest, the cause of the phenomenon is still poorly understood and remains unsolved. We hypothesize that this counter intuitive behavior is a naturally occurring result of the high dimensional geometry of the data manifold. As a first step towards exploring this hypothesis, we study a simple synthetic dataset of classifying between two concentric high dimensional spheres. For this dataset we show a fundamental tradeoff between the amount of test error and the average distance to nearest error. In particular, we prove that any model which misclassifies a small constant fraction of a sphere will be vulnerable to adversarial perturbations of size <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.156em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><msqrt><mi>d</mi></msqrt><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>. Surprisingly, when we train several different architectures on this dataset, all of their error sets naturally approach this theoretical bound. As a result of the theory, the vulnerability of neural networks to small adversarial perturbations is a logical consequence of the amount of test error observed. We hope that our theoretical analysis of this very simple case will point the way forward to explore how the geometry of complex real-world data sets leads to adversarial examples.</span>'}
{'title': 'Adversarial Spheres', 'authors': ['Justin Gilmer', 'Luke Metz', 'Fartash Faghri', 'Samuel S. Schoenholz', 'Maithra Raghu', 'Martin Wattenberg', 'Ian Goodfellow'], 'Conference': 'ICLR 2018 Workshop Submission', 'date': '12 Feb 2018 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SkthlLkPf&name=pdf', 'abstract': '</span><span class="note_content_value">State of the art computer vision models have been shown to be vulnerable to small adversarial perturbations of the input. In other words, most images in the data distribution are both correctly classified by the model and are very close to a visually similar misclassified image. Despite substantial research interest, the cause of the phenomenon is still poorly understood and remains unsolved. We hypothesize that this counter intuitive behavior is a naturally occurring result of the high dimensional geometry of the data manifold. As a first step towards exploring this hypothesis, we study a simple synthetic dataset of classifying between two concentric high dimensional spheres. For this dataset we show a fundamental tradeoff between the amount of test error and the average distance to nearest error. In particular, we prove that any model which misclassifies a small constant fraction of a sphere will be vulnerable to adversarial perturbations of size <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-msqrt><mjx-sqrt><mjx-surd><mjx-mo class="mjx-n"><mjx-c class="mjx-c221A"></mjx-c></mjx-mo></mjx-surd><mjx-box style="padding-top: 0.156em;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-box></mjx-sqrt></mjx-msqrt><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><msqrt><mi>d</mi></msqrt><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>. Surprisingly, when we train several different architectures on this dataset, all of their error sets naturally approach this theoretical bound. As a result of the theory, the vulnerability of neural networks to small adversarial perturbations is a logical consequence of the amount of test error observed. We hope that our theoretical analysis of this very simple case will point the way forward to explore how the geometry of complex real-world data sets leads to adversarial examples.</span>'}
{'title': 'Complex Query Answering with Neural Link Predictors', 'authors': ['Erik Arakelyan', 'Daniel Daza', 'Pasquale Minervini', 'Michael Cochez'], 'Conference': 'ICLR 2021 Oral', 'date': 'Published: 12 Jan 2021, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Mos9F9kDwkz&name=pdf', 'abstract': '</span><span class="note_content_value">Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2227"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∧</mo></math></mjx-assistive-mml></mjx-container>), disjunctions (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2228"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∨</mo></math></mjx-assistive-mml></mjx-container>) and existential quantifiers (<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c2203"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">∃</mi></math></mjx-assistive-mml></mjx-container>), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at <a href="https://github.com/uclnlp/cqd" target="_blank" rel="nofollow">https://github.com/uclnlp/cqd</a>.</span>'}
{'title': 'Why Does the VQA Model Answer No?: Improving Reasoning through Visual and Linguistic Inference', 'authors': ['Seungjun Jung', 'Junyoung Byun', 'Kyujin Shim', 'Changick Kim'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HJlvCR4KDS&name=pdf', 'abstract': '</span><span class="note_content_value">In order to make Visual Question Answering (VQA) explainable, previous studies not only visualize the attended region of a VQA model but also generate textual explanations for its answers. However, when the model’s answer is ‘no,’ existing methods have difficulty in revealing detailed arguments that lead to that answer. In addition, previous methods are insufficient to provide logical bases, when the question requires common sense to answer. In this paper, we propose a novel textual explanation method to overcome the aforementioned limitations. First, we extract keywords that are essential to infer an answer from a question. Second, for a pre-trained explanation generator, we utilize a novel Variable-Constrained\nBeam Search (VCBS) algorithm to generate phrases that best describes the relationship between keywords in images. Then, we complete an explanation by feeding the phrase to the generator. Furthermore, if the answer to the question is “yes” or “no,” we apply Natural Langauge Inference (NLI) to identify whether contents of the question can be inferred from the explanation using common sense. Our user study, conducted in Amazon Mechanical Turk (MTurk), shows that our proposed method generates more reliable explanations compared to the previous methods. Moreover, by modifying the VQA model’s answer through the output of the NLI model, we show that VQA performance increases by 1.1% from the original model.</span>'}
{'title': 'Ternary Weight Decomposition and Binary Activation Encoding for Fast and Compact Neural Network', 'authors': ['Mitsuru Ambai', 'Takuya Matsumoto', 'Takayoshi Yamashita', 'Hironobu Fujiyoshi'], 'Conference': 'Submitted to ICLR 2017', 'date': '02 Nov 2016 (modified: 21 Jul 2022)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=ByOK0rwlx&name=pdf', 'abstract': '</span><span class="note_content_value">This paper aims to reduce test-time computational load of a deep neural network. Unlike previous methods which factorize a weight matrix into multiple real-valued matrices, our method factorizes both weights and activations into integer and noninteger components. In our method, the real-valued weight matrix is approximated by a multiplication of a ternary matrix and a real-valued co-efficient matrix. Since the ternary matrix consists of three integer values, {-1, 0, +1}, it only consumes 2 bits per element. At test-time, an activation vector that passed from a previous layer is also transformed into a weighted sum of binary vectors, {-1, +1}, which enables fast feed-forward propagation based on simple logical operations: AND, XOR, and bit count. This makes it easier to deploy a deep network on low-power CPUs or to design specialized hardware.\nIn our experiments, we tested our method on three different networks: a CNN for handwritten digits, VGG-16 model for ImageNet classification, and VGG-Face for large-scale face recognition. In particular, when we applied our method to three fully connected layers in the VGG-16, 15x acceleration and memory compression up to 5.2% were achieved with only a 1.43% increase in the top-5 error. Our experiments also revealed that compressing convolutional layers can accelerate inference of the entire network in exchange of slight increase in error.</span>'}
{'title': 'Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs', 'authors': ['Forough Arabshahi', 'Sameer Singh', 'Animashree Anandkumar'], 'Conference': 'ICLR 2018 Conference Blind Submission', 'date': '15 Feb 2018 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=Hksj2WWAW&name=pdf', 'abstract': '</span><span class="note_content_value">Neural programming involves training neural networks to learn programs, mathematics, or logic from data. Previous works have failed to achieve good generalization performance, especially on problems and programs with high complexity or on large domains. This is because they mostly rely either on black-box function evaluations that do not capture the structure of the program, or on detailed execution traces that are expensive to obtain, and hence the training data has poor coverage of the domain under consideration. We present a novel framework that utilizes black-box function evaluations, in conjunction with symbolic expressions that define relationships between the given functions. We employ tree LSTMs to incorporate the structure of the symbolic expression trees. We use tree encoding for numbers present in function evaluation data, based on their decimal representation. We present an evaluation benchmark for this task to demonstrate our proposed model combines symbolic reasoning and function evaluation in a fruitful manner, obtaining high accuracies in our experiments. Our framework generalizes significantly better to expressions of higher depth and is able to fill partial equations with valid completions.</span>'}
{'title': 'Learning Symbolic Rules for Reasoning in Quasi-Natural Language', 'authors': ['Kaiyu Yang', 'Jia Deng'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=tjvEnPYc3Yq&name=pdf', 'abstract': '</span><span class="note_content_value">Symbolic reasoning, rule-based symbol manipulation, is a hallmark of human intelligence. However, rule-based systems have had limited success competing with learning-based systems outside formalized domains such as automated theorem proving. We hypothesize that this is due to the manual construction of rules in past attempts. In this work, we aim to build a rule-based system that can reason with natural language but without manually constructing rules. We propose MetaQNL, a "Quasi-Natural Language" that can express both formal logic and natural language sentences, and MetaInduce, a learning algorithm that induces MetaQNL rules from training data consisting of questions and answers, with or without intermediate reasoning steps. In addition, we introduce soft matching—a flexible mechanism for applying rules without rigid matching, overcoming a typical source of brittleness in symbolic reasoning. Our approach achieves state-of-the-art accuracy on multiple reasoning benchmarks; it learns compact models with much less data and produces not only answers but also checkable proofs. Further, experiments on two simple real-world datasets demonstrate the possibility for our method to handle noise and ambiguity.</span>'}
{'title': 'CrossBeam: Learning to Search in Bottom-Up Program Synthesis', 'authors': ['Kensen Shi', 'Hanjun Dai', 'Kevin Ellis', 'Charles Sutton'], 'Conference': 'ICLR 2022 Poster', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=qhC8mr2LEKq&name=pdf', 'abstract': '</span><span class="note_content_value">Many approaches to program synthesis perform a search within an enormous space of programs to find one that satisfies a given specification. Prior works have used neural models to guide combinatorial search algorithms, but such approaches still explore a huge portion of the search space and quickly become intractable as the size of the desired program increases. To tame the search space blowup, we propose training a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm. Our approach, called CrossBeam, uses the neural model to choose how to combine previously-explored programs into new programs, taking into account the search history and partial program executions. Motivated by work in structured prediction on learning to search, CrossBeam is trained on-policy using data extracted from its own bottom-up searches on training tasks. We evaluate CrossBeam in two very different domains, string manipulation and logic programming. We observe that CrossBeam learns to search efficiently, exploring much smaller portions of the program space compared to the state-of-the-art.\n</span>'}
{'title': 'Neural Arithmetic Units', 'authors': ['Andreas Madsen', 'Alexander Rosenberg Johansen'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': 'Published: 19 Dec 2019, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=H1gNOeHKPS&name=pdf', 'abstract': '</span><span class="note_content_value">Neural networks can approximate complex functions, but they struggle to perform exact arithmetic operations over real numbers. The lack of inductive bias for arithmetic operations leaves neural networks without the underlying logic necessary to extrapolate on tasks such as addition, subtraction, and multiplication. We present two new neural network components: the Neural Addition Unit (NAU), which can learn exact addition and subtraction; and the Neural Multiplication Unit (NMU) that can multiply subsets of a vector. The NMU is, to our knowledge, the first arithmetic neural network component that can learn to multiply elements from a vector, when the hidden size is large. The two new components draw inspiration from a theoretical analysis of recently proposed arithmetic components. We find that careful initialization, restricting parameter space, and regularizing for sparsity is important when optimizing the NAU and NMU. Our proposed units NAU and NMU, compared with previous neural units, converge more consistently, have fewer parameters, learn faster, can converge for larger hidden sizes, obtain sparse and meaningful weights, and can extrapolate to negative and small values.</span>'}
{'title': 'Interventional Black-Box Explanations', 'authors': ['Ola Ahmad', 'Simon Corbeil', 'Vahid Hashemi', 'Freddy Lecue'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=97WDkHzofx&name=pdf', 'abstract': '</span><span class="note_content_value">Deep Neural Networks (DNNs) are powerful systems able to freely evolve on their own from training data. However, like any highly parametrized mathematical model, capturing the explanation of any prediction of such models is rather difficult. We believe that there exist relevant mechanisms inside the structure of post-hoc DNNs that supports transparency and interpretability. To capture these mechanisms, we quantify the effects of parameters (pieces of knowledge) on models\' predictions using the framework of causality. We introduce a general formalism of the causal diagram to express cause-effect relations inside the DNN\'s architecture. Then, we develop a novel algorithm to construct explanations of DNN\'s predictions using the <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi><mi>o</mi></math></mjx-assistive-mml></mjx-container>-operator. We call our method, Interventional Black-Box Explanations. On image classification tasks, we explain the behaviour of the model and extract visual explanations from the effects of the causal filters in convolution layers. We qualitatively demonstrate that our method captures more informative concepts compared to traditional attribution-based methods.         \nFinally, we believe that our method is orthogonal to logic-based explanation methods and can be leveraged to improve their explanations.</span>'}
{'title': 'Natural Language Descriptions of Deep Visual Features', 'authors': ['Evan Hernandez', 'Sarah Schwettmann', 'David Bau', 'Teona Bagashvili', 'Antonio Torralba', 'Jacob Andreas'], 'Conference': 'ICLR 2022 Oral', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=NudBMY-tzDr&name=pdf', 'abstract': '</span><span class="note_content_value">Some neurons in deep networks specialize in recognizing highly specific perceptual, structural, or semantic features of inputs. In computer vision, techniques exist for identifying neurons that respond to individual concept categories like colors, textures, and object classes. But these techniques are limited in scope, labeling only a small subset of neurons and behaviors in any network. Is a richer characterization of neuron-level computation possible? We introduce a procedure (called MILAN, for mutual information-guided linguistic annotation of neurons) that automatically labels neurons with open-ended, compositional, natural language descriptions. Given a neuron, MILAN generates a description by searching for a natural language string that maximizes pointwise mutual information with the image regions in which the neuron is active. MILAN produces fine-grained descriptions that capture categorical, relational, and logical structure in learned features. These descriptions obtain high agreement with human-generated feature descriptions across a diverse set of model architectures and tasks, and can aid in understanding and controlling learned models. We highlight three applications of natural language neuron descriptions. First, we use MILAN for analysis, characterizing the distribution and importance of neurons selective for attribute, category, and relational information in vision models. Second, we use MILAN for auditing, surfacing neurons sensitive to human faces in datasets designed to obscure them. Finally, we use MILAN for editing, improving robustness in an image classifier by deleting neurons sensitive to text features spuriously correlated with class labels.</span>'}
{'title': 'On Incorporating Semantic Prior Knowlegde in Deep Learning Through Embedding-Space Constraints', 'authors': ['Damien Teney', 'Ehsan Abbasnejad', 'Anton van den Hengel'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=H1ggKyrYwB&name=pdf', 'abstract': '</span><span class="note_content_value">The knowledge that humans hold about a problem often extends far beyond a set of training data and output labels. While the success of deep learning mostly relies on supervised training, important properties cannot be inferred efficiently from end-to-end annotations alone, for example causal relations or domain-specific invariances. We present a general technique to supplement supervised training with prior knowledge expressed as relations between training instances. We illustrate the method on the task of visual question answering to exploit various auxiliary annotations, including relations of equivalence and of logical entailment between questions. Existing methods to use these annotations, including auxiliary losses and data augmentation, cannot guarantee the strict inclusion of these relations into the model since they require a careful balancing against the end-to-end objective. Our method uses these relations to shape the embedding space of the model, and treats them as strict constraints on its learned representations. %The resulting model encodes relations that better generalize across instances. In the context of VQA, this approach brings significant improvements in accuracy and robustness, in particular over the common practice of incorporating the constraints as a soft regularizer. We also show that incorporating this type of prior knowledge with our method brings consistent improvements, independently from the amount of supervised data used. It demonstrates the value of an additional training signal that is otherwise difficult to extract from end-to-end annotations alone.</span>'}
{'title': 'ThinkSum: Probabilistic reasoning over sets using large language models', 'authors': ['Batu Ozturkler', 'Nikolay Malkin', 'Zhen Wang', 'Nebojsa Jojic'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HdYxZ_OVZG&name=pdf', 'abstract': '</span><span class="note_content_value">Large language models (LLMs) have a substantial capacity for high-level analogical reasoning: reproducing patterns in linear text that occur in their training data (zero-shot evaluation) or in the provided context (few-shot in-context learning). However, recent studies show that even the largest LLMs fail in scenarios that require reasoning over multiple objects or facts or making sequences of logical deductions. We propose a two-stage probabilistic inference paradigm, ThinkSum, that reasons over sets of objects or facts in a structured manner. In the first stage (Think -- \'fast\' retrieval of associations), a LLM is queried in parallel over a set of phrases extracted from the prompt or an auxiliary model call. In the second stage (Sum -- \'slow\' probabilistic inference or reasoning), the results of these queries are aggregated to make the final prediction. We demonstrate the advantages of ThinkSum on the BIG-bench suite of evaluation tasks, achieving improvements over the state of the art using GPT-family models on ten difficult tasks, often with far smaller model variants. We compare and contrast ThinkSum with other proposed modifications to direct prompting of LLMs, such as variants of chain-of-thought prompting. We argue that because the probabilistic inference in ThinkSum is performed outside of calls to the LLM, ThinkSum is less sensitive to prompt design, yields more interpretable predictions, and can be flexibly combined with latent variable models to extract structured knowledge from LLMs.</span>'}
{'title': 'EM-RBR: a reinforced framework for knowledge graph completion from reasoning perspective', 'authors': ['Bozhou Chen', 'Zhaochong An', 'Houde Quan', 'Qihui Lin', 'Hongzhi Wang'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=EKw6nZ4QkJl&name=pdf', 'abstract': '</span><span class="note_content_value">Knowledge graph completion aims to predict the new links in given entities among the knowledge graph (KG). Most mainstream embedding methods focus on fact triplets contained in the given KG, however, ignoring the rich background information provided by logic rules driven from knowledge base implicitly. To solve this problem, in this paper, we propose a general framework, named EM-RBR(embedding and rule-based reasoning), capable of combining the advantages of reasoning based on rules and the state-of-the-art models of embedding. EM-RBR aims to utilize relational background knowledge contained in rules to conduct multi-relation reasoning link prediction rather than superficial vector triangle linkage in embedding models. By this way, we can explore relation between two entities in deeper context to achieve higher accuracy. In experiments, we demonstrate that EM-RBR achieves better performance compared with previous models on FB15k, WN18 and our new dataset FB15k-R, especially the new dataset where our model perform futher better than those state-of-the-arts. We make the implementation of EM-RBR available at <a href="https://github.com/1173710224/link-prediction-with-rule-based-reasoning" target="_blank" rel="nofollow">https://github.com/1173710224/link-prediction-with-rule-based-reasoning</a>.</span>'}
{'title': 'IID-GAN: an IID Sampling Perspective for Regularizing Mode Collapse', 'authors': ['Liangliang Shi', 'Yang Li', 'Alan Yuhan Xi', 'Junchi Yan'], 'Conference': 'ICLR 2022 Conference Withdrawn Submission', 'date': '28 Sept 2021 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=k0pi7xDoDTC&name=pdf', 'abstract': '</span><span class="note_content_value">Despite its success, generative adversarial networks (GANs) still suffer from mode collapse, namely the generator can only map latent variables to a partial set of modes of the target distribution. In this paper, we analyze and try to regularize this issue with an independent and identically distributed (IID) sampling perspective and emphasize that holding the IID property for generation for target distribution (i.e. real distribution) can naturally avoid mode collapse. This is based on the basic IID assumption for real data in machine learning. However, though the source samples <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D433 TEX-B"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">z</mi></mrow></math></mjx-assistive-mml></mjx-container> obey IID, the generation <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D433 TEX-B"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>G</mi><mo stretchy="false">(</mo><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">z</mi></mrow><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container> may not necessarily be IID from the target distribution.  Based on this observation, we propose a necessary condition of IID generation and provide a new loss to encourage the closeness between the inverse source of real data and the Gaussian source in the latent space to regularize the generation to be IID from the target distribution. The logic is that the inverse samples from target data should also be IID in the source distribution. Experiments on both synthetic and real-world data show the effectiveness of our model.</span>'}
{'title': 'Strategies for Classification Layer Initialization in Model-Agnostic Meta-Learning', 'authors': ['Nys Tjade Siegel', 'Thomas Goerttler', 'Klaus Obermayer'], 'Conference': 'Blogposts @ ICLR 2023 Conditional', 'date': 'Published: 02 May 2023, Last Modified: 02 May 2023', 'link': 'PDF not available', 'abstract': '</span><span class="note_content_value">In a previous study, Raghu et al. [2020] found that in model-agnostic meta-learning (MAML) for few-shot classification, the majority of changes observed in the network during the inner loop fine-tuning process occurred in the linear classification head. It is commonly believed that during this phase, the linear head remaps encoded features to the classes of the new task. In traditional MAML, the weights of the final linear layer are meta-learned in the usual way. However, there are some issues with this approach:\nFirst, it is difficult to imagine that a single set of optimal weights can be learned. This becomes apparent when considering class label permutations: two different tasks may have the same classes but in a different order. As a result, the weights that perform well for the first task will likely not be effective for the second task. This is reflected in the fact that MAML’s performance can vary by up to 15% depending on the class label assignments during testing.\nSecond, more challenging datasets such as Meta-Dataset are being proposed as few-shot learning benchmarks. These datasets have varying numbers of classes per task, making it impossible to learn a single set of weights for the classification layer.\nTherefore, it seems logical to consider how to initialize the final classification layer before fine-tuning on a new task. Random initialization may not be optimal, as it can introduce unnecessary noise.\nThis blog post will discuss different approaches to the last layer initialization that claim to outperform the original MAML method.</span>'}
{'title': 'Knowledge-driven Active Learning', 'authors': ['Gabriele Ciravegna', 'Frederic Precioso', 'Marco Gori'], 'Conference': 'ICLR 2022 Conference Withdrawn Submission', 'date': '28 Sept 2021 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=JzwLTPuG0fo&name=pdf', 'abstract': '</span><span class="note_content_value">In the last few years, Deep Learning models have become increasingly popular. However, their deployment is still precluded in those contexts where the amount of supervised data is limited and manual labelling expensive. Active learning strategies aim at solving this problem by requiring supervision only on few unlabelled samples, which improve the most model performances after adding them to the training set. Most strategies are based on uncertain sample selection, and even often restricted to samples lying close to the decision boundary. Here we propose a very different approach, taking into consideration domain knowledge. Indeed, in the case of multi-label classification, the relationships among classes offer a way to spot incoherent predictions, i.e., predictions where the model may most likely need supervision. We have developed a framework where first-order-logic knowledge is converted into constraints and their violation is checked as a natural guide for sample selection. We empirically demonstrate that knowledge-driven strategy outperforms standard strategies, particularly on those datasets where domain knowledge is complete. Furthermore, we show how the proposed approach enables discovering data distributions lying far from training data. Finally, the proposed knowledge-driven strategy can be also easily used in object-detection problems where standard uncertainty-based techniques are difficult to apply.</span>'}
{'title': 'Possibility Before Utility: Learning And Using Hierarchical Affordances', 'authors': ['Robby Costales', 'Shariq Iqbal', 'Fei Sha'], 'Conference': 'ICLR 2022 Spotlight', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=7b4zxUnrO2N&name=pdf', 'abstract': '</span><span class="note_content_value">Reinforcement learning algorithms struggle on tasks with complex hierarchical dependency structures. Humans and other intelligent agents do not waste time assessing the utility of every high-level action in existence, but instead only consider ones they deem possible in the first place. By focusing only on what is feasible, or "afforded\'\', at the present moment, an agent can spend more time both evaluating the utility of and acting on what matters. To this end, we present Hierarchical Affordance Learning (HAL), a method that learns a model of hierarchical affordances in order to prune impossible subtasks for more effective learning. Existing works in hierarchical reinforcement learning provide agents with structural representations of subtasks but are not affordance-aware, and by grounding our definition of hierarchical affordances in the present state, our approach is more flexible than the multitude of approaches that ground their subtask dependencies in a symbolic history. While these logic-based methods often require complete knowledge of the subtask hierarchy, our approach is able to utilize incomplete and varying symbolic specifications. Furthermore, we demonstrate that relative to non-affordance-aware methods, HAL agents are better able to efficiently learn complex tasks, navigate environment stochasticity, and acquire diverse skills in the absence of extrinsic supervision---all of which are hallmarks of human learning.</span>'}
{'title': 'LPRules: Rule Induction in Knowledge Graphs Using Linear Programming', 'authors': ['Sanjeeb Dash', 'Joao Goncalves'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=7QDPaL-Yl8U&name=pdf', 'abstract': '</span><span class="note_content_value">Knowledge graph (KG) completion is a well-studied problem in AI. Rule-based methods and embedding-based methods form two of the solution techniques. Rule-based methods learn first-order logic rules that capture existing facts in an input graph and then use these rules for reasoning about missing facts. A major drawback of such methods is the lack of scalability to large datasets. In this paper, we present a simple linear programming (LP) model to choose rules from a list of candidate rules and assign weights to them. For smaller KGs, we use simple heuristics to create the candidate list. For larger KGs, we start with a small initial candidate list, and then use standard column generation ideas to add more rules in order to improve the LP model objective value. To foster interpretability and generalizability, we limit the complexity of the set of chosen rules via explicit constraints, and tune the complexity hyperparameter for individual datasets. We show that our method can obtain state-of-the-art results for three out of four widely used KG datasets, while taking significantly less computing time than other popular rule learners including some based on neuro-symbolic methods. The improved scalability of our method allows us to tackle large datasets such as YAGO3-10.</span>'}
{'title': 'Universal Transformers', 'authors': ['Mostafa Dehghani', 'Stephan Gouws', 'Oriol Vinyals', 'Jakob Uszkoreit', 'Lukasz Kaiser'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': 'Published: 20 Dec 2018, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=HyzdRiR9Y7&name=pdf', 'abstract': '</span><span class="note_content_value">Recurrent neural networks (RNNs) sequentially process data by updating their state with each new data point, and have long been the de facto choice for sequence modeling tasks. However, their inherently sequential computation makes them slow to train. Feed-forward and convolutional architectures have recently been shown to achieve superior results on some sequence modeling tasks such as machine translation, with the added advantage that they concurrently process all inputs in the sequence, leading to easy parallelization and faster training times. Despite these successes, however, popular feed-forward sequence models like the Transformer fail to generalize in many simple tasks that recurrent models handle with ease, e.g. copying strings or even simple logical inference when the string or formula lengths exceed those observed at training time. We propose the Universal Transformer (UT), a parallel-in-time self-attentive recurrent sequence model which can be cast as a generalization of the Transformer model and which addresses these issues. UTs combine the parallelizability and global receptive field of feed-forward sequence models like the Transformer with the recurrent inductive bias of RNNs. We also add a dynamic per-position halting mechanism and find that it improves accuracy on several tasks. In contrast to the standard Transformer, under certain assumptions UTs can be shown to be Turing-complete. Our experiments show that UTs outperform standard Transformers on a wide range of algorithmic and language understanding tasks, including the challenging LAMBADA language modeling task where UTs achieve a new state of the art, and machine translation where UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De dataset.</span>'}
{'title': 'Constraint-Driven Explanations of Black-Box ML Models', 'authors': ['Aditya Aniruddha Shrotri', 'Nina Narodytska', 'Alexey Ignatiev', 'Joao Marques-Silva', 'Kuldeep S. Meel', 'Moshe Vardi'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=kVZ6WBYazFq&name=pdf', 'abstract': '</span><span class="note_content_value">Modern machine learning techniques have enjoyed widespread success, but are plagued by lack of transparency in their decision making, which has led to the emergence of the field of explainable AI.  One popular approach called LIME, seeks to explain an opaque model\'s behavior, by training a surrogate interpretable model to be locally faithful on perturbed instances. \nDespite being model-agnostic and easy-to-use, it is known that LIME\'s explanations can be unstable and are susceptible to adversarial attacks as a result of Out-Of-Distribution (OOD) sampling. Quality of explanations is also calculated heuristically, and lacks a strong theoretical foundation. In spite of numerous attempts to remedy some of these issues, making the LIME framework more trustworthy and reliable remains an open problem.\n\nIn this work, we demonstrate that the OOD sampling problem stems  from rigidity of the perturbation procedure.  To resolve this issue, we propose a theoretically sound framework based on uniform sampling of user-defined subspaces. Through logical constraints, we afford the end-user the flexibility to delineate the precise subspace of the input domain to be explained. This not only helps mitigate the problem of OOD sampling, but also allow experts to drill down and uncover bugs deep inside the model. For testing the quality of generated explanations, we develop an efficient estimation algorithm that is able to certifiably measure the true value of metrics such as fidelity up to any desired degree of accuracy, which can help in building trust in the generated explanations. Our framework called CLIME can be applied to any ML model, and extensive experiments demonstrate its versatility on real-world problems.\n</span>'}
{'title': 'Scalable Neural Theorem Proving on Knowledge Bases and Natural Language', 'authors': ['Pasquale Minervini', 'Matko Bosnjak', 'Tim Rocktäschel', 'Edward Grefenstette', 'Sebastian Riedel'], 'Conference': 'ICLR 2019 Conference Blind Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=BJzmzn0ctX&name=pdf', 'abstract': '</span><span class="note_content_value">Reasoning over text and Knowledge Bases (KBs) is a major challenge for Artificial Intelligence, with applications in machine reading, dialogue, and question answering.  Transducing text to logical forms which can be operated on is a brittle and error-prone process. Operating directly on text by jointly learning representations and transformations thereof by means of neural architectures that lack the ability to learn and exploit general rules can be very data-inefficient and not generalise correctly. These issues are addressed by Neural Theorem Provers (NTPs) (Rocktäschel &amp; Riedel, 2017), neuro-symbolic systems based on a continuous relaxation of Prolog’s backward chaining algorithm, where symbolic unification between atoms is replaced by a differentiable operator computing the similarity between their embedding representations. In this paper, we first propose Neighbourhood-approximated Neural Theorem Provers (NaNTPs) consisting of two extensions toNTPs, namely a) a method for drastically reducing the previously prohibitive time and space complexity during inference and learning, and b) an attention mechanism for improving the rule learning process, deeming them usable on real-world datasets. Then, we propose a novel approach for jointly reasoning over KB facts and textual mentions, by jointly embedding them in a shared embedding space. The proposed method is able to extract rules and provide explanations—involving both textual patterns and KB relations—from large KBs and text corpora. We show that NaNTPs perform on par with NTPs at a fraction of a cost, and can achieve competitive link prediction results on challenging large-scale datasets, including WN18, WN18RR, and FB15k-237 (with and without textual mentions) while being able to provide explanations for each prediction and extract interpretable rules.</span>'}
{'title': 'Inapplicable Actions Learning for Knowledge Transfer in Reinforcement Learning', 'authors': ['Leo Ardon', 'Alberto Pozanco', 'Daniel Borrajo', 'Sumitra Ganesh'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=TXH64IwWgS&name=pdf', 'abstract': '</span><span class="note_content_value">Reinforcement Learning (RL) algorithms are known to scale poorly to environments with many available actions, requiring numerous samples to learn an optimal policy. The traditional approach of considering the same fixed action space in every possible state implies that the agent must understand, while also learning to maximize its reward, to ignore irrelevant actions such as <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mtext class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c><mjx-c class="mjx-c1D45B TEX-I"></mjx-c><mjx-c class="mjx-c1D44E TEX-I"></mjx-c><mjx-c class="mjx-c1D45D TEX-I"></mjx-c><mjx-c class="mjx-c1D45D TEX-I"></mjx-c><mjx-c class="mjx-c1D459 TEX-I"></mjx-c><mjx-c class="mjx-c1D456 TEX-I"></mjx-c><mjx-c class="mjx-c1D450 TEX-I"></mjx-c><mjx-c class="mjx-c1D44E TEX-I"></mjx-c><mjx-c class="mjx-c1D44F TEX-I"></mjx-c><mjx-c class="mjx-c1D459 TEX-I"></mjx-c><mjx-c class="mjx-c1D452 TEX-I"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c1D44E TEX-I"></mjx-c><mjx-c class="mjx-c1D450 TEX-I"></mjx-c><mjx-c class="mjx-c1D461 TEX-I"></mjx-c><mjx-c class="mjx-c1D456 TEX-I"></mjx-c><mjx-c class="mjx-c1D45C TEX-I"></mjx-c><mjx-c class="mjx-c1D45B TEX-I"></mjx-c><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mtext></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext mathvariant="italic">inapplicable actions</mtext></math></mjx-assistive-mml></mjx-container> (i.e. actions that have no effect on the environment when performed in a given state). Knowing this information can help reduce the sample complexity of RL algorithms by masking the inapplicable actions from the policy distribution to only explore actions relevant to finding an optimal policy. This is typically done in an ad-hoc manner with hand-crafted domain logic added to the RL algorithm. In this paper, we propose a more systematic approach to introduce this knowledge into the algorithm. We (i) standardize the way knowledge can be manually specified to the agent; and (ii) present a new framework to autonomously learn these state-dependent action constraints jointly with the policy. We show experimentally that learning inapplicable actions greatly improves the sample efficiency of the algorithm by providing a reliable signal to mask out irrelevant actions. Moreover, we demonstrate that thanks to the transferability of the knowledge acquired, it can be reused in other tasks to make the learning process more efficient.</span>'}
{'title': 'Programmatic Reinforcement Learning without Oracles', 'authors': ['Wenjie Qiu', 'He Zhu'], 'Conference': 'ICLR 2022 Spotlight', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=6Tk2noBdvxt&name=pdf', 'abstract': '</span><span class="note_content_value">Deep reinforcement learning (RL) has led to encouraging successes in many challenging control tasks. However, a deep RL model lacks interpretability due to the difficulty of identifying how the model\'s control logic relates to its network structure. Programmatic policies structured in more interpretable representations emerge as a promising solution. Yet two shortcomings remain: First, synthesizing programmatic policies requires optimizing over the discrete and non-differentiable search space of program architectures. Previous works are suboptimal because they only enumerate program architectures greedily guided by a pretrained RL oracle. Second, these works do not exploit compositionality, an important programming concept, to reuse and compose primitive functions to form a complex function for new tasks. Our first contribution is a programmatically interpretable RL framework that conducts program architecture search on top of a continuous relaxation of the architecture space defined by programming language grammar rules. Our algorithm allows policy architectures to be learned with policy parameters via bilevel optimization using efficient policy-gradient methods, and thus does not require a pretrained oracle. Our second contribution is improving programmatic policies to support compositionality by integrating primitive functions learned to grasp task-agnostic skills as a composite program to solve novel RL problems. Experiment results demonstrate that our algorithm excels in discovering optimal programmatic policies that are highly interpretable. The code of this work is available at <a href="https://github.com/RU-Automated-Reasoning-Group/pi-PRL" target="_blank" rel="nofollow">https://github.com/RU-Automated-Reasoning-Group/pi-PRL</a>.</span>'}
{'title': 'Detecting Anomalies in Communication Packet Streams based on Generative Adversarial Networks', 'authors': [], 'Conference': 'ICLR 2018 Conference Withdrawn Submission', 'date': '03 Jan 2018 (modified: 25 Jan 2018)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SJjADecmf&name=pdf', 'abstract': '</span><span class="note_content_value">The fault diagnosis in a modern communication system is traditionally supposed to be difficult, or even impractical for a purely data-driven machine learning approach, for it is a humanmade system of intensive knowledge. A few labeled raw packet streams extracted from fault archive can hardly be sufficient to deduce the intricate logic of underlying protocols. In this paper, we supplement these limited samples with two inexhaustible data sources: the unlabeled records probed from a system in service, and the labeled data simulated in an emulation environment. To transfer their inherent knowledge to the target domain, we construct a directed information flow graph, whose nodes are neural network components consisting of two generators, three discriminators and one classifier, and whose every forward path represents a pair of adversarial optimization goals, in accord with the semi-supervised and transfer learning demands. The multi-headed network can be trained in an alternative approach, at each iteration of which we select one target to update the weights along the path upstream, and refresh the residual layer-wisely to all outputs downstream. The actual results show that it can achieve comparable accuracy on classifying Transmission Control Protocol (TCP) streams without deliberate expert features. The solution has relieved operation engineers from massive works of understanding and maintaining rules, and provided a quick solution independent of specific protocols.</span>'}
{'title': 'Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning', 'authors': ['Pan Lu', 'Liang Qiu', 'Kai-Wei Chang', 'Ying Nian Wu', 'Song-Chun Zhu', 'Tanmay Rajpurohit', 'Peter Clark', 'Ashwin Kalyan'], 'Conference': 'ICLR 2023 poster', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=DHyHRBwJUTN&name=pdf', 'abstract': '</span><span class="note_content_value">Mathematical reasoning, a core ability of human intelligence, presents unique challenges for machines in abstract thinking and logical reasoning. Recent large pre-trained language models such as GPT-3 have achieved remarkable progress on mathematical reasoning tasks written in text form, such as math word problems (MWP). However, it is unknown if the models can handle more complex problems that involve math reasoning over heterogeneous information, such as tabular data. To fill the gap, we present Tabular Math Word Problems (TabMWP), a new dataset containing 38,431 open-domain grade-level problems that require mathematical reasoning on both textual and tabular data. Each question in TabMWP is aligned with a tabular context, which is presented as an image, semi-structured text, and a structured table. There are two types of questions: free-text and multi-choice, and each problem is annotated with gold solutions to reveal the multi-step reasoning process. We evaluate different pre-trained models on TabMWP, including the GPT-3 model in a few-shot setting. As earlier studies suggest, since few-shot GPT-3 relies on the selection of in-context examples, its performance is unstable and can degrade to near chance. The unstable issue is more severe when handling complex problems like TabMWP. To mitigate this, we further propose a novel approach, PromptPG, which utilizes policy gradient to learn to select in-context examples from a small amount of training data and then constructs the corresponding prompt for the test example. Experimental results show that our method outperforms the best baseline by 5.31% on the accuracy metric and reduces the prediction variance significantly compared to random selection, which verifies its effectiveness in selecting in-context examples. The data and code are available at <a href="https://promptpg.github.io." target="_blank" rel="nofollow">https://promptpg.github.io.</a></span>'}
{'title': 'Flexible and Efficient Long-Range Planning Through Curious Exploration', 'authors': ['Aidan Curtis', 'Minjian Xin', 'Kevin Feigelis', 'Dan Yamins'], 'Conference': 'ICLR 2020 Conference Blind Submission', 'date': '25 Sept 2019 (modified: 16 Sept 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=r1xo9grKPr&name=pdf', 'abstract': '</span><span class="note_content_value">Identifying algorithms that flexibly and efficiently discover temporally-extended multi-phase plans is an essential next step for the advancement of robotics and model-based reinforcement learning. The core problem of long-range planning is finding an efficient way to search through the tree of possible action sequences — which, if left unchecked, grows exponentially with the length of the plan. Existing non-learned planning solutions from the Task and Motion Planning (TAMP) literature rely on the existence of logical descriptions for the effects and preconditions for actions. This constraint allows TAMP methods to efficiently reduce the tree search problem but limits their ability to generalize to unseen and complex physical environments. In contrast, deep reinforcement learning (DRL) methods use flexible neural-network-based function approximators to discover policies that generalize naturally to unseen circumstances. However, DRL methods have had trouble dealing with the very sparse reward landscapes inherent to long-range multi-step planning situations. Here, we propose the Curious Sample Planner (CSP), which fuses elements of TAMP and DRL by using a curiosity-guided sampling strategy to learn to efficiently explore the tree of action effects. We show that CSP can efficiently discover interesting and complex temporally-extended plans for solving a wide range of physically realistic 3D tasks. In contrast, standard DRL and random sampling methods often fail to solve these tasks at all or do so only with a huge and highly variable number of training samples. We explore the use of a variety of curiosity metrics with CSP and analyze the types of solutions that CSP discovers. Finally, we show that CSP supports task transfer so that the exploration policies learned during experience with one task can help improve efficiency on related tasks.</span>'}
{'title': 'On Learning Read-once DNFs With Neural Networks', 'authors': ['Ido Bronstein', 'Alon Brutzkus', 'Amir Globerson'], 'Conference': 'ICLR 2021 Conference Blind Submission', 'date': '28 Sept 2020 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=G0VouKj9HUG&name=pdf', 'abstract': '</span><span class="note_content_value">Learning functions over Boolean variables is a fundamental problem in machine learning. But not much is known about learning such functions by neural networks. Because learning these functions in the distribution free setting is NP-Hard, they are unlikely to be efficiently learnable by networks in this case. However, assuming the inputs are sampled from the uniform distribution, an important subset of functions that are known to be efficiently learnable is read-once DNFs. Here we focus on this setting where the functions are learned by a convex neural network and gradient descent. \nWe first observe empirically that the learned neurons are aligned with the terms of the DNF, despite the fact that there are many zero-error networks that do not have this property. Thus, the learning process has a clear inductive bias towards such logical formulas. To gain a better theoretical understanding of this phenomenon we focus on minimizing the population risk. We show that this risk can be minimized by multiple networks: from ones that memorize data to ones that compactly represent the DNF. We then set out to understand why gradient descent ``"chooses" the compact representation. \nWe use a computer assisted proof to prove the inductive bias for relatively small DNFs, and use it to design a process for reconstructing the DNF from the learned network. We then continue to provide theoretical insights on the learning process and the loss surface to better understand the resulting inductive bias. For example, we show that the neurons in solutions with minimum <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msub><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D459 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: -0.15em;"><mjx-mn class="mjx-n" size="s"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>l</mi><mn>2</mn></msub></math></mjx-assistive-mml></mjx-container>-norm of the weights are also aligned with the terms of the DNF. Finally, we empirically show that our results are validated in the empirical case for high dimensional DNFs, more general network architectures and tabular datasets.</span>'}
{'title': 'Improving Accuracy and Explainability of Online Handwriting Recognition', 'authors': ['Jonathan Gold', 'Hilda Azimi', 'Steven Chang', 'Koray Karabina'], 'Conference': 'ICLR 2023 Conference Withdrawn Submission', 'date': '22 Sept 2022 (modified: 13 Feb 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=20tAZh6Ut3&name=pdf', 'abstract': '</span><span class="note_content_value">Handwriting recognition technology allows recognizing a written text from a given data. The recognition task can target letters, symbols, or words, and the input data can be a digital image or recorded by various sensors. A wide range of applications from signature verification to electronic document processing can be realized by implementing efficient and accurate handwriting recognition algorithms. Over the years, there has been an increasing interest in experimenting with different types of technology to collect handwriting data, create datasets, and develop algorithms to recognize characters and symbols. More recently, the OnHW-chars dataset has been published that contains multivariate time series data of the English alphabet collected using a ballpoint pen fitted with sensors. The authors of OnHW-chars also provided some baseline results through their machine learning (ML) and deep learning (DL) classifiers.\n\nIn this paper, we develop handwriting recognition models on the OnHW-chars dataset and improve the accuracy of previous models. More specifically, our ML models provide <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c33"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>11.3</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>-<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c35"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>23.56</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> improvements over the previous ML models, and our optimized DL models with ensemble learning provide <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c38"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3.08</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container>-<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="3" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c37"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c31"></mjx-c></mjx-mn><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>7.01</mn><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> improvements over the previous DL models. In addition to our accuracy improvements over the spectrum, we aim to provide some level of explainability for our models to provide more logic behind chosen methods and why the models make sense for the data type in the dataset. Our source codes, data, and models will be made publicly available for verifiability and reproducibility of our results.</span>'}
{'title': 'Graph Neural Networks for Aerodynamic Flow Reconstruction from Sparse Sensing', 'authors': ['Gregory Duthé', 'Imad Abdallah', 'Sarah Barber', 'Eleni Chatzi'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=_kf9GU5c_sE&name=pdf', 'abstract': '</span><span class="note_content_value">  Sensing the fluid flow around an arbitrary geometry entails extrapolating from the physical quantities perceived at its surface in order to reconstruct the features of the surrounding fluid. This is a challenging inverse problem, yet one that if solved could have a significant impact on many engineering applications. The exploitation of such an inverse logic has gained interest in recent years with the advent of widely available cheap but capable MEMS-based sensors. When combined with novel data-driven methods, these sensors may allow for flow reconstruction around immersed structures, benefiting applications such as unmanned airborne/underwater vehicle path planning or control and structural health monitoring of wind turbine blades. In this work, we train deep reversible Graph Neural Networks (GNNs) to perform flow sensing (flow reconstruction) around two-dimensional aerodynamic shapes: airfoils. Motivated by recent work, which has shown that GNNs can be powerful alternatives to mesh-based forward physics simulators, we implement a Message-Passing Neural Network to simultaneously reconstruct both the pressure and velocity fields surrounding simulated airfoils based on their surface pressure distributions, whilst additionally gathering useful farfield properties in the form of context vectors. We generate a unique dataset of Computational Fluid Dynamics simulations by simulating random, yet meaningful combinations of input boundary conditions and airfoil shapes. We show that despite the challenges associated with reconstructing the flow around arbitrary airfoil geometries in high Reynolds turbulent inflow conditions, our framework is able to generalize well to unseen cases.</span>'}
{'title': 'Non-Parametric Neuro-Adaptive Control Subject to Task Specifications', 'authors': ['Christos Verginis', 'Zhe Xu', 'ufuk topcu'], 'Conference': 'ICLR 2022 Submitted', 'date': 'Published: 28 Jan 2022, Last Modified: 13 Feb 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=FWiwSGJ_Bpa&name=pdf', 'abstract': '</span><span class="note_content_value">We develop a learning-based algorithm for the control of autonomous systems governed by unknown, nonlinear dynamics to satisfy user-specified spatio-temporal tasks expressed as signal temporal logic specifications. Most existing algorithms either assume certain parametric forms for the unknown dynamic terms or resort to unnecessarily large control inputs in order to provide theoretical guarantees. \nThe proposed algorithm addresses these drawbacks by integrating neural-network-based learning with adaptive control. More specifically, the algorithm learns a controller, represented as a neural network, using training data that correspond to a collection of system parameters and tasks. These parameters and tasks are derived by varying the nominal parameters and the spatio-temporal constraints of the user-specified task, respectively.  It then incorporates this neural network into an online closed-form adaptive control policy in such a way that the resulting behavior satisfies the user-defined task. The proposed algorithm does not use any a priori information on the unknown dynamic terms or any approximation schemes. We provide formal theoretical guarantees on the satisfaction of the task. Numerical experiments on a robotic manipulator and a unicycle robot demonstrate that the proposed algorithm guarantees the satisfaction of 50 user-defined tasks, and outperforms control policies that do not employ online adaptation or the neural-network controller. Finally, we show that the proposed algorithm achieves greater performance than standard reinforcement-learning algorithms in the pendulum benchmarking environment.</span>'}
{'title': 'Knowledge-Driven Active Learning', 'authors': ['Gabriele Ciravegna', 'Frederic Precioso', 'Marco Gori'], 'Conference': 'Submitted to ICLR 2023', 'date': 'Published: 01 Feb 2023, Last Modified: 16 Sept 2023', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=hmpjFiUly1&name=pdf', 'abstract': '</span><span class="note_content_value">The deployment of Deep Learning (DL) models is still precluded in those contexts where the amount of supervised data is limited. To answer this issue, active learning strategies aim at minimizing the amount of labelled data required to train a DL model. Most active strategies are based on uncertain sample selection, and even often restricted to samples lying close to the decision boundary. These techniques are theoretically sound, but an understanding of the selected samples based on their content is not straightforward, further driving non-experts to consider DL as a black-box. For the first time, here we propose a different approach, taking into consideration common domain-knowledge and enabling non-expert users to train a model with fewer samples. In our Knowledge-driven Active Learning (KAL) framework, rule-based knowledge is converted into logic constraints and their violation is checked as a natural guide for sample selection. We show that even simple relationships among data and output classes offer a way to spot predictions for which the model need supervision. The proposed approach (i) outperforms many active learning strategies in terms of average F1 score, particularly in those contexts where domain knowledge is rich. Furthermore, we empirically demonstrate that (ii) KAL discovers data distribution lying far from the initial training data unlike uncertainty-based strategies, (iii) it ensures domain experts that the provided knowledge is respected by the model on test data, and (iv) it can be employed even when domain-knowledge is not available by coupling it with a XAI technique. Finally, we also show that KAL is also suitable for object recognition tasks and, its computational demand is low, unlike many recent active learning strategies.</span>'}
{'title': 'Data Interpretation and Reasoning Over Scientific Plots', 'authors': ['Pritha Ganguly', 'Nitesh Methani'], 'Conference': 'ICLR 2019 Conference Withdrawn Submission', 'date': '27 Sept 2018 (modified: 05 May 2023)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=SygeznA9YX&name=pdf', 'abstract': '</span><span class="note_content_value">Data Interpretation is an important part of Quantitative Aptitude exams and requires an individual to answer questions grounded in plots such as bar charts, line graphs, scatter plots, \\textit{etc}. Recently, there has been an increasing interest in building models which can perform this task by learning from datasets containing triplets of the form \\{plot, question, answer\\}. Two such datasets have been proposed in the recent past which contain plots generated from synthetic data with limited (i) <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="0" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="3"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi><mo>−</mo><mi>y</mi></math></mjx-assistive-mml></mjx-container> axes variables (ii) question templates and (iii) answer vocabulary and hence do not adequately capture the challenges posed by this task. To overcome these limitations of existing datasets, we introduce a new dataset containing <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="1" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c37"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>9.7</mn></math></mjx-assistive-mml></mjx-container> million question-answer pairs grounded over <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="2" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c37"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="2"><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>270</mn><mo>,</mo><mn>000</mn></math></mjx-assistive-mml></mjx-container> plots with three main differentiators. First, the plots in our dataset contain a wide variety of realistic <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="3" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></mjx-assistive-mml></mjx-container>-<mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="4" style="font-size: 121.3%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D466 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></mjx-assistive-mml></mjx-container> variables such as CO2 emission, fertility rate, \\textit{etc.} extracted from  real word data sources such as World Bank, government sites, \\textit{etc}. Second, the questions in our dataset are more complex as they are based on templates extracted from interesting questions asked by a crowd of workers using a fraction of these plots. Lastly, the answers in our dataset are not restricted to a small vocabulary and a large fraction of the answers seen at test time are not present in the training vocabulary. As a result, existing models for Visual Question Answering which largely use end-to-end models in a multi-class classification framework cannot be used for this task. We establish initial results on this dataset and emphasize the complexity of the task using a multi-staged modular pipeline with various sub-components to (i) extract relevant data from the plot and convert it to a semi-structured table (ii) combine the question with this table and use compositional semantic parsing to arrive at a logical form from which the answer can be derived. We believe that such a modular framework is the best way to go forward as it would enable the research community to independently make progress on all the sub-tasks involved in plot question answering.</span>'}
{'title': 'Near-Data Processing for Machine Learning', 'authors': ['Hyeokjun Choe', 'Seil Lee', 'Hyunha Nam', 'Seongsik Park', 'Seijoon Kim', 'Eui-Young Chung', 'Sungroh Yoon'], 'Conference': 'Submitted to ICLR 2017', 'date': '05 Nov 2016 (modified: 21 Jul 2022)', 'link': 'https://openreview.nethttps://openreview.net/attachment?id=H1_EDpogx&name=pdf', 'abstract': '</span><span class="note_content_value">In computer architecture, near-data processing (NDP) refers to augmenting the memory or the storage with processing power so that it can process the data stored therein. By offloading the computational burden of CPU and saving the need for transferring raw data in its entirety, NDP exhibits a great potential for acceleration and power reduction. Despite this potential, specific research activities on NDP have witnessed only limited success until recently, often owing to performance mismatches between logic and memory process technologies that put a limit on the processing capability of memory. Recently, there have been two major changes in the game, igniting the resurgence of NDP with renewed interest. The first is the success of machine learning (ML), which often demands a great deal of computation for training, requiring frequent transfers of big data. The second is the advent of NAND flash-based solid-state drives (SSDs) containing multicore processors that can accommodate extra computation for data processing. Sparked by these application needs and technological support, we evaluate the potential of NDP for ML using a new SSD platform that allows us to simulate in-storage processing (ISP) of ML workloads. Our platform (named ISP-ML) is a full-fledged simulator of a realistic multi-channel SSD that can execute various ML algorithms using the data stored in the SSD. For thorough performance analysis and in-depth comparison with alternatives, we focus on a specific algorithm: stochastic gradient decent (SGD), which is the de facto standard for training differentiable learning machines including deep neural networks. We implement and compare three variants of SGD (synchronous, Downpour, and elastic averaging) using ISP-ML, exploiting the multiple NAND channels for parallelizing SGD. In addition, we compare the performance of ISP and that of conventional in-host processing, revealing the advantages of ISP. Based on the advantages and limitations identified through our experiments, we further discuss directions for future research on ISP for accelerating ML.</span>'}
